var documenterSearchIndex = {"docs":
[{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"EditURL = \"https://github.com/jump-dev/DiffOpt.jl/blob/master/docs/src/examples/sensitivity-analysis-ridge.jl\"","category":"page"},{"location":"examples/sensitivity-analysis-ridge/#Sensitivity-Analysis-of-Ridge-Regression","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"","category":"section"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"(Image: ) (Image: )","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"This example illustrates the sensitivity analysis of data points in a Ridge Regression problem. The general form of the problem is given below:","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"beginsplit\nbeginarray ll\nmboxminimize  sum_i=1^N (y_i - w x_i - b)^2 + alpha (w^2 + b^2) \nendarray\nendsplit","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"where","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"w, b are slope and intercept of the regressing line\nx, y are the N data points\nÎ± is the regularization constant","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"which is equivalent to:","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"beginsplit\nbeginarray ll\nmboxminimize  e^tope + alpha (w^2 + b^2) \nmboxst  e_i = y_i - w x_i - b quad quad i=1N  \nendarray\nendsplit","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"This tutorial uses the following packages","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"using JuMP\nimport DiffOpt\nimport Random\nimport OSQP\nimport Plots\nimport LinearAlgebra: normalize!, dot","category":"page"},{"location":"examples/sensitivity-analysis-ridge/#Define-and-solve-the-problem","page":"Sensitivity Analysis of Ridge Regression","title":"Define and solve the problem","text":"","category":"section"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"Construct a set of noisy (guassian) data points around a line.","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"Random.seed!(42)\n\nN = 100\n\nw = 2 * abs(randn())\nb = rand()\nX = randn(N)\nY = w * X .+ b + 0.8 * randn(N);\nnothing #hide","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"The helper method fit_ridge defines and solves the corresponding model. The ridge regression is modeled with quadratic programming (quadratic objective and linear constraints) and solved in generic methods of OSQP. This is not the standard way of solving the ridge regression problem this is done here for didactic purposes.","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"function fit_ridge(X, Y, alpha = 0.1)\n    N = length(Y)\n    # Initialize a JuMP Model with OSQP solver\n    model = Model(() -> DiffOpt.diff_optimizer(OSQP.Optimizer))\n    set_silent(model)\n    @variable(model, w) # angular coefficient\n    @variable(model, b) # linear coefficient\n    @variable(model, e[1:N]) # approximation error\n    # constraint defining approximation error\n    @constraint(model, cons[i=1:N], e[i] == Y[i] - w * X[i] - b)\n    # objective minimizing squared error and ridge penalty\n    @objective(\n        model,\n        Min,\n        dot(e, e) + alpha * (sum(w * w) + sum(b * b)),\n    )\n    optimize!(model)\n    return model, w, b, cons # return model, variables and constraints references\nend","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"Train on the data generated.","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"model, w, b, cons = fit_ridge(X, Y)\nwÌ‚, bÌ‚ = value(w), value(b)","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"We can visualize the approximating line.","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"p = Plots.scatter(X, Y, label=\"\")\nmi, ma = minimum(X), maximum(X)\nPlots.plot!(p, [mi, ma], [mi * wÌ‚ + bÌ‚, ma * wÌ‚ + bÌ‚], color=:red, label=\"\")","category":"page"},{"location":"examples/sensitivity-analysis-ridge/#Differentiate","page":"Sensitivity Analysis of Ridge Regression","title":"Differentiate","text":"","category":"section"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"Now that we've solved the problem, we can compute the sensitivity of optimal values of the angular coefficient w with respect to perturbations in the data points (x,y).","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"Begin differentiating the model. analogous to varying Î¸ in the expression:","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"e_i = (y_i + theta_y_i) - w (x_i + theta_x_i) - b","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"âˆ‡ = zero(X)\nfor i in 1:N\n    for j in 1:N\n        MOI.set(\n            model,\n            DiffOpt.ForwardInConstraint(),\n            cons[j],\n            i == j ? index(w) + 1.0 : 0.0 * index(w)\n        )\n    end\n    DiffOpt.forward(model)\n    dw = MOI.get(\n        model,\n        DiffOpt.ForwardOutVariablePrimal(),\n        w\n    )\n    âˆ‡[i] = abs(dw)\nend\n\nnormalize!(âˆ‡);\nnothing #hide","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"Visualize point sensitivities with respect to regressing line. Note that the gradients are normalized.","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"p = Plots.scatter(\n    X, Y,\n    color = [x > 0 ? :red : :blue for x in âˆ‡],\n    markersize = [25 * abs(x) for x in âˆ‡],\n    label = \"\"\n)\nmi, ma = minimum(X), maximum(X)\nPlots.plot!(p, [mi, ma], [mi * wÌ‚ + bÌ‚, ma * wÌ‚ + bÌ‚], color = :red, label = \"\")","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"Note the points in the extremes of the line segment are larger because moving those points has a stronger effect on the angular coefficient of the line.","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"","category":"page"},{"location":"examples/sensitivity-analysis-ridge/","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"This page was generated using Literate.jl.","category":"page"},{"location":"intro/#Introduction","page":"Introduction","title":"Introduction","text":"","category":"section"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"An optimization problem is the problem of finding the best solution from all feasible solutions. The standard form of an optimization problem is ","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"beginaligned\nunderset xoperatorname minimize f(x)operatorname subjectto g_i(x)leq 0quad i=1dots mh_j(x)=0quad j=1dots p\nendaligned","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"Note that finding solution to most of the optimization problems is computationally intractable. Here we consider a subset of those problems called convex optimization problems, which admit polynomial time solutions. The standard form of a convex optimization problem is ","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"beginaligned\nunderset xoperatorname minimize f(x)operatorname subjectto g_i(x)leq 0quad i=1dots mA x = b\nendaligned","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"where f and g_i are convex functions.","category":"page"},{"location":"intro/#Parameterized-problems","page":"Introduction","title":"Parameterized  problems","text":"","category":"section"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"In practice, convex optimization problems include parameters, apart from the decision variables, which determines the structure of the problem itself i.e. the objective function and constraints. Hence they affect the solution too. A general form of a parameterized convex optimization problem is ","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"beginaligned\nunderset xoperatorname minimize f(x theta)operatorname subjectto g_i(x theta)leq 0quad i=1dots mA(theta) x = b(theta)\nendaligned","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"where theta is the parameter. In different fields, these parameters go by different names:","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"Hyperparameters in machine learning\nRisk aversion or other backtesing parameters in financial modelling\nParameterized systems in control theory","category":"page"},{"location":"intro/#What-do-we-mean-by-differentiating-a-parameterized-optimization-program?-Why-do-we-need-it?","page":"Introduction","title":"What do we mean by differentiating a parameterized optimization program? Why do we need it?","text":"","category":"section"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"Often, parameters are chosen and tuned by hand - an iterative process - and the structure of the problem is crafted manually. But it is possible to do an automatic gradient based tuning of parameters.","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"Consider solution of the parametrized optimization problem, x(theta),","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"beginsplit\nbeginarray lll\nx^*(theta)= underset xoperatorname argmin  f(x theta)\n              operatorname subjectto  g_i(x theta)leq 0quad i=1dots m\n                                           A(theta) x = b(theta)\nendarray\nendsplit","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"which is the input of l(x^*(theta)), a loss function. Our goal is to choose the best parameter theta so that l is optimized. Here, l(x^*(theta)) is the objective function and theta is the decision variable. In order to apply a gradient-based strategy to this problem, we need to differentiate l with respect to theta.","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"fracpartial l(x^*(theta))partial theta = fracpartial l(x^*(theta))partial x^*(theta)  fracpartial x^*(theta)partial theta","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"By implicit function theorem, this translates to differentiating the program data, i.e. functions f, g_i(x) and matrices A, b, with respect to theta.","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"This is can be achieved in two steps or passes:","category":"page"},{"location":"intro/","page":"Introduction","title":"Introduction","text":"Forward pass - Given an initial value of theta, solves the optimization problem to find x^*(theta)\nBackward pass - Given x^*, differentiate and find fracpartial x^*(theta)partial theta","category":"page"},{"location":"manual/#Manual","page":"Manual","title":"Manual","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"note: Note\nAs of now, this package only works for optimization models that can be written either in convex conic form or convex quadratic form.","category":"page"},{"location":"manual/#Supported-objectives-and-constraints-scheme-1","page":"Manual","title":"Supported objectives & constraints - scheme 1","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"For QPTH/OPTNET style backend, the package supports following Function-in-Set constraints: ","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"MOI Function MOI Set\nVariableIndex GreaterThan\nVariableIndex LessThan\nVariableIndex EqualTo\nScalarAffineFunction GreaterThan\nScalarAffineFunction LessThan\nScalarAffineFunction EqualTo","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"and the following objective types: ","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"MOI Function\nVariableIndex\nScalarAffineFunction\nScalarQuadraticFunction","category":"page"},{"location":"manual/#Supported-objectives-and-constraints-scheme-2","page":"Manual","title":"Supported objectives & constraints - scheme 2","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"For DiffCP/CVXPY style backend, the package supports following Function-in-Set constraints: ","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"MOI Function MOI Set\nVectorOfVariables Nonnegatives\nVectorOfVariables Nonpositives\nVectorOfVariables Zeros\nVectorOfVariables SecondOrderCone\nVectorOfVariables PositiveSemidefiniteConeTriangle\nVectorAffineFunction Nonnegatives\nVectorAffineFunction Nonpositives\nVectorAffineFunction Zeros\nVectorAffineFunction SecondOrderCone\nVectorAffineFunction PositiveSemidefiniteConeTriangle","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"and the following objective types: ","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"MOI Function\nVariableIndex\nScalarAffineFunction","category":"page"},{"location":"manual/#Creating-a-differentiable-optimizer","page":"Manual","title":"Creating a differentiable optimizer","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"You can create a differentiable optimizer over an existing MOI solver by using the diff_optimizer utility. ","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"diff_optimizer","category":"page"},{"location":"manual/#DiffOpt.diff_optimizer","page":"Manual","title":"DiffOpt.diff_optimizer","text":"diff_optimizer(optimizer_constructor)::Optimizer\n\nCreates a DiffOpt.Optimizer, which is an MOI layer with an internal optimizer and other utility methods. Results (primal, dual and slack values) are obtained by querying the internal optimizer instantiated using the optimizer_constructor. These values are required for find jacobians with respect to problem data.\n\nOne define a differentiable model by using any solver of choice. Example:\n\njulia> import DiffOpt, GLPK\n\njulia> model = DiffOpt.diff_optimizer(GLPK.Optimizer)\njulia> model.add_variable(x)\njulia> model.add_constraint(...)\n\njulia> _backward_quad(model)  # for convex quadratic models\n\njulia> _backward_quad(model)  # for convex conic models\n\n\n\n\n\n","category":"function"},{"location":"manual/#Adding-new-sets-and-constraints","page":"Manual","title":"Adding new sets and constraints","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"The DiffOpt Optimizer behaves similarly to other MOI Optimizers and implements the MOI.AbstractOptimizer API.","category":"page"},{"location":"manual/#Projections-on-cone-sets","page":"Manual","title":"Projections on cone sets","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"DiffOpt requires taking projections and finding projection gradients of vectors while computing the jacobians. For this purpose, we use MathOptSetDistances.jl, which is a dedicated package for computing set distances, projections and projection gradients.","category":"page"},{"location":"manual/#Conic-problem-formulation","page":"Manual","title":"Conic problem formulation","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"note: Note\nAs of now, the package is using SCS geometric form for affine expressions in cones.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Consider a convex conic optimization problem in its primal (P) and dual (D) forms:","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"beginsplit\nbeginarray llcc\ntextbfPrimal Problem   textbfDual Problem  \nmboxminimize  c^T x  quad quad  mboxminimize  b^T y  \nmboxsubject to  A x + s = b  quad quad  mboxsubject to  A^T y + c = 0 \n s in mathcalK    y in mathcalK^*\nendarray\nendsplit","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"where","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"x in R^n is the primal variable, y in R^m is the dual variable, and s in R^m is the primal slack","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"variable","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"mathcalK subseteq R^m is a closed convex cone and mathcalK^* subseteq R^m is the corresponding dual cone","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"variable","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"A in R^m times n, b in R^m, c in R^n are problem data","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"In the light of above, DiffOpt differentiates program variables x, s, y  w.r.t pertubations/sensivities in problem data i.e. dA, db, dc. This is achieved via implicit differentiation and matrix differential calculus.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"Note that the primal (P) and dual (D) are self-duals of each other. Similarly, for the constraints we support, mathcalK is same in format as mathcalK^*.","category":"page"},{"location":"manual/#Reference-articles","page":"Manual","title":"Reference articles","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Differentiating Through a Cone Program - Akshay Agrawal, Shane Barratt, Stephen Boyd, Enzo Busseti, Walaa M. Moursi, 2019\nA fast and differentiable QP solver for PyTorch. Crafted by Brandon Amos and J. Zico Kolter.\nOptNet: Differentiable Optimization as a Layer in Neural Networks","category":"page"},{"location":"manual/#Backward-Pass-vector","page":"Manual","title":"Backward Pass vector","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"One possible point of confusion in finding Jacobians is the role of the backward pass vector - above eqn (7), OptNet: Differentiable Optimization as a Layer in Neural Networks. While differentiating convex programs, it is often the case that we don't want to find the acutal derivatives, rather we might be interested in computing the product of Jacobians with a backward pass vector, often used in backprop in machine learning/automatic differentiation. This is what happens in scheme 1 of DiffOpt backend.","category":"page"},{"location":"manual/","page":"Manual","title":"Manual","text":"But, for the conic system (scheme 2), we provide perturbations in conic data (dA, db, dc) to compute pertubations (dx, dy, dz) in input variables. Unlike the quadratic case, these perturbations are actual derivatives, not the product with a backward pass vector. This is an important distinction between the two schemes of differential optimization.","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"EditURL = \"https://github.com/jump-dev/DiffOpt.jl/blob/master/docs/src/examples/sensitivity-analysis-svm.jl\"","category":"page"},{"location":"examples/sensitivity-analysis-svm/#Sensitivity-Analysis-of-SVM","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"","category":"section"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"(Image: ) (Image: )","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"This notebook illustrates sensitivity analysis of data points in a Support Vector Machine (inspired from @matbesancon's SimpleSVMs.)","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"For reference, Section 10.1 of https://online.stat.psu.edu/stat508/book/export/html/792 gives an intuitive explanation of what it means to have a sensitive hyperplane or data point. The general form of the SVM training problem is given below (without regularization):","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"beginsplit\nbeginarray ll\nmboxminimize  lambdaw^2 + sum_i=1^N xi_i \nmboxst  xi_i ge 0 quad quad i=1N  \n             y_i (w^T X_i + b) ge 1 - xi_i quad i=1N  \nendarray\nendsplit","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"where","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"X, y are the N data points\nw is the support vector\nb determines the offset b/||w|| of the hyperplane with normal w\nÎ¾ is the soft-margin loss.","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"This tutorial uses the following packages","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"using JuMP     # The mathematical programming modelling language\nimport DiffOpt # JuMP extension for differentiable optimization\nimport Ipopt   # Optimization solver that handles quadratic programs\nimport Plots   # Graphing tool\nimport LinearAlgebra: dot, norm, normalize!\nimport Random","category":"page"},{"location":"examples/sensitivity-analysis-svm/#Define-and-solve-the-SVM","page":"Sensitivity Analysis of SVM","title":"Define and solve the SVM","text":"","category":"section"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"Construct separable, non-trivial data points.","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"N = 100\nD = 2\nRandom.seed!(62)\nX = vcat(randn(N Ã· 2, D), randn(N Ã· 2, D) .+ [4.5, 2.0]')\ny = append!(ones(N Ã· 2), -ones(N Ã· 2))\nÎ» = 0.05;\nnothing #hide","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"Let's initialize a special model that can understand sensitivities","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"model = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer))\nMOI.set(model, MOI.Silent(), true)","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"Add the variables","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"@variable(model, Î¾[1:N])\n@variable(model, w[1:D])\n@variable(model, b);\nnothing #hide","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"Add the constraints.","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"@constraint(\n    model,\n    [i in 1:N],\n    Î¾[i] >= 0\n);\n@constraint(\n    model,\n    cons[i in 1:N],\n    y[i] * (dot(X[i, :], w) + b) >= 1 - Î¾[i]\n);\nnothing #hide","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"Define the objective and solve","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"@objective(\n    model,\n    Min,\n    Î» * dot(w, w) + sum(Î¾),\n)\n\noptimize!(model)","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"We can visualize the separating hyperplane.","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"loss = objective_value(model)\n\nwv = value.(w)\n\nbv = value(b)\n\nsvm_x = [0.0, 5.0] # arbitrary points\nsvm_y = (-bv .- wv[1] * svm_x )/wv[2]\n\np = Plots.scatter(X[:,1], X[:,2], color = [yi > 0 ? :red : :blue for yi in y], label = \"\")\nPlots.yaxis!(p, (-2, 4.5))\nPlots.plot!(p, svm_x, svm_y, label = \"loss = $(round(loss, digits=2))\", width=3)","category":"page"},{"location":"examples/sensitivity-analysis-svm/#Gradient-of-hyperplane-wrt-the-data-point-coordinates","page":"Sensitivity Analysis of SVM","title":"Gradient of hyperplane wrt the data point coordinates","text":"","category":"section"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"Now that we've solved the SVM, we can compute the sensitivity of optimal values â€“ the separating hyperplane in our case â€“ with respect to perturbations of the problem data â€“ the data points â€“ using DiffOpt.","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"How does a change in coordinates of the data points, X, affects the position of the hyperplane? This is achieved by finding gradients of w, b with respect to X[i], 2D coordinates of the data points.","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"Begin differentiating the model. analogous to varying Î¸ in the expression:","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"y_i (w^T (X_i + theta) + b) ge 1 - xi_i","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"âˆ‡ = zeros(N)\ndX = zeros(N, D);\nfor i in 1:N\n    dX[i, :] = ones(D)  # set\n    for j in 1:N\n        MOI.set(\n            model,\n            DiffOpt.ForwardInConstraint(),\n            cons[j],\n            y[j] * dot(dX[j,:], index.(w)),\n        )\n    end\n    DiffOpt.forward(model)\n    dw = MOI.get.(\n        model,\n        DiffOpt.ForwardOutVariablePrimal(),\n        w,\n    )\n    db = MOI.get(\n        model,\n        DiffOpt.ForwardOutVariablePrimal(),\n        b,\n    )\n    âˆ‡[i] = norm(dw) + norm(db)\n    dX[i, :] = zeros(D)  # reset the change made at the beginning of the loop\nend\n\nnormalize!(âˆ‡);\nnothing #hide","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"We can visualize the separating hyperplane sensitivity with respect to the data points. Note that the norm of the gradients are normalized and all the small numbers were converted into 1/10 of the largest value to show all the points of the set.","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"p3 = Plots.scatter(\n    X[:,1], X[:,2],\n    color = [yi > 0 ? :red : :blue for yi in y], label = \"\",\n    markersize = 20 * max.(âˆ‡, 0.1 * maximum(âˆ‡)),\n)\nPlots.yaxis!(p3, (-2, 4.5))\nPlots.plot!(p3, svm_x, svm_y, label = \"\", width=3)","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"","category":"page"},{"location":"examples/sensitivity-analysis-svm/","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"EditURL = \"https://github.com/jump-dev/DiffOpt.jl/blob/master/docs/src/examples/matrix-inversion-manual.jl\"","category":"page"},{"location":"examples/matrix-inversion-manual/#Differentiating-a-QP-wrt-a-single-variable","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"","category":"section"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"(Image: ) (Image: )","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Consider the quadratic program","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"beginsplit\nbeginarray ll\nmboxminimize  frac12 x^T Q x + q^T x \nmboxsubject to  G x leq h x in mathcalR^2 \nendarray\nendsplit","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"where Q, q, G are fixed and h is the single parameter.","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"In this example, we'll try to differentiate the QP wrt h, by finding its jacobian by hand (using Eqn (6) of QPTH article) and compare the results:","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Manual compuation\nUsing JuMP and DiffOpt","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Assuming","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Q = [[4, 1], [1, 2]]\nq = [1, 1]\nG = [1, 1]","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"and begining with a starting value of h=-1","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"few values just for reference","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"variable optimal value note\nx* [-0.25; -0.75] Primal optimal\nðœ†âˆ— -0.75 Dual optimal","category":"page"},{"location":"examples/matrix-inversion-manual/#Finding-Jacobian-using-matrix-inversion","page":"Differentiating a QP wrt a single variable","title":"Finding Jacobian using matrix inversion","text":"","category":"section"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Lets formulate Eqn (6) of QPTH article for our QP. If we assume h as the only parameter and Q,q,G as fixed problem data - also note that our QP doesn't involves Ax=b constraint - then Eqn (6) reduces to","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"begingather\n beginbmatrix\n     Q  g^T \n     lambda^* g  g x^* - h\n endbmatrix\n beginbmatrix\n     dx \n     d lambda\n endbmatrix\n =\n  beginbmatrix\n   0 \n   lambda^* dh\n   endbmatrix\nendgather","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Now to find the jacobians $ \\frac{\\partial x}{\\partial h}, \\frac{\\partial \\lambda}{\\partial h}$ we substitute dh = I = [1] and plug in values of Q,q,G to get","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"begingather\n beginbmatrix\n     4  1  1 \n     1  2  1 \n     -075  -075  0\n endbmatrix\n beginbmatrix\n     fracpartial x_1partial h \n     fracpartial x_2partial h \n     fracpartial lambdapartial h\n endbmatrix\n =\n  beginbmatrix\n   0 \n   0 \n   -075\n   endbmatrix\nendgather","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Upon solving using matrix inversion, the jacobian is","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"fracpartial x_1partial h = 025 fracpartial x_2partial h = 075 fracpartial lambdapartial h = -175","category":"page"},{"location":"examples/matrix-inversion-manual/#Finding-Jacobian-using-JuMP-and-DiffOpt","page":"Differentiating a QP wrt a single variable","title":"Finding Jacobian using JuMP and DiffOpt","text":"","category":"section"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"using JuMP\nimport DiffOpt\nimport Ipopt\n\nn = 2 # variable dimension\nm = 1; # no of inequality constraints\n\nQ = [4. 1.;1. 2.]\nq = [1.; 1.]\nG = [1. 1.;]\nh = [-1.;]   # initial values set","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Initialize empty model","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"model = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer))\nset_silent(model)","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Add the variables","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"@variable(model, x[1:2])","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Add the constraints.","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"@constraint(\n    model,\n    cons[j in 1:1],\n    sum(G[j, i] * x[i] for i in 1:2)  <= h[j]\n);\n\n@objective(\n    model,\n    Min,\n    1/2 * sum(Q[j, i] * x[i] *x[j] for i in 1:2, j in 1:2) +\n    sum(q[i] * x[i] for i in 1:2)\n)","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Solve problem","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"optimize!(model)","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"primal solution","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"value.(x)","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"dual solution","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"dual.(cons)","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"set sentivitity","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"MOI.set(\n    model,\n    DiffOpt.ForwardInConstraint(),\n    cons[1],\n    0.0 * index(x[1]) - 1.0,\n)","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Compute derivatives","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"DiffOpt.forward(model)","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"Query derivative","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"dx = MOI.get.(\n    model,\n    DiffOpt.ForwardOutVariablePrimal(),\n    x,\n)","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"","category":"page"},{"location":"examples/matrix-inversion-manual/","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"EditURL = \"https://github.com/jump-dev/DiffOpt.jl/blob/master/docs/src/examples/autotuning-ridge.jl\"","category":"page"},{"location":"examples/autotuning-ridge/#Auto-tuning-Hyperparameters","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"","category":"section"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"(Image: ) (Image: )","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"This example shows how to learn a hyperparameter in Ridge Regression using a gradient descent routine. Let the regularized regression problem be formulated as:","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"beginequation\nmin_w quad frac12nd sum_i=1^n (w^T x_i - y_i)^2 + fracalpha2d  w _2^2\nendequation","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"where","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"x, y are the data points\nw are the learned weights\nÎ± is the hyperparameter acting on regularization.","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"The main optimization model will be formulated with JuMP. Using the gradient of the optimal weights with respect to the regularization parameters computed with DiffOpt, we can perform a gradient descent on top of the inner model to minimize the test loss.","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"This tutorial uses the following packages","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"using JuMP     # The mathematical programming modelling language\nimport DiffOpt # JuMP extension for differentiable optimization\nimport OSQP    # Optimization solver that handles quadratic programs\nimport Plots   # Graphing tool\nimport LinearAlgebra: norm, dot\nimport Random","category":"page"},{"location":"examples/autotuning-ridge/#Generating-a-noisy-regression-dataset","page":"Auto-tuning Hyperparameters","title":"Generating a noisy regression dataset","text":"","category":"section"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Random.seed!(42)\n\nN = 100\nD = 20\nnoise = 5\n\nw_real = 10 * randn(D)\nX = 10 * randn(N, D)\ny = X * w_real + noise * randn(N)\nl = N Ã· 2  # test train split\n\nX_train = X[1:l, :]\nX_test  = X[l+1:N, :]\ny_train = y[1:l]\ny_test  = y[l+1:N];\nnothing #hide","category":"page"},{"location":"examples/autotuning-ridge/#Defining-the-regression-problem","page":"Auto-tuning Hyperparameters","title":"Defining the regression problem","text":"","category":"section"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"We implement the regularized regression problem as a function taking the problem data, building a JuMP model and solving it.","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"function fit_ridge(model, X, y, Î±)\n    JuMP.empty!(model)\n    set_silent(model)\n    N, D = size(X)\n    @variable(model, w[1:D])\n    err_term = X * w - y\n    @objective(\n        model,\n        Min,\n        dot(err_term, err_term) / (2 * N * D) + Î± * dot(w, w) / (2 * D),\n    )\n    optimize!(model)\n    @assert termination_status(model) == MOI.OPTIMAL\n    return w\nend","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"We can solve the problem for several values of Î± to visualize the effect of regularization on the testing and training loss.","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Î±s = 0.00:0.01:0.50\nmse_test = Float64[]\nmse_train = Float64[]\nmodel = Model(() -> DiffOpt.diff_optimizer(OSQP.Optimizer))\n(Ntest, D) = size(X_test)\n(Ntrain, D) = size(X_train)\nfor Î± in Î±s\n    w = fit_ridge(model, X_train, y_train, Î±)\n    wÌ‚ = value.(w)\n    yÌ‚_test = X_test * wÌ‚\n    yÌ‚_train = X_train * wÌ‚\n    push!(mse_test, norm(yÌ‚_test - y_test)^2 / (2 * Ntest * D))\n    push!(mse_train, norm(yÌ‚_train - y_train)^2 / (2 * Ntrain * D))\nend","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Visualize the Mean Score Error metric","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Plots.plot(\n    Î±s, mse_test ./ sum(mse_test),\n    label=\"MSE test\", xaxis = \"Î±\", yaxis=\"MSE\", legend=(0.8, 0.2)\n)\nPlots.plot!(\n    Î±s, mse_train ./ sum(mse_train),\n    label=\"MSE train\"\n)\nPlots.title!(\"Normalized MSE on training and testing sets\")","category":"page"},{"location":"examples/autotuning-ridge/#Leveraging-differentiable-optimization:-computing-the-derivative-of-the-solution","page":"Auto-tuning Hyperparameters","title":"Leveraging differentiable optimization: computing the derivative of the solution","text":"","category":"section"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Using DiffOpt, we can compute âˆ‚w_i/âˆ‚Î±, the derivative of the learned solution Ì‚w w.r.t. the regularization parameter.","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"function compute_dw_dÎ±(model, w)\n    D = length(w)\n    dw_dÎ± = zeros(D)\n    MOI.set(\n        model,\n        DiffOpt.ForwardInObjective(),\n        dot(w, w)  / (2 * D),\n    )\n    DiffOpt.forward(model)\n    for i in 1:D\n        dw_dÎ±[i] = MOI.get(\n            model,\n            DiffOpt.ForwardOutVariablePrimal(),\n            w[i],\n        )\n    end\n    return dw_dÎ±\nend","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Using âˆ‚w_i/âˆ‚Î± computed with compute_dw_dÎ±, we can compute the derivative of the test loss w.r.t. the parameter Î± by composing derivatives.","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"function d_testloss_dÎ±(model, X_test, y_test, w, wÌ‚)\n    N, D = size(X_test)\n    dw_dÎ± = compute_dw_dÎ±(model, w)\n    err_term = X_test * wÌ‚ - y_test\n    return sum(eachindex(err_term)) do i\n        dot(X_test[i,:], dw_dÎ±) * err_term[i]\n    end / (N * D)\nend","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"We can define a meta-optimizer function performing gradient descent on the test loss w.r.t. the regularization parameter.","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"function descent(Î±0, max_iters=100; fixed_step = 0.01, grad_tol=1e-3)\n    Î±_s = Float64[]\n    âˆ‚Î±_s = Float64[]\n    test_loss = Float64[]\n    Î± = Î±0\n    N, D = size(X_test)\n    model = Model(() -> DiffOpt.diff_optimizer(OSQP.Optimizer))\n    for iter in 1:max_iters\n        w = fit_ridge(model, X_train, y_train, Î±)\n        wÌ‚ = value.(w)\n        err_term = X_test * wÌ‚ - y_test\n        âˆ‚Î± = d_testloss_dÎ±(model, X_test, y_test, w, wÌ‚)\n        push!(Î±_s, Î±)\n        push!(âˆ‚Î±_s, âˆ‚Î±)\n        push!(test_loss, norm(err_term)^2 / (2 * N * D))\n        Î± -= fixed_step * âˆ‚Î±\n        if abs(âˆ‚Î±) â‰¤ grad_tol\n            break\n        end\n    end\n    return Î±_s, âˆ‚Î±_s, test_loss\nend\n\nÎ±Ì„, âˆ‚Î±Ì„, mseÌ„ = descent(0.10, 500)\niters = 1:length(Î±Ì„);\nnothing #hide","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Visualize gradient descent and convergence","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Plots.plot(\n    Î±s, mse_test,\n    label=\"MSE test\", xaxis = (\"Î±\"), legend=:topleft\n)\nPlots.plot!(Î±Ì„, mseÌ„, label=\"learned Î±\", lw = 2)\nPlots.title!(\"Regularizer learning\")","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Visualize the convergence of Î± to its optimal value","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Plots.plot(\n    iters, Î±Ì„, label = nothing, color = :blue,\n    xaxis = (\"Iterations\"), legend=:bottom,\n    title = \"Convergence of Î±\"\n)","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Visualize the convergence of the objective function","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Plots.plot(\n    iters, mseÌ„, label = nothing, color = :red,\n    xaxis = (\"Iterations\"), legend=:bottom,\n    title = \"Convergence of MSE\"\n)","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Visualize the convergence of the derivative to zero","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"Plots.plot(\n    iters, âˆ‚Î±Ì„, label = nothing, color = :green,\n    xaxis = (\"Iterations\"), legend=:bottom,\n    title = \"Convergence of âˆ‚Î±\"\n)","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"","category":"page"},{"location":"examples/autotuning-ridge/","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"This page was generated using Literate.jl.","category":"page"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/","page":"Reference","title":"Reference","text":"","category":"page"},{"location":"reference/","page":"Reference","title":"Reference","text":"Modules = [DiffOpt]","category":"page"},{"location":"reference/#DiffOpt.AbstractLazyScalarFunction","page":"Reference","title":"DiffOpt.AbstractLazyScalarFunction","text":"abstract type AbstractLazyScalarFunction <: MOI.AbstractScalarFunction end\n\nSubtype of MOI.AbstractScalarFunction that is not a standard MOI scalar function but can be converted to one using standard_form.\n\nThe function can also be inspected lazily using JuMP.coefficient or quad_sym_half.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.BackwardInVariablePrimal","page":"Reference","title":"DiffOpt.BackwardInVariablePrimal","text":"BackwardInVariablePrimal <: MOI.AbstractVariableAttribute\n\nA MOI.AbstractVariableAttribute to set input data to backward differentiation, that is, problem solution.\n\nFor instance, to set the tangent of the variable of index vi, do the following:\n\nMOI.set(model, DiffOpt.BackwardInVariablePrimal(), x)\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.BackwardOutConstraint","page":"Reference","title":"DiffOpt.BackwardOutConstraint","text":"BackwardOutConstraint\n\nAn MOI.AbstractConstraintAttribute to get output data to backward differentiation, that is, problem input data.\n\nFor instance, if the following returns x + 2y + 5, it means that the tangent has coordinate 1 for the coefficient of x, coordinate 2 for the coefficient of y and 5 for the function constant. If the constraint is of the form func == constant or func <= constant, the tangent for the constant on the right-hand side is -5.\n\nMOI.get(model, DiffOpt.BackwardOutConstraint(), ci)\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.BackwardOutObjective","page":"Reference","title":"DiffOpt.BackwardOutObjective","text":"BackwardOutObjective <: MOI.AbstractModelAttribute\n\nA MOI.AbstractModelAttribute to get output data to backward differentiation, that is, problem input data.\n\nFor instance, to get the tangent of the objective function corresponding to the tangent given to BackwardInVariablePrimal, do the following:\n\nfunc = MOI.get(model, DiffOpt.BackwardOutObjective)\n\nThen, to get the sensitivity of the linear term with variable x, do\n\nJuMP.coefficient(func, x)\n\nTo get the sensitivity with respect to the quadratic term with variables x and y, do either\n\nJuMP.coefficient(func, x, y)\n\nor\n\nDiffOpt.quad_sym_half(func, x, y)\n\nwarning: Warning\nThese two lines are not equivalent in case x == y, see quad_sym_half for the details on the difference between these two functions.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ForwardInConstraint","page":"Reference","title":"DiffOpt.ForwardInConstraint","text":"ForwardInConstraint <: MOI.AbstractConstraintAttribute\n\nA MOI.AbstractConstraintAttribute to set input data to forward differentiation, that is, problem input data.\n\nFor instance, if the scalar constraint of index ci contains Î¸ * (x + 2y) <= 5Î¸, for the purpose of computing the derivative with respect to Î¸, the following should be set:\n\nMOI.set(model, DiffOpt.ForwardInConstraint(), ci, 1.0 * x + 2.0 * y - 5.0)\n\nNote that we use -5 as the ForwardInConstraint sets the tangent of the ConstraintFunction so we consider the expression Î¸ * (x + 2y - 5).\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ForwardInObjective","page":"Reference","title":"DiffOpt.ForwardInObjective","text":"ForwardInObjective <: MOI.AbstractModelAttribute\n\nA MOI.AbstractModelAttribute to set input data to forward differentiation, that is, problem input data. The possible values are any MOI.AbstractScalarFunction. A MOI.ScalarQuadraticFunction can only be used in linearly constrained quadratic models.\n\nFor instance, if the objective contains Î¸ * (x + 2y), for the purpose of computing the derivative with respect to Î¸, the following should be set:\n\nMOI.set(model, DiffOpt.ForwardInObjective(), 1.0 * x + 2.0 * y)\n\nwhere x and y are the relevant MOI.VariableIndex.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ForwardOutVariablePrimal","page":"Reference","title":"DiffOpt.ForwardOutVariablePrimal","text":"ForwardOutVariablePrimal <: MOI.AbstractVariableAttribute\n\nA MOI.AbstractVariableAttribute to get output data from forward differentiation, that is, problem solution.\n\nFor instance, to get the tangent of the variable of index vi corresponding to the tangents given to ForwardInObjective and ForwardInConstraint, do the following:\n\nMOI.get(model, DiffOpt.ForwardOutVariablePrimal(), vi)\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.IndexMappedFunction","page":"Reference","title":"DiffOpt.IndexMappedFunction","text":"IndexMappedFunction{F<:MOI.AbstractFunction} <: AbstractLazyScalarFunction\n\nLazily represents the function MOI.Utilities.map_indices(index_map, DiffOpt.standard_form(func)).\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.MOItoJuMP","page":"Reference","title":"DiffOpt.MOItoJuMP","text":"MOItoJuMP{F<:MOI.AbstractScalarFunction} <: JuMP.AbstractJuMPScalar\n\nLazily represents the function JuMP.jump_function(model, DiffOpt.standard_form(func)).\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.MatrixScalarQuadraticFunction","page":"Reference","title":"DiffOpt.MatrixScalarQuadraticFunction","text":"struct MatrixScalarQuadraticFunction{T, VT, MT} <: MOI.AbstractScalarFunction\n    affine::VectorScalarAffineFunction{T,VT}\n    terms::MT\nend\n\nRepresents the function x' * terms * x / 2 + affine as an MOI.AbstractScalarFunction where x[i] = MOI.VariableIndex(i). Use standard_form to convert it to a MOI.ScalarQuadraticFunction{T}.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.MatrixVectorAffineFunction","page":"Reference","title":"DiffOpt.MatrixVectorAffineFunction","text":"MatrixVectorAffineFunction{T, VT} <: MOI.AbstractVectorFunction\n\nRepresents the function terms * x + constant as an MOI.AbstractVectorFunction where x[i] = MOI.VariableIndex(i). Use standard_form to convert it to a MOI.VectorAffineFunction{T}.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ProductOfSets","page":"Reference","title":"DiffOpt.ProductOfSets","text":"ProductOfSets{T} <: MOI.Utilities.OrderedProductOfSets{T}\n\nThe MOI.Utilities.@product_of_sets macro requires to know the list of sets at compile time. In DiffOpt however, the list depends on what the user is going to use as set as DiffOpt supports any set as long as it implements the required function of MathOptSetDistances. For this type, the list of sets can be given a run-time.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ProgramClass","page":"Reference","title":"DiffOpt.ProgramClass","text":"ProgramClass <: MOI.AbstractOptimizerAttribute\n\nDetermines which program class to used from ProgramClassCode. The default is AUTOMATIC.\n\nOne important advantage of setting the class explicitly is that it will allow necessary bridges to be used. If the class is AUTOMATIC then DiffOpt.Optimizer will report that it supports both objective and constraints of the QP and CP classes. For instance, it will reports that is supports both quadratic objective and conic constraints. However, at the differentiation stage, we won't be able to differentiate since QP does not support conic constraints and CP does not support quadratic objective. On the other hand, if the ProgramClass is set to CONIC then DiffOpt.Optimizer will report that it does not support quadratic objective hence it will be bridged to second-order cone constraints and we will be able to use CP to differentiate.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ProgramClassCode","page":"Reference","title":"DiffOpt.ProgramClassCode","text":"@enum ProgramClassCode QUADRATIC CONIC AUTOMATIC\n\nProgram class used by DiffOpt. DiffOpt implements differentiation of two different program class:\n\nQuadratic Program (QP): quadratic objective and linear constraints and\nConic Program (CP): linear objective and conic constraints.\n\nAUTOMATIC which means that the class will be automatically selected given the problem data: if any constraint is conic, CP is used and QP is used otherwise. See ProgramClass.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ProgramClassUsed","page":"Reference","title":"DiffOpt.ProgramClassUsed","text":"ProgramClassUsed <: MOI.AbstractOptimizerAttribute\n\nProgram class actually used, same as ProgramClass except that it does not return AUTOMATIC but the class automatically chosen instead. This attribute is read-only, it cannot be set, set ProgramClass instead.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.VectorScalarAffineFunction","page":"Reference","title":"DiffOpt.VectorScalarAffineFunction","text":"VectorScalarAffineFunction{T, VT} <: MOI.AbstractScalarFunction\n\nRepresents the function x â‹… terms + constant as an MOI.AbstractScalarFunction where x[i] = MOI.VariableIndex(i). Use standard_form to convert it to a MOI.ScalarAffineFunction{T}.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.DÏ€-Union{Tuple{T}, Tuple{Vector{T}, MathOptInterface.ModelLike, DiffOpt.ProductOfSets, MathOptInterface.Utilities.IndexMap}} where T","page":"Reference","title":"DiffOpt.DÏ€","text":"DÏ€(v::Vector{Float64}, model, cones::ProductOfSets, index_map::MOIU.IndexMap)\n\nGiven a model, its cones and the index_map from the indices of model to the indices of cones, find the gradient of the projection of the vectors v of length equal to the number of rows in the conic form onto the cartesian product of the cones corresponding to these rows. For more info, refer to https://github.com/matbesancon/MathOptSetDistances.jl\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.backward-Tuple{DiffOpt.ConicDiff, DiffOpt.DiffInputCache}","page":"Reference","title":"DiffOpt.backward","text":"backward(model::ConicDiff)\n\nMethod to compute the product of the transpose of the derivative (Jacobian) at the conic program parameters A, b, c  to the perturbations dx, dy, ds. This is similar to backward.\n\nFor theoretical background, refer Section 3 of Differentiating Through a Cone Program, https://arxiv.org/abs/1904.09043\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.backward-Tuple{DiffOpt.Optimizer}","page":"Reference","title":"DiffOpt.backward","text":"backward(model::Optimizer)\n\nWrapper method for the backward pass. This method will consider as input a currently solved problem and differentials with respect to the solution set with the BackwardInVariablePrimal attribute. The output problem data differentials can be queried with the attributes BackwardOutObjective and BackwardOutConstraint.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.backward-Tuple{DiffOpt.QPDiff, DiffOpt.DiffInputCache}","page":"Reference","title":"DiffOpt.backward","text":"backward(model::QPDiff)\n\nMethod to differentiate optimal solution z and return product of jacobian matrices (dz / dQ, dz / dq, etc) with the backward pass vector dl / dz\n\nThe method computes the product of\n\njacobian of problem solution z* with respect to  problem parameters set with the BackwardInVariablePrimal\na backward pass vector dl / dz, where l can be a loss function\n\nNote that this method does not returns the actual jacobians.\n\nFor more info refer eqn(7) and eqn(8) of https://arxiv.org/pdf/1703.00443.pdf\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.create_LHS_matrix","page":"Reference","title":"DiffOpt.create_LHS_matrix","text":"create_LHS_matrix(z, Î», Q, G, h, A=nothing)\n\nInverse matrix specified on RHS of eqn(7) in https://arxiv.org/pdf/1703.00443.pdf\n\nHelper method while calling _backward_quad\n\n\n\n\n\n","category":"function"},{"location":"reference/#DiffOpt.diff_optimizer-Tuple{Any}","page":"Reference","title":"DiffOpt.diff_optimizer","text":"diff_optimizer(optimizer_constructor)::Optimizer\n\nCreates a DiffOpt.Optimizer, which is an MOI layer with an internal optimizer and other utility methods. Results (primal, dual and slack values) are obtained by querying the internal optimizer instantiated using the optimizer_constructor. These values are required for find jacobians with respect to problem data.\n\nOne define a differentiable model by using any solver of choice. Example:\n\njulia> import DiffOpt, GLPK\n\njulia> model = DiffOpt.diff_optimizer(GLPK.Optimizer)\njulia> model.add_variable(x)\njulia> model.add_constraint(...)\n\njulia> _backward_quad(model)  # for convex quadratic models\n\njulia> _backward_quad(model)  # for convex conic models\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.forward-Tuple{DiffOpt.ConicDiff, DiffOpt.DiffInputCache}","page":"Reference","title":"DiffOpt.forward","text":"forward(model::ConicDiff, input_cache::DiffInputCache)\n\nMethod to compute the product of the derivative (Jacobian) at the conic program parameters A, b, c  to the perturbations dA, db, dc. This is similar to forward.\n\nFor theoretical background, refer Section 3 of Differentiating Through a Cone Program, https://arxiv.org/abs/1904.09043\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.forward-Tuple{DiffOpt.Optimizer}","page":"Reference","title":"DiffOpt.forward","text":"forward(model::Optimizer)\n\nWrapper method for the forward pass. This method will consider as input a currently solved problem and differentials with respect to problem data set with the ForwardInObjective and  ForwardInConstraint attributes. The output solution differentials can be queried with the attribute ForwardOutVariablePrimal.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.forward-Tuple{DiffOpt.QPDiff, DiffOpt.DiffInputCache}","page":"Reference","title":"DiffOpt.forward","text":"forward(model::QPDiff)\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.get_problem_data-Tuple{MathOptInterface.AbstractOptimizer}","page":"Reference","title":"DiffOpt.get_problem_data","text":"get_problem_data(model::MOI.AbstractOptimizer)\n\nReturn problem parameters as matrices along with other program info such as number of constraints, variables, etc\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.map_rows-Tuple{Function, Any, DiffOpt.ProductOfSets, MathOptInterface.Utilities.IndexMap, Union{DiffOpt.Flattened, DiffOpt.Nested}}","page":"Reference","title":"DiffOpt.map_rows","text":"map_rows(f::Function, model, cones::ProductOfSets, index_map::MOIU.IndexMap, map_mode::Union{Nested{T}, Flattened{T}})\n\nGiven a model, its cones, the index_map from the indices of model to the indices of cones and map_mode of type Nested (resp. Flattened), return a Vector{T} of length equal to the number of cones (resp. rows) in the conic form where the value for the index (resp. rows) corresponding to each cone is equal to f(ci, r) where ci is the corresponding constraint index in model and r is a UnitRange of the corresponding rows in the conic form.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.quad_sym_half","page":"Reference","title":"DiffOpt.quad_sym_half","text":"quad_sym_half(func, vi1::MOI.VariableIndex, vi2::MOI.VariableIndex)\n\nReturn Q[i,j] = Q[j,i] where the quadratic terms of func is represented by x' Q x / 2 for a symmetric matrix Q where x[i] = vi1 and x[j] = vi2. Note that while this is equal to JuMP.coefficient(func, vi1, vi2) if vi1 != vi2, in the case vi1 == vi2, it is rather equal to 2JuMP.coefficient(func, vi1, vi2).\n\n\n\n\n\n","category":"function"},{"location":"reference/#DiffOpt.standard_form","page":"Reference","title":"DiffOpt.standard_form","text":"standard_form(func::AbstractLazyScalarFunction)\n\nConverts func to a standard MOI scalar function.\n\nstandard_form(func::MOItoJuMP)\n\nConverts func to a standard JuMP scalar function.\n\n\n\n\n\n","category":"function"},{"location":"reference/#DiffOpt.Ï€-Union{Tuple{T}, Tuple{Vector{T}, MathOptInterface.ModelLike, DiffOpt.ProductOfSets, MathOptInterface.Utilities.IndexMap}} where T","page":"Reference","title":"DiffOpt.Ï€","text":"Ï€(v::Vector{Float64}, model::MOI.ModelLike, cones::ProductOfSets, index_map::MOIU.IndexMap)\n\nGiven a model, its cones and the index_map from the indices of model to the indices of cones, find the projection of the vectors v of length equal to the number of rows in the conic form onto the cartesian product of the cones corresponding to these rows. For more info, refer to https://github.com/matbesancon/MathOptSetDistances.jl\n\n\n\n\n\n","category":"method"},{"location":"usage/#Usage","page":"Usage","title":"Usage","text":"","category":"section"},{"location":"usage/","page":"Usage","title":"Usage","text":"Create a differentiable model from existing optimizers","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"using JuMP\nimport DiffOpt\nimport SCS\n\nmodel = DiffOpt.diff_optimizer(SCS.Optimizer)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Update and solve the model ","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"x = MOI.add_variables(model, 2)\nc = MOI.add_constraint(model, ...)\n\nMOI.optimize!(model)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"Finally differentiate the model (primal and dual variables specifically) to obtain product of jacobians with respect to problem parameters and a backward pass vector. Currently DiffOpt supports two backends for differentiating a model:","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"To differentiate Convex Quadratic Program","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"beginalign*\n min_x in mathbbR^n  frac12 x^T Q x + q^T x   \n textst                A x = b        qquad         b in mathbbR^m \n                            G x leq h     qquad         h in mathbbR^p\nendalign*","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"we can use the backward method","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"MOI.set.(model,\n    DiffOpt.BackwardInVariablePrimal(), x, ones(2))\nDiffOpt.backward(model)\ngrad_obj = MOI.get(model, DiffOpt.BackwardOutObjective())\ngrad_con = MOI.get.(model, DiffOpt.BackwardOutConstraint(), c)","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"To differentiate convex conic program","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"beginalign*\n min_x in mathbbR^n  c^T x \n textst                A x + s = b  \n                            b in mathbbR^m  \n                            s in mathcalK\nendalign*","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"we can use the forward method with perturbations in matrices A, b, c","category":"page"},{"location":"usage/","page":"Usage","title":"Usage","text":"import LinearAlgebra: â‹…\nMOI.set(model, DiffOpt.ForwardInObjective(), ones(2) â‹… x)\nDiffOpt.forward(model)\ngrad_x = MOI.get.(model, DiffOpt.ForwardOutVariablePrimal(), x)","category":"page"},{"location":"#DiffOpt.jl","page":"Home","title":"DiffOpt.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DiffOpt.jl is a package for differentiating convex optimization program (JuMP.jl or MathOptInterface.jl models) with respect to program parameters. Note that this package does not contain any solver. This package has two major backends, available via backward and forward methods, to differentiate models (quadratic or conic) with optimal solutions.","category":"page"},{"location":"","page":"Home","title":"Home","text":"note: Note\nCurrently supports linear programs (LP), convex quadratic programs (QP) and convex conic programs (SDP, SOCP constraints only). ","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"DiffOpt can be installed through the Julia package manager:","category":"page"},{"location":"","page":"Home","title":"Home","text":"(v1.3) pkg> add https://github.com/jump-dev/DiffOpt.jl","category":"page"},{"location":"#Why-are-Differentiable-optimization-problems-important?","page":"Home","title":"Why are Differentiable optimization problems important?","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Differentiable optimization is a promising field of convex optimization and has many potential applications in game theory, control theory and machine learning (specifically deep learning - refer this video for more). Recent work has shown how to differentiate specific subclasses of convex optimization problems. But several applications remain unexplored (refer section 8 of this really good thesis). With the help of automatic differentiation, differentiable optimization can have a significant impact on creating end-to-end differentiable systems to model neural networks, stochastic processes, or a game.","category":"page"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Contributions to this package are more than welcome, if you find a bug or have any suggestions for the documentation please post it on the github issue tracker.","category":"page"},{"location":"","page":"Home","title":"Home","text":"When contributing please note that the package follows the JuMP style guide","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"EditURL = \"https://github.com/jump-dev/DiffOpt.jl/blob/master/docs/src/examples/chainrules_unit.jl\"","category":"page"},{"location":"examples/chainrules_unit/#ChainRules-integration-demo:-Relaxed-Unit-Commitment","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"","category":"section"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"(Image: ) (Image: )","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"In this example, we will demonstrate the integration of DiffOpt with ChainRulesCore.jl, the library allowing the definition of derivatives for functions that can then be used by automatic differentiation systems.","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"using JuMP\nimport DiffOpt\nimport Plots\nimport LinearAlgebra: â‹…\nimport GLPK\nimport ChainRulesCore","category":"page"},{"location":"examples/chainrules_unit/#Unit-commitment-problem","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Unit commitment problem","text":"","category":"section"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"We will consider a unit commitment problem, finding the cost-minimizing activation of generation units in a power network over multiple time periods. The considered constraints include:","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"Demand satisfaction of several loads\nRamping constraints\nGeneration limits.","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"The decisions are:","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"u_it in 01: activation of the i-th unit at time t\np_it: power output of the i-th unit at time t.","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"DiffOpt handles convex optimization problems only, we therefore relax the domain of the u_it variables to left01right.","category":"page"},{"location":"examples/chainrules_unit/#Primal-UC-problem","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Primal UC problem","text":"","category":"section"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"ChainRules defines the differentiation of functions. The actual function that is differentiated in the context of DiffOpt is the solution map taking in input the problem parameters and returning the solution.","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"function unit_commitment(\n        load1_demand, load2_demand, gen_costs, noload_costs;\n        model = Model(GLPK.Optimizer), silent=false)\n    MOI.set(model, MOI.Silent(), silent)\n\n    # Problem data\n    units = [1, 2] # Generator identifiers\n    load_names = [\"Load1\", \"Load2\"] # Load identifiers\n    n_periods = 4 # Number of time periods\n    Pmin = Dict(1 => fill(0.5, n_periods), 2 => fill(0.5, n_periods)) # Minimum power output (pu)\n    Pmax = Dict(1 => fill(3.0, n_periods), 2 => fill(3.0, n_periods)) # Maximum power output (pu)\n    RR = Dict(1 => 0.25, 2 => 0.25) # Ramp rates (pu/min)\n    P0 = Dict(1 => 0.0, 2 => 0.0) # Initial power output (pu)\n    D = Dict(\"Load1\" => load1_demand, \"Load2\" => load2_demand) # Demand (pu)\n    Cp = Dict(1 => gen_costs[1], 2 => gen_costs[2]) # Generation cost coefficient ($/pu)\n    Cnl = Dict(1 => noload_costs[1], 2 => noload_costs[2]) # No-load cost ($)\n\n    # Variables\n    # Note: u represents the activation of generation units.\n    # Would be binary in the typical UC problem, relaxed here to u âˆˆ [0,1]\n    # for a linear relaxation.\n    @variable(model, 0 <= u[g in units, t in 1:n_periods] <= 1) # Commitment\n    @variable(model, p[g in units, t in 1:n_periods] >= 0) # Power output (pu)\n\n    # Constraints\n\n    # Energy balance\n    @constraint(\n        model,\n        energy_balance_cons[t in 1:n_periods],\n        sum(p[g, t] for g in units) == sum(D[l][t] for l in load_names),\n    )\n\n    # Generation limits\n    @constraint(model, [g in units, t in 1:n_periods], Pmin[g][t] * u[g, t] <= p[g, t])\n    @constraint(model, [g in units, t in 1:n_periods], p[g, t] <= Pmax[g][t] * u[g, t])\n\n    # Ramp rates\n    @constraint(model, [g in units, t in 2:n_periods], p[g, t] - p[g, t - 1] <= 60 * RR[g])\n    @constraint(model, [g in units], p[g, 1] - P0[g] <= 60 * RR[g])\n    @constraint(model, [g in units, t in 2:n_periods], p[g, t - 1] - p[g, t] <= 60 * RR[g])\n    @constraint(model, [g in units], P0[g] - p[g, 1] <= 60 * RR[g])\n\n    # Objective\n    @objective(\n        model,\n        Min,\n        sum((Cp[g] * p[g, t]) + (Cnl[g] * u[g, t]) for g in units, t in 1:n_periods),\n    )\n\n    optimize!(model)\n    # asserting finite optimal value\n    @assert termination_status(model) == MOI.OPTIMAL\n    # converting to dense matrix\n    return JuMP.value.(p.data)\nend\n\nm = Model(GLPK.Optimizer)\n@show unit_commitment(\n    [1.0, 1.2, 1.4, 1.6], [1.0, 1.2, 1.4, 1.6],\n    [1000.0, 1500.0], [500.0, 1000.0],\n    model=m, silent=true\n)","category":"page"},{"location":"examples/chainrules_unit/#Perturbation-of-a-single-input-parameter","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Perturbation of a single input parameter","text":"","category":"section"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"Let us vary the demand at the second time frame on both loads:","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"demand_values = 0.05:0.05:3.0\npvalues = map(demand_values) do di\n    unit_commitment(\n        [1.0, di, 1.4, 1.6], [1.0, di, 1.4, 1.6],\n        [1000.0, 1500.0], [500.0, 1000.0],\n        silent=true,\n    )\nend\npflat = [getindex.(pvalues, i) for i in eachindex(pvalues[1])];\nnothing #hide","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"The influence of this variation of the demand is piecewise linear on the generation at different time frames:","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"Plots.scatter(demand_values, pflat, xaxis = (\"Demand\"), yaxis = (\"Generation\"))\nPlots.title!(\"Different time frames and generators\")\nPlots.xlims!(0.0, 3.5)","category":"page"},{"location":"examples/chainrules_unit/#Forward-Differentiation","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Forward Differentiation","text":"","category":"section"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"Forward differentiation rule for the solution map of the unit commitment problem. It takes as arguments:","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"the perturbations on the input parameters\nthe differentiated function\nthe primal values of the input parameters,","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"and returns a tuple (primal_output, perturbations), the main primal result and the perturbation propagated to this result:","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"function ChainRulesCore.frule(\n        (_, Î”load1_demand, Î”load2_demand, Î”gen_costs, Î”noload_costs),\n        ::typeof(unit_commitment),\n        load1_demand, load2_demand, gen_costs, noload_costs;\n        optimizer=GLPK.Optimizer,\n        )\n    # creating the UC model with a DiffOpt optimizer wrapper around GLPK\n    model = Model(() -> DiffOpt.diff_optimizer(optimizer))\n    # building and solving the main model\n    pv = unit_commitment(\n        load1_demand, load2_demand, gen_costs, noload_costs, model=model)\n    energy_balance_cons = model[:energy_balance_cons]\n\n    # Setting some perturbation of the energy balance constraints\n    # Perturbations are set as MOI functions\n    Î”energy_balance = [\n        convert(MOI.ScalarAffineFunction{Float64}, d1 + d2)\n        for (d1, d2) in zip(Î”load1_demand, Î”load2_demand)\n    ]\n    MOI.set.(\n        model,\n        DiffOpt.ForwardInConstraint(), energy_balance_cons,\n        Î”energy_balance,\n    )\n\n    p = model[:p]\n    u = model[:u]\n\n    # setting the perturbation of the linear objective\n    Î”obj = sum(Î”gen_costs â‹… p[:,t] + Î”noload_costs â‹… u[:,t] for t in size(p, 2))\n    MOI.set(model, DiffOpt.ForwardInObjective(), Î”obj)\n    DiffOpt.forward(JuMP.backend(model))\n    # querying the corresponding perturbation of the decision\n    Î”p = MOI.get.(model, DiffOpt.ForwardOutVariablePrimal(), p)\n    return (pv, Î”p.data)\nend","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"We can now compute the perturbation of the output powers Î”pv for a perturbation of the first load demand at time 2:","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"load1_demand = [1.0, 1.0, 1.4, 1.6]\nload2_demand = [1.0, 1.0, 1.4, 1.6]\ngen_costs = [1000.0, 1500.0]\nnoload_costs = [500.0, 1000.0];\nnothing #hide","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"all input perturbations are 0 except first load at time 2","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"Î”load1_demand = 0 * load1_demand\nÎ”load1_demand[2] = 1.0\nÎ”load2_demand = 0 * load2_demand\nÎ”gen_costs = 0 * gen_costs\nÎ”noload_costs = 0 * noload_costs\n(pv, Î”pv) = ChainRulesCore.frule(\n    (nothing, Î”load1_demand, Î”load2_demand, Î”gen_costs, Î”noload_costs),\n    unit_commitment,\n    load1_demand, load2_demand, gen_costs, noload_costs,\n)\n\nÎ”pv","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"The result matches what we observe in the previous figure: the generation of the first generator at the second time frame (third element on the plot).","category":"page"},{"location":"examples/chainrules_unit/#Reverse-mode-differentiation-of-the-solution-map","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Reverse-mode differentiation of the solution map","text":"","category":"section"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"The rrule returns the primal and a pullback. The pullback takes a seed for the optimal solution Ì„p and returns derivatives with respect to each input parameter of the function.","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"function ChainRulesCore.rrule(\n        ::typeof(unit_commitment),\n        load1_demand, load2_demand, gen_costs, noload_costs;\n        optimizer=GLPK.Optimizer,\n        silent=false)\n    model = Model(() -> DiffOpt.diff_optimizer(optimizer))\n    # solve the forward UC problem\n    pv = unit_commitment(\n        load1_demand, load2_demand, gen_costs, noload_costs,\n        model=model, silent=silent)\n    function pullback_unit_commitment(pb)\n        p = model[:p]\n        u = model[:u]\n        energy_balance_cons = model[:energy_balance_cons]\n\n        MOI.set.(model, DiffOpt.BackwardInVariablePrimal(), p, pb)\n        DiffOpt.backward(JuMP.backend(model))\n\n        obj = MOI.get(model, DiffOpt.BackwardOutObjective())\n\n        # computing derivative wrt linear objective costs\n        dgen_costs = similar(gen_costs)\n        dgen_costs[1] = sum(JuMP.coefficient.(obj, p[1,:]))\n        dgen_costs[2] = sum(JuMP.coefficient.(obj, p[2,:]))\n\n        dnoload_costs = similar(noload_costs)\n        dnoload_costs[1] = sum(JuMP.coefficient.(obj, u[1,:]))\n        dnoload_costs[2] = sum(JuMP.coefficient.(obj, u[2,:]))\n\n        # computing derivative wrt constraint constant\n        dload1_demand = JuMP.constant.(\n            MOI.get.(model, DiffOpt.BackwardOutConstraint(), energy_balance_cons))\n        dload2_demand = copy(dload1_demand)\n        return (dload1_demand, dload2_demand, dgen_costs, dnoload_costs)\n    end\n    return (pv, pullback_unit_commitment)\nend","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"We can set a seed of one on the power of the first generator at the second time frame and zero for all other parts of the solution:","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"(pv, pullback_unit_commitment) = ChainRulesCore.rrule(\n    unit_commitment,\n    load1_demand, load2_demand, gen_costs, noload_costs,\n    optimizer=GLPK.Optimizer,\n    silent=true,\n)\ndpv = 0 * pv\ndpv[1,2] = 1\ndargs = pullback_unit_commitment(dpv)\n(dload1_demand, dload2_demand, dgen_costs, dnoload_costs) = dargs;\nnothing #hide","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"The sensitivities with respect to the load demands are:","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"dload1_demand","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"and:","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"dload2_demand","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"The sensitivity of the generation is propagated to the sensitivity of both loads at the second time frame.","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"This example integrating ChainRules was designed with support from Invenia Technical Computing.","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"","category":"page"},{"location":"examples/chainrules_unit/","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"This page was generated using Literate.jl.","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"EditURL = \"https://github.com/jump-dev/DiffOpt.jl/blob/master/docs/src/examples/custom-relu.jl\"","category":"page"},{"location":"examples/custom-relu/#Custom-ReLU-layer","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"","category":"section"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"(Image: ) (Image: )","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"We demonstrate how DiffOpt can be used to generate a simple neural network unit - the ReLU layer. A neural network is created using Flux.jl which is trained on the MNIST dataset.","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"This tutorial uses the following packages","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"using JuMP\nimport DiffOpt\nimport OSQP\nimport ChainRulesCore\nimport Flux\nimport Statistics\nimport Base.Iterators: repeated","category":"page"},{"location":"examples/custom-relu/#The-ReLU-and-its-derivative","page":"Custom ReLU layer","title":"The ReLU and its derivative","text":"","category":"section"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"Define a relu through an optimization problem solved by a quadratic solver. Return the solution of the problem.","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"function matrix_relu(\n    y::AbstractArray{T};\n    model = Model(() -> DiffOpt.diff_optimizer(OSQP.Optimizer))\n) where T\n    _x = zeros(size(y))\n    N = length(y[:, 1])\n    empty!(model)\n    set_silent(model)\n    @variable(model, x[1:N] >= 0)\n    for i in 1:size(y)[2]\n        @objective(\n            model,\n            Min,\n            x'x -2x'y[:, i]\n        )\n        optimize!(model)\n        _x[:, i] = value.(x)\n    end\n    return _x\nend","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"Define the backward differentiation rule, for the function we defined above.","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"function ChainRulesCore.rrule(\n    ::typeof(matrix_relu),\n    y::AbstractArray{T};\n    model = Model(() -> DiffOpt.diff_optimizer(OSQP.Optimizer))\n) where T\n    pv = matrix_relu(y, model = model)\n    function pullback_matrix_relu(dx)\n        x = model[:x]\n        dy = zeros(T, size(dx))\n        for i in 1:size(y)[2]\n            MOI.set.(\n                model,\n                DiffOpt.BackwardInVariablePrimal(),\n                x,\n                dx[:, i]\n            ) # set sensitivities\n            DiffOpt.backward(model) # compute grad\n            obj_exp = MOI.get(\n                model,\n                DiffOpt.BackwardOutObjective()\n            ) # return grdiente wrt objective function parameters\n            dy[:, i] = JuMP.coefficient.(obj_exp, x) # coeff of `x` in -2x'y\n            dy[:, i] = -2 * dy[:, i]\n        end\n        return (ChainRulesCore.NoTangent(), dy,)\n    end\n    return pv, pullback_matrix_relu\nend","category":"page"},{"location":"examples/custom-relu/#prepare-data","page":"Custom ReLU layer","title":"prepare data","text":"","category":"section"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"imgs = Flux.Data.MNIST.images()\nlabels = Flux.Data.MNIST.labels();\nnothing #hide","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"Preprocessing","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"X = hcat(float.(reshape.(imgs, :))...) #stack all the images\nY = Flux.onehotbatch(labels, 0:9); # just a common way to encode categorical variables\n\nN = 1000\n\ntrain_X = X[:, 1:N]\ntrain_Y = Y[:, 1:N]\n\ntest_X = hcat(float.(reshape.(Flux.Data.MNIST.images(:test), :))...)\ntest_Y = Flux.onehotbatch(Flux.Data.MNIST.labels(:test), 0:9);\nnothing #hide","category":"page"},{"location":"examples/custom-relu/#Define-the-Network","page":"Custom ReLU layer","title":"Define the Network","text":"","category":"section"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"Network structure","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"inner = 15\n\nm = Flux.Chain(\n    Flux.Dense(784, inner), #784 being image linear dimension (28 x 28)\n    matrix_relu,\n    Flux.Dense(inner, 10), # 10 beinf the number of outcomes (0 to 9)\n    Flux.softmax,\n)","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"Define input data The original data is repeated epochs times because Flux.train! only loops through the data set once","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"epochs = 5\n\ndataset = repeated((train_X, train_Y), epochs);\nnothing #hide","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"Parameters for the network training","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"custom_loss(x, y) = Flux.crossentropy(m(x), y) # training loss function\nopt = Flux.ADAM(); # stochastic gradient descent variant to optimize weights of the neral network\nevalcb = () -> @show(custom_loss(X, Y)); # callback to show loss\nnothing #hide","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"Train to optimize network parameters","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"@time Flux.train!(custom_loss, Flux.params(m), dataset, opt, cb = Flux.throttle(evalcb, 5));\nnothing #hide","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"Although our custom implementation takes time, it is able to reach similar accuracy as the usual ReLU function implementation.","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"accuracy(x, y) = Statistics.mean(Flux.onecold(m(x)) .== Flux.onecold(y)); # average of correct guesses\nnothing #hide","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"Train accuracy","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"accuracy(train_X, train_Y)","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"Test accuracy","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"accuracy(test_X, test_Y)","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"Note that the accuracy is low due to simplified training. It is possible to increase the number of samples N, the number of epochs epoch and teh conectivity inner.","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"","category":"page"},{"location":"examples/custom-relu/","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"This page was generated using Literate.jl.","category":"page"}]
}
