var documenterSearchIndex = {"docs":
[{"location":"examples/custom-relu_new/#Custom-ReLU-layer","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"(Image: )\n\nWe demonstrate how DiffOpt can be used to generate a simple neural network unit - the ReLU layer. A neural network is created using Flux.jl and trained on the MNIST dataset.\n\nThis tutorial uses the following packages\n\nusing JuMP\nimport DiffOpt\nimport Ipopt\nimport ChainRulesCore\nimport Flux\nimport MLDatasets\nimport Statistics\nimport Base.Iterators: repeated\nusing LinearAlgebra","category":"section"},{"location":"examples/custom-relu_new/#The-ReLU-and-its-derivative","page":"Custom ReLU layer","title":"The ReLU and its derivative","text":"Define a relu through an optimization problem solved by a quadratic solver. Return the solution of the problem. TODO: use HiGHS\n\nfunction matrix_relu(\n    y_data::Matrix;\n    model = DiffOpt.nonlinear_diff_model(Ipopt.Optimizer),\n)\n    layer_size, batch_size = size(y_data)\n    empty!(model)\n    set_silent(model)\n    @variable(model, x[1:layer_size, 1:batch_size] >= 0)\n    @variable(model, y[1:layer_size, 1:batch_size] in Parameter.(y_data))\n    @objective(model, Min, x[:]'x[:] - 2y[:]'x[:])\n    optimize!(model)\n    return Float32.(value.(x))\nend\n\nDefine the reverse differentiation rule, for the function we defined above.\n\nfunction ChainRulesCore.rrule(\n    ::typeof(matrix_relu),\n    y_data::Matrix{T},\n) where {T}\n    model = DiffOpt.nonlinear_diff_model(Ipopt.Optimizer)\n    pv = matrix_relu(y_data; model = model)\n    function pullback_matrix_relu(dl_dx)\n        # some value from the backpropagation (e.g., loss) is denoted by `l`\n        # so `dl_dy` is the derivative of `l` wrt `y`\n        x = model[:x]::Matrix{JuMP.VariableRef} # load decision variable `x` into scope\n        y = model[:y]::Matrix{JuMP.VariableRef} # load parameter variable `y` into scope\n        # set sensitivities (dl/dx)\n        for i in eachindex(x)\n            DiffOpt.set_reverse_variable(model, x[i], dl_dx[i])\n        end\n        # compute grad (dx/dy)\n        DiffOpt.reverse_differentiate!(model)\n        # return gradient (dl/dy = dl/dx * dx/dy)\n        dl_dy = DiffOpt.get_reverse_parameter.(model, y)\n        return (ChainRulesCore.NoTangent(), dl_dy)\n    end\n    return pv, pullback_matrix_relu\nend\n\nFor more details about backpropagation, visit Introduction, ChainRulesCore.jl.","category":"section"},{"location":"examples/custom-relu_new/#Define-the-network","page":"Custom ReLU layer","title":"Define the network","text":"layer_size = 10\nm = Flux.Chain(\n    Flux.Dense(784, layer_size), # 784 being image linear dimension (28 x 28)\n    matrix_relu,\n    Flux.Dense(layer_size, 10), # 10 being the number of outcomes (0 to 9)\n    Flux.softmax,\n)","category":"section"},{"location":"examples/custom-relu_new/#Prepare-data","page":"Custom ReLU layer","title":"Prepare data","text":"N = 1000 # batch size\n# Preprocessing train data\nimgs = MLDatasets.MNIST(; split = :train).features[:, :, 1:N]\nlabels = MLDatasets.MNIST(; split = :train).targets[1:N]\ntrain_X = float.(reshape(imgs, size(imgs, 1) * size(imgs, 2), N)) # stack images\ntrain_Y = Flux.onehotbatch(labels, 0:9);\n# Preprocessing test data\ntest_imgs = MLDatasets.MNIST(; split = :test).features[:, :, 1:N]\ntest_labels = MLDatasets.MNIST(; split = :test).targets[1:N];\ntest_X = float.(reshape(test_imgs, size(test_imgs, 1) * size(test_imgs, 2), N))\ntest_Y = Flux.onehotbatch(test_labels, 0:9);\nnothing #hide\n\nDefine input data The original data is repeated epochs times because Flux.train! only loops through the data set once\n\nepochs = 2#50 # ~1 minute (i7 8th gen with 16gb RAM)\n# epochs = 100 # leads to 77.8% in about 2 minutes\ndataset = repeated((train_X, train_Y), epochs);\nnothing #hide","category":"section"},{"location":"examples/custom-relu_new/#Network-training","page":"Custom ReLU layer","title":"Network training","text":"training loss function, Flux optimizer\n\ncustom_loss(m, x, y) = Flux.crossentropy(m(x), y)\nopt = Flux.setup(Flux.Adam(), m)\n\nTrain to optimize network parameters\n\n@time Flux.train!(custom_loss, m, dataset, opt);\nnothing #hide\n\nAlthough our custom implementation takes time, it is able to reach similar accuracy as the usual ReLU function implementation.","category":"section"},{"location":"examples/custom-relu_new/#Accuracy-results","page":"Custom ReLU layer","title":"Accuracy results","text":"Average of correct guesses\n\naccuracy(x, y) = Statistics.mean(Flux.onecold(m(x)) .== Flux.onecold(y));\nnothing #hide\n\nTraining accuracy\n\naccuracy(train_X, train_Y)\n\nTest accuracy\n\naccuracy(test_X, test_Y)\n\nNote that the accuracy is low due to simplified training. It is possible to increase the number of samples N, the number of epochs epoch and the connectivity inner.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/polyhedral_project_new/#Polyhedral-QP-layer","page":"Polyhedral QP layer","title":"Polyhedral QP layer","text":"(Image: )\n\nWe use DiffOpt to define a custom network layer which, given an input matrix y, computes its projection onto a polytope defined by a fixed number of inequalities: a_i^T x â‰¥ b_i. A neural network is created using Flux.jl and trained on the MNIST dataset, integrating this quadratic optimization layer.\n\nThe QP is solved in the forward pass, and its DiffOpt derivative is used in the backward pass expressed with ChainRulesCore.rrule.\n\nThis example is similar to the custom ReLU layer, except that the layer is parameterized by the hyperplanes (w,b) and not a simple stateless function. This also means that ChainRulesCore.rrule must return the derivatives of the output with respect to the layer parameters to allow for backpropagation.\n\nusing JuMP\nimport DiffOpt\nimport Ipopt\nimport ChainRulesCore\nimport Flux\nimport MLDatasets\nimport Statistics\nusing Base.Iterators: repeated\nusing LinearAlgebra\nusing Random\n\nRandom.seed!(42)","category":"section"},{"location":"examples/polyhedral_project_new/#The-Polytope-representation-and-its-derivative","page":"Polyhedral QP layer","title":"The Polytope representation and its derivative","text":"struct Polytope{N}\n    w::NTuple{N,Vector{Float64}}\n    b::Vector{Float64}\nend\n\nPolytope(w::NTuple{N}) where {N} = Polytope{N}(w, randn(N))\n\nWe define a \"call\" operation on the polytope, making it a so-called functor. Calling the polytope with a matrix y operates an Euclidean projection of this matrix onto the polytope.\n\nfunction (polytope::Polytope{N})(\n    y_data::AbstractMatrix;\n    model = DiffOpt.nonlinear_diff_model(Ipopt.Optimizer),\n) where {N}\n    layer_size, batch_size = size(y_data)\n    empty!(model)\n    set_silent(model)\n    @variable(model, x[1:layer_size, 1:batch_size])\n    @variable(model, y[1:layer_size, 1:batch_size] in Parameter.(y_data))\n    @variable(model, b[idx=1:N] in Parameter.(polytope.b[idx]))\n    @variable(\n        model,\n        w[idx=1:N, i=1:layer_size] in Parameter(polytope.w[idx][i])\n    )\n    @constraint(\n        model,\n        greater_than_cons[idx in 1:N, sample in 1:batch_size],\n        dot(polytope.w[idx], x[:, sample]) â‰¥ b[idx]\n    )\n    @objective(model, Min, dot(x - y, x - y))\n    optimize!(model)\n    return Float32.(JuMP.value.(x))\nend\n\nThe @functor macro from Flux implements auxiliary functions for collecting the parameters of our custom layer and operating backpropagation.\n\nFlux.@functor Polytope\n\nDefine the reverse differentiation rule, for the function we defined above. Flux uses ChainRules primitives to implement reverse-mode differentiation of the whole network. To learn the current layer (the polytope the layer contains), the gradient is computed with respect to the Polytope fields in a ChainRulesCore.Tangent type which is used to represent derivatives with respect to structs. For more details about backpropagation, visit Introduction, ChainRulesCore.jl.\n\nfunction ChainRulesCore.rrule(\n    polytope::Polytope{N},\n    y_data::AbstractMatrix,\n) where {N}\n    model = DiffOpt.nonlinear_diff_model(Ipopt.Optimizer)\n    xv = polytope(y_data; model = model)\n    function pullback_matrix_projection(dl_dx)\n        dl_dx = ChainRulesCore.unthunk(dl_dx)\n        #  `dl_dy` is the derivative of `l` wrt `y`\n        x = model[:x]::Matrix{JuMP.VariableRef}\n        y = model[:y]::Matrix{JuMP.VariableRef}\n        w = model[:w]::Matrix{JuMP.VariableRef}\n        b = model[:b]::Vector{JuMP.VariableRef}\n        layer_size, batch_size = size(x)\n        # set sensitivities\n        for i in eachindex(x)\n            DiffOpt.set_reverse_variable(model, x[i], dl_dx[i])\n        end\n        # compute grad\n        DiffOpt.reverse_differentiate!(model)\n        # compute gradient wrt objective function parameter y\n        dl_dy = DiffOpt.get_reverse_parameter.(model, y)\n        # compute gradient wrt objective function parameter w and b\n        _dl_dw = DiffOpt.get_reverse_parameter.(model, w)\n        dl_dw = zero.(polytope.w)\n        for idx in 1:N\n            dl_dw[idx] .= _dl_dw[idx, :]\n        end\n        dl_db = DiffOpt.get_reverse_parameter.(model, b)\n        dself = ChainRulesCore.Tangent{Polytope{N}}(; w = dl_dw, b = dl_db)\n        return (dself, dl_dy)\n    end\n    return xv, pullback_matrix_projection\nend","category":"section"},{"location":"examples/polyhedral_project_new/#Define-the-Network","page":"Polyhedral QP layer","title":"Define the Network","text":"layer_size = 20\nm = Flux.Chain(\n    Flux.Dense(784, layer_size), # 784 being image linear dimension (28 x 28)\n    Polytope((randn(layer_size), randn(layer_size), randn(layer_size))),\n    Flux.Dense(layer_size, 10), # 10 being the number of outcomes (0 to 9)\n    Flux.softmax,\n)","category":"section"},{"location":"examples/polyhedral_project_new/#Prepare-data","page":"Polyhedral QP layer","title":"Prepare data","text":"M = 500 # batch size\n# Preprocessing train data\nimgs = MLDatasets.MNIST(; split = :train).features[:, :, 1:M]\nlabels = MLDatasets.MNIST(; split = :train).targets[1:M]\ntrain_X = float.(reshape(imgs, size(imgs, 1) * size(imgs, 2), M)) # stack images\ntrain_Y = Flux.onehotbatch(labels, 0:9);\n# Preprocessing test data\ntest_imgs = MLDatasets.MNIST(; split = :test).features[:, :, 1:M]\ntest_labels = MLDatasets.MNIST(; split = :test).targets[1:M]\ntest_X = float.(reshape(test_imgs, size(test_imgs, 1) * size(test_imgs, 2), M))\ntest_Y = Flux.onehotbatch(test_labels, 0:9);\nnothing #hide\n\nDefine input data The original data is repeated epochs times because Flux.train! only loops through the data set once\n\nepochs = 5\ndataset = repeated((train_X, train_Y), epochs);\nnothing #hide","category":"section"},{"location":"examples/polyhedral_project_new/#Network-training","page":"Polyhedral QP layer","title":"Network training","text":"training loss function, Flux optimizer\n\ncustom_loss(m, x, y) = Flux.crossentropy(m(x), y)\nopt = Flux.setup(Flux.Adam(), m)\n\nTrain to optimize network parameters\n\n@time Flux.train!(custom_loss, m, dataset, opt);\nnothing #hide\n\nAlthough our custom implementation takes time, it is able to reach similar accuracy as the usual ReLU function implementation.","category":"section"},{"location":"examples/polyhedral_project_new/#Accuracy-results","page":"Polyhedral QP layer","title":"Accuracy results","text":"Average of correct guesses\n\naccuracy(x, y) = Statistics.mean(Flux.onecold(m(x)) .== Flux.onecold(y));\nnothing #hide\n\nTraining accuracy\n\naccuracy(train_X, train_Y)\n\nTest accuracy\n\naccuracy(test_X, test_Y)\n\nNote that the accuracy is low due to simplified training. It is possible to increase the number of samples N, the number of epochs epoch and the connectivity inner.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/sensitivity-analysis-ridge/#Sensitivity-Analysis-of-Ridge-Regression","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"(Image: )\n\nThis example illustrates the sensitivity analysis of data points in a Ridge Regression problem. The general form of the problem is given below:\n\nbeginsplit\nbeginarray ll\nmboxminimize  sum_i=1^N (y_i - w x_i - b)^2 + alpha (w^2 + b^2) \nendarray\nendsplit\n\nwhere\n\nw, b are slope and intercept of the regressing line\nx, y are the N data points\nÎ± is the regularization constant\n\nwhich is equivalent to:\n\nbeginsplit\nbeginarray ll\nmboxminimize  e^tope + alpha (w^2) \nmboxst  e_i = y_i - w x_i - b quad quad i=1N  \nendarray\nendsplit\n\nThis tutorial uses the following packages\n\nusing JuMP\nimport DiffOpt\nimport Random\nimport Ipopt\nimport Plots\nusing LinearAlgebra: dot","category":"section"},{"location":"examples/sensitivity-analysis-ridge/#Define-and-solve-the-problem","page":"Sensitivity Analysis of Ridge Regression","title":"Define and solve the problem","text":"Construct a set of noisy (guassian) data points around a line.\n\nRandom.seed!(42)\n\nN = 150\n\nw = 2 * abs(randn())\nb = rand()\nX = randn(N)\nY = w * X .+ b + 0.8 * randn(N);\nnothing #hide\n\nThe helper method fit_ridge defines and solves the corresponding model. The ridge regression is modeled with quadratic programming (quadratic objective and linear constraints) and solved in generic methods of Ipopt. This is not the standard way of solving the ridge regression problem this is done here for didactic purposes.\n\nfunction fit_ridge(X, Y, alpha = 0.1)\n    N = length(Y)\n    # Initialize a JuMP Model with Ipopt solver\n    model = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer))\n    set_silent(model)\n    @variable(model, w) # angular coefficient\n    @variable(model, b) # linear coefficient\n    # expression defining approximation error\n    @expression(model, e[i=1:N], Y[i] - w * X[i] - b)\n    # objective minimizing squared error and ridge penalty\n    @objective(model, Min, 1 / N * dot(e, e) + alpha * (w^2))\n    optimize!(model)\n    return model, w, b # return model & variables\nend\n\nPlot the data points and the fitted line for different alpha values\n\np = Plots.scatter(X, Y; label = nothing, legend = :topleft)\nmi, ma = minimum(X), maximum(X)\nPlots.title!(\"Fitted lines and points\")\n\nfor alpha in 0.5:0.5:1.5\n    local model, w, b = fit_ridge(X, Y, alpha)\n    wÌ‚ = value(w)\n    bÌ‚ = value(b)\n    Plots.plot!(\n        p,\n        [mi, ma],\n        [mi * wÌ‚ + bÌ‚, ma * wÌ‚ + bÌ‚];\n        label = \"alpha=$alpha\",\n        width = 2,\n    )\nend\np","category":"section"},{"location":"examples/sensitivity-analysis-ridge/#Differentiate","page":"Sensitivity Analysis of Ridge Regression","title":"Differentiate","text":"Now that we've solved the problem, we can compute the sensitivity of optimal values of the slope w with respect to perturbations in the data points (x,y).\n\nalpha = 0.4\nmodel, w, b = fit_ridge(X, Y, alpha)\nwÌ‚ = value(w)\nbÌ‚ = value(b)\n\nWe first compute sensitivity of the slope with respect to a perturbation of the independent variable x.\n\nRecalling that the points (x_i y_i) appear in the objective function as: (yi - b - w*xi)^2, the DiffOpt.ForwardObjectiveFunction attribute must be set accordingly, with the terms multiplying the parameter in the objective. When considering the perturbation of a parameter Î¸, DiffOpt.ForwardObjectiveFunction() takes in the expression in the objective that multiplies Î¸. If Î¸ appears with a quadratic and a linear form: Î¸^2 a x + Î¸ b y, then the expression to pass to ForwardObjectiveFunction is 2Î¸ a x + b y.\n\nSensitivity with respect to x and y\n\nâˆ‡y = zero(X)\nâˆ‡x = zero(X)\nfor i in 1:N\n    MOI.set(\n        model,\n        DiffOpt.ForwardObjectiveFunction(),\n        2w^2 * X[i] + 2b * w - 2 * w * Y[i],\n    )\n    DiffOpt.forward_differentiate!(model)\n    âˆ‡x[i] = MOI.get(model, DiffOpt.ForwardVariablePrimal(), w)\n    MOI.set(model, DiffOpt.ForwardObjectiveFunction(), (2Y[i] - 2b - 2w * X[i]))\n    DiffOpt.forward_differentiate!(model)\n    âˆ‡y[i] = MOI.get(model, DiffOpt.ForwardVariablePrimal(), w)\nend\n\nVisualize point sensitivities with respect to regression points.\n\np = Plots.scatter(\n    X,\n    Y;\n    color = [dw < 0 ? :blue : :red for dw in âˆ‡x],\n    markersize = [5 * abs(dw) + 1.2 for dw in âˆ‡x],\n    label = \"\",\n)\nmi, ma = minimum(X), maximum(X)\nPlots.plot!(\n    p,\n    [mi, ma],\n    [mi * wÌ‚ + bÌ‚, ma * wÌ‚ + bÌ‚];\n    color = :blue,\n    label = \"\",\n)\nPlots.title!(\"Regression slope sensitivity with respect to x\")\n\np = Plots.scatter(\n    X,\n    Y;\n    color = [dw < 0 ? :blue : :red for dw in âˆ‡y],\n    markersize = [5 * abs(dw) + 1.2 for dw in âˆ‡y],\n    label = \"\",\n)\nmi, ma = minimum(X), maximum(X)\nPlots.plot!(\n    p,\n    [mi, ma],\n    [mi * wÌ‚ + bÌ‚, ma * wÌ‚ + bÌ‚];\n    color = :blue,\n    label = \"\",\n)\nPlots.title!(\"Regression slope sensitivity with respect to y\")\n\nNote the points with less central x values induce a greater y sensitivity of the slope.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_Example_new/#Thermal-Generation-Dispatch-Example","page":"Thermal Generation Dispatch Example","title":"Thermal Generation Dispatch Example","text":"(Image: )\n\nThis example illustrates the sensitivity analysis of thermal generation dispatch problem.\n\nThis problem can be described as the choice of thermal generation g given a demand d, a price for thermal generation c and a penalty price c_{Ï•} for any demand not attended Ï•.\n\nbeginsplit\nbeginarray ll\nmboxminimize  sum_i=1^N c_i g_i + c_phi phi \nmboxst  g_i ge 0 quad i=1N  \n             g_i le G_i quad i=1N  \n             sum_i=1^N g_i + phi = d\nendarray\nendsplit\n\nwhere\n\nG_{i} is the maximum possible generation for a thermal generator i","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_Example_new/#Define-and-solve-the-Thermal-Dispatch-Problem","page":"Thermal Generation Dispatch Example","title":"Define and solve the Thermal Dispatch Problem","text":"First, import the libraries.\n\nusing Test\nusing JuMP\nimport DiffOpt\nimport LinearAlgebra: dot\nimport HiGHS\nimport MathOptInterface as MOI\nimport Plots\n\nDefine the model that will be construct given a set of parameters.\n\nfunction generate_model(\n    d_data::Float64;\n    g_sup::Vector{Float64},\n    c_g::Vector{Float64},\n    c_Ï•::Float64,\n)\n    # Creation of the Model and Parameters\n    model = DiffOpt.quadratic_diff_model(HiGHS.Optimizer)\n    set_silent(model)\n    I = length(g_sup)\n\n    # Variables\n    @variable(model, g[i in 1:I] >= 0.0)\n    @variable(model, Ï• >= 0.0)\n\n    # Parameters\n    @variable(model, d in Parameter(d_data))\n\n    # Constraints\n    @constraint(model, limit_constraints_sup[i in 1:I], g[i] <= g_sup[i])\n    @constraint(model, demand_constraint, sum(g) + Ï• == d)\n\n    # Objectives\n    @objective(model, Min, dot(c_g, g) + c_Ï• * Ï•)\n\n    # Solve the model\n    optimize!(model)\n\n    # Return the solved model\n    return model\nend\n\nDefine the functions that will get the primal values g and \\phi and sensitivity analysis of the demand dg/dd and d\\phi/dd from a optimized model.\n\nfunction diff_forward(model::Model, Ïµ::Float64 = 1.0)\n    # Initialization of parameters and references to simplify the notation\n    vect_ref = [model[:g]; model[:Ï•]]\n\n    # Get the primal solution of the model\n    vect = value.(vect_ref)\n\n    # Reset the sensitivities of the model\n    DiffOpt.empty_input_sensitivities!(model)\n\n    # Pass the perturbation to the DiffOpt Framework\n    DiffOpt.set_forward_parameter(model, model[:d], Ïµ)\n\n    # Compute the derivatives with the Forward Mode\n    DiffOpt.forward_differentiate!(model)\n\n    # Get the derivative of the model\n    dvect = DiffOpt.get_forward_variable.(model, vect_ref)\n\n    # Return the values as a vector\n    return [vect; dvect]\nend\n\nfunction diff_reverse(model::Model, Ïµ::Float64 = 1.0)\n    # Initialization of parameters and references to simplify the notation\n    vect_ref = [model[:g]; model[:Ï•]]\n\n    # Get the primal solution of the model\n    vect = value.(vect_ref)\n\n    # Set variables needed for the DiffOpt Backward Framework\n    dvect = Array{Float64,1}(undef, length(vect_ref))\n\n    # Loop for each primal variable\n    for i in 1:(I+1)\n        # Reset the sensitivities of the model\n        DiffOpt.empty_input_sensitivities!(model)\n\n        # Pass the perturbation to the DiffOpt Framework\n        DiffOpt.set_reverse_variable.(model, vect_ref[i], Ïµ)\n\n        # Compute the derivatives with the Forward Mode\n        DiffOpt.reverse_differentiate!(model)\n\n        # Get the derivative of the model\n        dvect[i] = DiffOpt.get_reverse_parameter(model, model[:d])\n    end\n\n    # Return the values as a vector\n    return [vect; dvect]\nend\n\nInitialize of Parameters\n\ng_sup = [10.0, 20.0, 30.0]\nI = length(g_sup)\nd = 0.0:0.1:80\nd_size = length(d)\nc_g = [1.0, 3.0, 5.0]\nc_Ï• = 10.0;\nnothing #hide\n\nGenerate models for each demand d\n\nmodels = generate_model.(d; g_sup = g_sup, c_g = c_g, c_Ï• = c_Ï•);\nnothing #hide\n\nGet the results of models with the DiffOpt Forward and Backward context\n\nresult_forward = diff_forward.(models)\noptimize!.(models)\nresult_reverse = diff_reverse.(models);\nnothing #hide\n\nOrganization of results to plot Initialize data_results that will contain every result\n\ndata_results = Array{Float64,3}(undef, 2, d_size, 2 * (I + 1));\nnothing #hide\n\nPopulate the data_results array\n\nfor k in 1:d_size\n    data_results[1, k, :] = result_forward[k]\n    data_results[2, k, :] = result_reverse[k]\nend","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_Example_new/#Results-with-Plot-graphs","page":"Thermal Generation Dispatch Example","title":"Results with Plot graphs","text":"","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_Example_new/#Results-for-the-forward-context","page":"Thermal Generation Dispatch Example","title":"Results for the forward context","text":"Result Primal Values:\n\nPlots.plot(\n    d,\n    data_results[1, :, 1:(I+1)];\n    title = \"Generation by Demand\",\n    label = [\"Thermal Generation 1\" \"Thermal Generation 2\" \"Thermal Generation 3\" \"Generation Deficit\"],\n    xlabel = \"Demand [unit]\",\n    ylabel = \"Generation [unit]\",\n)\n\nResult Sensitivity Analysis:\n\nPlots.plot(\n    d,\n    data_results[1, :, (I+2):(2*(I+1))];\n    title = \"Sensitivity of Generation by Demand\",\n    label = [\"T. Gen. 1 Sensitivity\" \"T. Gen. 2 Sensitivity\" \"T. Gen. 3 Sensitivity\" \"Gen. Deficit Sensitivity\"],\n    xlabel = \"Demand [unit]\",\n    ylabel = \"Sensitivity [-]\",\n)","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_Example_new/#Results-for-the-reverse-context","page":"Thermal Generation Dispatch Example","title":"Results for the reverse context","text":"Result Primal Values:\n\nPlots.plot(\n    d,\n    data_results[2, :, 1:(I+1)];\n    title = \"Generation by Demand\",\n    label = [\"Thermal Generation 1\" \"Thermal Generation 2\" \"Thermal Generation 3\" \"Generation Deficit\"],\n    xlabel = \"Demand [unit]\",\n    ylabel = \"Generation [unit]\",\n)\n\nResult Sensitivity Analysis:\n\nPlots.plot(\n    d,\n    data_results[2, :, (I+2):(2*(I+1))];\n    title = \"Sensitivity of Generation by Demand\",\n    label = [\"T. Gen. 1 Sensitivity\" \"T. Gen. 2 Sensitivity\" \"T. Gen. 3 Sensitivity\" \"Gen. Deficit Sensitivity\"],\n    xlabel = \"Demand [unit]\",\n    ylabel = \"Sensitivity [-]\",\n)\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"intro/#Introduction","page":"Introduction","title":"Introduction","text":"An optimization problem is the problem of finding the best solution from all feasible solutions. The standard form of an optimization problem is \n\nbeginaligned\nunderset xoperatorname minimize f(x)operatorname subjectto g_i(x)leq 0quad i=1dots mh_j(x)=0quad j=1dots p\nendaligned\n\nNote that finding solution to most of the optimization problems is computationally intractable. Here we consider a subset of those problems called convex optimization problems, which admit polynomial time solutions. The standard form of a convex optimization problem is \n\nbeginaligned\nunderset xoperatorname minimize f(x)operatorname subjectto g_i(x)leq 0quad i=1dots mA x = b\nendaligned\n\nwhere f and g_i are convex functions.","category":"section"},{"location":"intro/#Parameterized-problems","page":"Introduction","title":"Parameterized  problems","text":"In practice, convex optimization problems include parameters, apart from the decision variables, which determines the structure of the problem itself i.e. the objective function and constraints. Hence they affect the solution too. A general form of a parameterized convex optimization problem is \n\nbeginaligned\nunderset xoperatorname minimize f(x theta)operatorname subjectto g_i(x theta)leq 0quad i=1dots mA(theta) x = b(theta)\nendaligned\n\nwhere theta is the parameter. In different fields, these parameters go by different names:\n\nHyperparameters in machine learning\nRisk aversion or other backtesing parameters in financial modelling\nParameterized systems in control theory","category":"section"},{"location":"intro/#What-do-we-mean-by-differentiating-a-parameterized-optimization-program?-Why-do-we-need-it?","page":"Introduction","title":"What do we mean by differentiating a parameterized optimization program? Why do we need it?","text":"Often, parameters are chosen and tuned by hand - an iterative process - and the structure of the problem is crafted manually. But it is possible to do an automatic gradient based tuning of parameters.\n\nConsider solution of the parametrized optimization problem, x(theta),\n\nbeginsplit\nbeginarray lll\nx^*(theta)= underset xoperatorname argmin  f(x theta)\n              operatorname subjectto  g_i(x theta)leq 0quad i=1dots m\n                                           A(theta) x = b(theta)\nendarray\nendsplit\n\nwhich is the input of l(x^*(theta)), a loss function. Our goal is to choose the best parameter theta so that l is optimized. Here, l(x^*(theta)) is the objective function and theta is the decision variable. In order to apply a gradient-based strategy to this problem, we need to differentiate l with respect to theta.\n\nfracpartial l(x^*(theta))partial theta = fracpartial l(x^*(theta))partial x^*(theta)  fracpartial x^*(theta)partial theta\n\nBy implicit function theorem, this translates to differentiating the program data, i.e. functions f, g_i(x) and matrices A, b, with respect to theta.\n\nThis is can be achieved in two steps or passes:\n\nForward pass - Given an initial value of theta, solves the optimization problem to find x^*(theta)\nBackward pass - Given x^*, differentiate and find fracpartial x^*(theta)partial theta","category":"section"},{"location":"examples/matrix-inversion-manual_new/#Differentiating-a-QP-wrt-a-single-variable","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"(Image: )\n\nConsider the quadratic program\n\nbeginsplit\nbeginarray ll\nmboxminimize  frac12 x^T Q x + q^T x \nmboxsubject to  G x leq h x in mathcalR^2 \nendarray\nendsplit\n\nwhere Q, q, G are fixed and h is the single parameter.\n\nIn this example, we'll try to differentiate the QP wrt h, by finding its jacobian by hand (using Eqn (6) of QPTH article) and compare the results:\n\nManual compuation\nUsing JuMP and DiffOpt\n\nAssuming\n\nQ = [[4, 1], [1, 2]]\nq = [1, 1]\nG = [1, 1]\n\nand begining with a starting value of h=-1\n\nfew values just for reference\n\nvariable optimal value note\nx* [-0.25; -0.75] Primal optimal\nðœ†âˆ— -0.75 Dual optimal","category":"section"},{"location":"examples/matrix-inversion-manual_new/#Finding-Jacobian-using-matrix-inversion","page":"Differentiating a QP wrt a single variable","title":"Finding Jacobian using matrix inversion","text":"Lets formulate Eqn (6) of QPTH article for our QP. If we assume h as the only parameter and Q,q,G as fixed problem data - also note that our QP doesn't involves Ax=b constraint - then Eqn (6) reduces to\n\nbegingather\n beginbmatrix\n     Q  G^T \n     lambda^* G  G x^* - h\n endbmatrix\n beginbmatrix\n     dx \n     d lambda\n endbmatrix\n =\n  beginbmatrix\n   0 \n   lambda^* dh\n   endbmatrix\nendgather\n\nNow to find the jacobians $ \\frac{\\partial x}{\\partial h}, \\frac{\\partial \\lambda}{\\partial h}$ we substitute dh = I = [1] and plug in values of Q,q,G to get\n\nbegingather\n beginbmatrix\n     4  1  1 \n     1  2  1 \n     -075  -075  0\n endbmatrix\n beginbmatrix\n     fracpartial x_1partial h \n     fracpartial x_2partial h \n     fracpartial lambdapartial h\n endbmatrix\n =\n  beginbmatrix\n   0 \n   0 \n   -075\n   endbmatrix\nendgather\n\nUpon solving using matrix inversion, the jacobian is\n\nfracpartial x_1partial h = 025 fracpartial x_2partial h = 075 fracpartial lambdapartial h = -175","category":"section"},{"location":"examples/matrix-inversion-manual_new/#Finding-Jacobian-using-JuMP-and-DiffOpt","page":"Differentiating a QP wrt a single variable","title":"Finding Jacobian using JuMP and DiffOpt","text":"using JuMP\nimport DiffOpt\nimport Ipopt\n\nn = 2 # variable dimension\nm = 1; # no of inequality constraints\n\nQ = [4.0 1.0; 1.0 2.0]\nq = [1.0; 1.0]\nG = [1.0 1.0;]\nh = [-1.0;]   # initial values set\n\nInitialize empty model\n\nmodel = DiffOpt.quadratic_diff_model(Ipopt.Optimizer)\nset_silent(model)\n\nAdd the variables\n\n@variable(model, x[1:2])\n\nAdd the parameters\n\n@variable(model, y[1:length(h)] in Parameter.(h))\n\nAdd the constraints.\n\n@constraint(model, cons[j in 1:1], sum(G[j, i] * x[i] for i in 1:2) <= y[j]);\n\n@objective(\n    model,\n    Min,\n    1 / 2 * sum(Q[j, i] * x[i] * x[j] for i in 1:2, j in 1:2) +\n    sum(q[i] * x[i] for i in 1:2)\n)\n\nSolve problem\n\noptimize!(model)\n\nprimal solution\n\nvalue.(x)\n\ndual solution\n\ndual.(cons)\n\nset sensitivitity\n\nDiffOpt.set_forward_parameter.(model, y, 1.0)\n\nCompute derivatives\n\nDiffOpt.forward_differentiate!(model)\n\nQuery derivative\n\ndx = DiffOpt.get_forward_variable.(model, x)\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/Planar_Arm_Example/#Planar-Arm-Example","page":"Planar Arm Example","title":"Planar Arm Example","text":"Inverse Kinematics (IK) computes joint angles that place a robotâ€™s end-effector at a desired target (x_ty_t). For a 2-link planar arm with joint angles theta_1theta_2, the end-effector position is:\n\nf(theta_1theta_2) = bigl(ell_1cos(theta_1) + ell_2cos(theta_1+theta_2)\nell_1sin(theta_1) + ell_2sin(theta_1+theta_2)bigr)\n\nWe can solve an NLP:\n\nmin_theta_1theta_2  (theta_1^2 + theta_2^2)\nquadtextstquad f(theta_1theta_2) = (x_ty_t)\n\nTreat (x_ty_t) as parameters. Once solved, we differentiate w.r.t. (x_ty_t) to find how small changes in the target location alter the optimal angles - the differential kinematics.","category":"section"},{"location":"examples/Planar_Arm_Example/#Define-and-solve-the-2-link-planar-arm-problem-and-build-sensitivity-map-of-joint-angles-to-target","page":"Planar Arm Example","title":"Define and solve the 2-link planar arm problem and build sensitivity map of joint angles to target","text":"First, import the libraries.\n\nusing Test\nusing JuMP\nimport DiffOpt\nusing LinearAlgebra\nusing Statistics\nimport Ipopt\nusing Plots\nusing Plots.Measures\n\nFixed data\n\nArm geometry\n\nl1 = 1.0;\nl2 = 1.0;\nreach = l1 + l2          # 2.0\ntol = 1e-6               # numerical tolerance for feasibility\n\nSampling grid in workspace\n\ngrid_res = 25 # grid resolution low for documentation compilation requirements\nxs = range(-reach, reach; length = grid_res)\nys = range(-reach, reach; length = grid_res)\n\nheat = fill(NaN, grid_res, grid_res)   # store â€–J_invâ€–â‚‚\nfeas = fill(0.0, grid_res, grid_res)  # feasibility mask\nÎ¸1mat = similar(heat)\n\nfunction ik_angles(x, y; l1 = 1.0, l2 = 1.0, elbow_up = true)\n    c2 = (x^2 + y^2 - l1^2 - l2^2) / (2 * l1 * l2)\n    Î¸2 = elbow_up ? acos(clamp(c2, -1, 1)) : -acos(clamp(c2, -1, 1))\n    k1 = l1 + l2 * cos(Î¸2)\n    k2 = l2 * sin(Î¸2)\n    Î¸1 = atan(y, x) - atan(k2, k1)\n    return Î¸1, Î¸2\nend\n\nfor (i, x_t) in enumerate(xs), (j, y_t) in enumerate(ys)\n    global Î¸1mat, heat\n    # skip points outside the circular reach\n    norm([x_t, y_t]) > reach && continue\n\n    # ---------- build differentiable NLP ----------\n    model = DiffOpt.nonlinear_diff_model(Ipopt.Optimizer)\n    set_silent(model)\n\n    @variable(model, xt in Parameter(x_t))\n    @variable(model, yt in Parameter(y_t))\n    @variable(model, Î¸1)\n    @variable(model, Î¸2)\n\n    @objective(model, Min, Î¸1^2 + Î¸2^2)\n    @constraint(model, l1 * cos(Î¸1) + l2 * cos(Î¸1 + Î¸2) == xt)\n    @constraint(model, l1 * sin(Î¸1) + l2 * sin(Î¸1 + Î¸2) == yt)\n\n    # --- supply analytic start values ---\n    Î¸1â‚€, Î¸2â‚€ = ik_angles(x_t, y_t; elbow_up = true)\n    set_start_value(Î¸1, Î¸1â‚€)\n    set_start_value(Î¸2, Î¸2â‚€)\n\n    optimize!(model)\n    println(\"Solving for target (\", x_t, \", \", y_t, \")\")\n    # check for optimality\n    status = termination_status(model)\n    println(\"Status: \", status)\n\n    status == MOI.OPTIMAL || status == MOI.LOCALLY_SOLVED || continue\n\n    Î¸1Ì‚ = value(Î¸1)\n    Î¸1mat[j, i] = Î¸1Ì‚   # save pose\n\n    # ---- forward diff wrt  xt  (âˆ‚Î¸/âˆ‚x) ----\n    DiffOpt.empty_input_sensitivities!(model)\n    DiffOpt.set_forward_parameter(model, xt, 0.01)\n    DiffOpt.forward_differentiate!(model)\n    dÎ¸1_dx = DiffOpt.get_forward_variable(model, Î¸1)\n    dÎ¸2_dx = DiffOpt.get_forward_variable(model, Î¸2)\n\n    # check first order approximation keeps solution close to target withing tolerance\n    Î¸_approx = [Î¸1Ì‚ + dÎ¸1_dx, Î¸1Ì‚ + dÎ¸2_dx]\n    x_approx = l1 * cos(Î¸_approx[1]) + l2 * cos(Î¸_approx[1] + Î¸_approx[2])\n    y_approx = l1 * sin(Î¸_approx[1]) + l2 * sin(Î¸_approx[1] + Î¸_approx[2])\n    _error = [x_approx - (x_t + 0.01), y_approx - y_t]\n    println(\"Error in first order approximation: \", _error)\n    feas[j, i] = norm(_error)\n\n    # ---- forward diff wrt  yt  (âˆ‚Î¸/âˆ‚y) ----\n    DiffOpt.empty_input_sensitivities!(model)\n    DiffOpt.set_forward_parameter(model, yt, 0.01)\n    DiffOpt.forward_differentiate!(model)\n    dÎ¸1_dy = DiffOpt.get_forward_variable(model, Î¸1)\n    dÎ¸2_dy = DiffOpt.get_forward_variable(model, Î¸2)\n\n    # 2-norm of inverse Jacobian\n    Jinv = [\n        dÎ¸1_dx dÎ¸1_dy\n        dÎ¸2_dx dÎ¸2_dy\n    ]\n    heat[j, i] = opnorm(Jinv)            # Ïƒ_max  of Jinv\nend\n\nReplace nans with 0.0\n\nheat = replace(heat, NaN => 0.0)","category":"section"},{"location":"examples/Planar_Arm_Example/#Results-with-Plot-graphs","page":"Planar Arm Example","title":"Results with Plot graphs","text":"default(;\n    size = (1150, 350),\n    legendfontsize = 8,\n    guidefontsize = 9,\n    tickfontsize = 7,\n)\n\nplt = heatmap(\n    xs,\n    ys,\n    heat;\n    xlabel = \"x target\",\n    ylabel = \"y target\",\n    clims = (0, quantile(skipmissing(heat), 0.95)),   # clip extremes\n    colorbar_title = \"â€–âˆ‚Î¸/âˆ‚(x,y)â€–â‚‚\",\n    left_margin = 5Plots.Measures.mm,\n    bottom_margin = 5Plots.Measures.mm,\n);\nnothing #hide\n\nOverlay workspace boundary\n\nÎ¸ = range(0, 2Ï€; length = 200)\nplot!(plt, reach * cos.(Î¸), reach * sin.(Î¸); c = :white, lw = 1, lab = \"reach\");\n\nplt_feas = heatmap(\n    xs,\n    ys,\n    feas;\n    xlabel = \"x target\",\n    ylabel = \"y target\",\n    clims = (0, 1),\n    colorbar_title = \"Precision Error\",\n    left_margin = 5Plots.Measures.mm,\n    bottom_margin = 5Plots.Measures.mm,\n);\n\nplot!(\n    plt_feas,\n    reach * cos.(Î¸),\n    reach * sin.(Î¸);\n    c = :white,\n    lw = 1,\n    lab = \"reach\",\n);\n\nplt_all = plot(\n    plt,\n    plt_feas;\n    layout = (1, 2),\n    left_margin = 5Plots.Measures.mm,\n    bottom_margin = 5Plots.Measures.mm,\n    legend = :bottomright,\n)\n\nLeft figure shows the spectral-norm heat-map bigllVertpartialboldsymbolthetapartial(xy)bigrrVert_2 for a two-link arm - Bright rings mark near-singular poses. Right figure shows the normalized precision error of the first order approximation derived from calculated sensitivities.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"manual/#Manual","page":"Manual","title":"Manual","text":"","category":"section"},{"location":"manual/#Supported-objectives-and-constraints-scheme-1","page":"Manual","title":"Supported objectives & constraints - scheme 1","text":"For QuadraticProgram backend, the package supports following Function-in-Set constraints: \n\nMOI Function MOI Set\nVariableIndex GreaterThan\nVariableIndex LessThan\nVariableIndex EqualTo\nScalarAffineFunction GreaterThan\nScalarAffineFunction LessThan\nScalarAffineFunction EqualTo\n\nand the following objective types: \n\nMOI Function\nVariableIndex\nScalarAffineFunction\nScalarQuadraticFunction","category":"section"},{"location":"manual/#Supported-objectives-and-constraints-ConicProgram-backend","page":"Manual","title":"Supported objectives & constraints - ConicProgram backend","text":"For the ConicProgram backend, the package supports following Function-in-Set constraints: \n\nMOI Function MOI Set\nVectorOfVariables Nonnegatives\nVectorOfVariables Nonpositives\nVectorOfVariables Zeros\nVectorOfVariables SecondOrderCone\nVectorOfVariables PositiveSemidefiniteConeTriangle\nVectorAffineFunction Nonnegatives\nVectorAffineFunction Nonpositives\nVectorAffineFunction Zeros\nVectorAffineFunction SecondOrderCone\nVectorAffineFunction PositiveSemidefiniteConeTriangle\n\nand the following objective types: \n\nMOI Function\nVariableIndex\nScalarAffineFunction\n\nOther conic sets such as RotatedSecondOrderCone and PositiveSemidefiniteConeSquare are supported through bridges.","category":"section"},{"location":"manual/#Supported-objectives-and-constraints-NonlinearProgram-backend","page":"Manual","title":"Supported objectives & constraints - NonlinearProgram backend","text":"For the NonlinearProgram backend, the package supports following Function-in-Set constraints:\n\nMOI Function MOI Set\nVariableIndex GreaterThan\nVariableIndex LessThan\nVariableIndex EqualTo\nScalarAffineFunction GreaterThan\nScalarAffineFunction LessThan\nScalarAffineFunction EqualTo\nScalarQuadraticFunction GreaterThan\nScalarQuadraticFunction LessThan\nScalarQuadraticFunction EqualTo\nScalarNonlinearFunction GreaterThan\nScalarNonlinearFunction LessThan\nScalarNonlinearFunction EqualTo\n\nand the following objective types: \n\nMOI Function\nVariableIndex\nScalarAffineFunction\nScalarQuadraticFunction\nScalarNonlinearFunction","category":"section"},{"location":"manual/#VectorNonlinearOracle-bridge-(NonlinearProgram)","page":"Manual","title":"VectorNonlinearOracle bridge (NonlinearProgram)","text":"DiffOpt.NonLinearProgram supports MOI.VectorOfVariables in MOI.VectorNonlinearOracle through an internal bridge that rewrites the vector oracle into scalar nonlinear constraints.\n\nAt a high level, for a vector oracle fmathbbR^n to mathbbR^m with bounds l le f(x) le u:\n\none scalar nonlinear operator is registered per output row f_i(x)\neach row is converted into one or two scalar constraints based on bounds:\nfinite and equal li == ui: EqualTo(l[i])\nfinite lower only: GreaterThan(l[i])\nfinite upper only: LessThan(u[i])\nboth finite and different: one GreaterThan and one LessThan\ninfinite bounds are skipped\n\nCallback signature requirements follow MOI:\n\nunivariate (input_dimension == 1):\nf(x)::Real\nâˆ‡f(x)::Real\nâˆ‡Â²f(x)::Real\nmultivariate (input_dimension > 1):\nf(x...)::Real\nâˆ‡f(g, x...) fills g\nâˆ‡Â²f(H, x...) fills the lower-triangular part of H\n\nWarm-start mapping for bridged constraints:\n\nConstraintPrimalStart expects an input vector x (not f(x)), evaluates the oracle at x, and writes starts for each generated scalar constraint.\nConstraintDualStart accepts either:\nlength = output dimension m: treated as direct row duals\nlength = input dimension n: interpreted as J' * Î» and converted to row duals Î» via a least-squares solve\n\nCurrent limitation:\n\nfor dual starts on rows with both finite bounds (l[i] < u[i]), only the lower-bound side is propagated explicitly (the upper-side split is not modeled in this bridge-level helper).\n\nMinimal JuMP example:\n\nusing JuMP, DiffOpt, Ipopt\nimport MathOptInterface as MOI\n\nmodel = DiffOpt.nonlinear_diff_model(Ipopt.Optimizer)\n@variable(model, x[1:2])\n@objective(model, Min, x[1]^2 + x[2]^2)\n\nfunction eval_f(ret, z)\n    ret[1] = z[1]^2 + z[2]^2\n    return\nend\nfunction eval_jacobian(ret, z)\n    ret[1] = 2z[1]\n    ret[2] = 2z[2]\n    return\nend\nfunction eval_hessian_lagrangian(ret, z, Î¼)\n    ret[1] = 2Î¼[1]  # (1,1)\n    ret[2] = 2Î¼[1]  # (2,2)\n    return\nend\n\nset = MOI.VectorNonlinearOracle(;\n    dimension = 2,\n    l = [-Inf],\n    u = [1.0],\n    eval_f,\n    jacobian_structure = [(1, 1), (1, 2)],\n    eval_jacobian,\n    hessian_lagrangian_structure = [(1, 1), (2, 2)],\n    eval_hessian_lagrangian,\n)\n\n@constraint(model, [x[1], x[2]] in set)\noptimize!(model)","category":"section"},{"location":"manual/#Creating-a-differentiable-MOI-optimizer","page":"Manual","title":"Creating a differentiable MOI optimizer","text":"You can create a differentiable optimizer over an existing MOI solver by using the diff_optimizer utility. ","category":"section"},{"location":"manual/#Projections-on-cone-sets","page":"Manual","title":"Projections on cone sets","text":"DiffOpt requires taking projections and finding projection gradients of vectors while computing the jacobians. For this purpose, we use MathOptSetDistances.jl, which is a dedicated package for computing set distances, projections and projection gradients.","category":"section"},{"location":"manual/#Conic-problem-formulation","page":"Manual","title":"Conic problem formulation","text":"note: Note\nAs of now, when defining a conic or convex quadratic problem, the package is using SCS geometric form for affine expressions in cones.\n\nConsider a convex conic optimization problem in its primal (P) and dual (D) forms:\n\nbeginsplit\nbeginarray llcc\ntextbfPrimal Problem   textbfDual Problem  \nmboxminimize  c^T x  quad quad  mboxminimize  b^T y  \nmboxsubject to  A x + s = b  quad quad  mboxsubject to  A^T y + c = 0 \n s in mathcalK    y in mathcalK^*\nendarray\nendsplit\n\nwhere\n\nx in R^n is the primal variable, y in R^m is the dual variable, and s in R^m is the primal slack\n\nvariable\n\nmathcalK subseteq R^m is a closed convex cone and mathcalK^* subseteq R^m is the corresponding dual cone\n\nvariable\n\nA in R^m times n, b in R^m, c in R^n are problem data\n\nIn the light of above, DiffOpt differentiates program variables x, s, y  w.r.t pertubations/sensivities in problem data i.e. dA, db, dc. This is achieved via implicit differentiation and matrix differential calculus.\n\nNote that the primal (P) and dual (D) are self-duals of each other. Similarly, for the constraints we support, mathcalK is same in format as mathcalK^*.","category":"section"},{"location":"manual/#Reference-articles","page":"Manual","title":"Reference articles","text":"Differentiating Through a Cone Program - Akshay Agrawal, Shane Barratt, Stephen Boyd, Enzo Busseti, Walaa M. Moursi, 2019\nA fast and differentiable QP solver for PyTorch. Crafted by Brandon Amos and J. Zico Kolter.\nOptNet: Differentiable Optimization as a Layer in Neural Networks","category":"section"},{"location":"manual/#Backward-Pass-vector","page":"Manual","title":"Backward Pass vector","text":"One possible point of confusion in finding Jacobians is the role of the backward pass vector - above eqn (7), OptNet: Differentiable Optimization as a Layer in Neural Networks. While differentiating convex programs, it is often the case that we don't want to find the actual derivatives, rather we might be interested in computing the product of Jacobians with a backward pass vector, often used in backpropagation in machine learning/automatic differentiation. This is what happens in DiffOpt backends.","category":"section"},{"location":"manual/#DiffOpt.diff_optimizer","page":"Manual","title":"DiffOpt.diff_optimizer","text":"function diff_optimizer(\n    optimizer_constructor;\n    with_bridge_type = Float64,\n    with_cache_type = Float64,\n    with_outer_cache = !isnothing(with_bridge_type),\n    allow_parametric_opt_interface = true,\n)\n\nCreates a DiffOpt.Optimizer, which is an MOI layer with an internal optimizer and other utility methods. Results (primal, dual and slack values) are obtained by querying the internal optimizer instantiated using the optimizer_constructor. These values are required for find jacobians with respect to problem data.\n\nThe inner optimizer is instantiated with MOI.instantiate(optimizer_constructor; with_bridge_type, with_cache_type); see the docs of MOI.instantiate.\n\nIf allow_parametric_opt_interface is true and the inner optimizer does not natively (in the sense, without the bridge layer) supports ParameterSet, then a ParametricOptInterface.Optimizer layer is added.\n\nIf with_outer_cache is true, an additional layer of cache is added.\n\nOne define a differentiable model by using any solver of choice. Example:\n\njulia> import DiffOpt, HiGHS\n\njulia> model = DiffOpt.diff_optimizer(HiGHS.Optimizer)\njulia> set_attribute(model, DiffOpt.ModelConstructor, DiffOpt.QuadraticProgram.Model) # optional selection of diff method\njulia> x = model.add_variable(model)\njulia> model.add_constraint(model, ...)\n\n\n\n\n\n","category":"function"},{"location":"examples/sensitivity-analysis-svm/#Sensitivity-Analysis-of-SVM","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"(Image: )\n\nThis notebook illustrates sensitivity analysis of data points in a Support Vector Machine (inspired from @matbesancon's SimpleSVMs.)\n\nFor reference, Section 10.1 of https://online.stat.psu.edu/stat508/book/export/html/792 gives an intuitive explanation of what it means to have a sensitive hyperplane or data point. The general form of the SVM training problem is given below (with ell_2 regularization):\n\nbeginsplit\nbeginarray ll\nmboxminimize  lambdaw^2 + sum_i=1^N xi_i \nmboxst  xi_i ge 0 quad quad i=1N  \n             y_i (w^T X_i + b) ge 1 - xi_i quad i=1N  \nendarray\nendsplit\n\nwhere\n\nX, y are the N data points\nw is the support vector\nb determines the offset b/||w|| of the hyperplane with normal w\nÎ¾ is the soft-margin loss\nÎ» is the ell_2 regularization.\n\nThis tutorial uses the following packages\n\nusing JuMP     # The mathematical programming modelling language\nimport DiffOpt # JuMP extension for differentiable optimization\nimport Ipopt   # Optimization solver that handles quadratic programs\nimport LinearAlgebra\nimport Plots\nimport Random","category":"section"},{"location":"examples/sensitivity-analysis-svm/#Define-and-solve-the-SVM","page":"Sensitivity Analysis of SVM","title":"Define and solve the SVM","text":"Construct two clusters of data points.\n\nN = 100\nD = 2\n\nRandom.seed!(62)\nX = vcat(randn(N Ã· 2, D), randn(N Ã· 2, D) .+ [2.0, 2.0]')\ny = append!(ones(N Ã· 2), -ones(N Ã· 2))\nÎ» = 0.05;\nnothing #hide\n\nLet's initialize a special model that can understand sensitivities\n\nmodel = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer))\nMOI.set(model, MOI.Silent(), true)\n\nAdd the variables\n\n@variable(model, Î¾[1:N] >= 0)\n@variable(model, w[1:D])\n@variable(model, b);\nnothing #hide\n\nAdd the constraints.\n\n@constraint(\n    model,\n    con[i in 1:N],\n    y[i] * (LinearAlgebra.dot(X[i, :], w) + b) >= 1 - Î¾[i]\n);\nnothing #hide\n\nDefine the objective and solve\n\n@objective(model, Min, Î» * LinearAlgebra.dot(w, w) + sum(Î¾))\n\noptimize!(model)\n\nWe can visualize the separating hyperplane.\n\nloss = objective_value(model)\n\nwv = value.(w)\n\nbv = value(b)\n\nsvm_x = [-2.0, 4.0] # arbitrary points\nsvm_y = (-bv .- wv[1] * svm_x) / wv[2]\n\np = Plots.scatter(\n    X[:, 1],\n    X[:, 2];\n    color = [yi > 0 ? :red : :blue for yi in y],\n    label = \"\",\n)\nPlots.plot!(\n    p,\n    svm_x,\n    svm_y;\n    label = \"loss = $(round(loss, digits=2))\",\n    width = 3,\n)","category":"section"},{"location":"examples/sensitivity-analysis-svm/#Gradient-of-hyperplane-wrt-the-data-point-coordinates","page":"Sensitivity Analysis of SVM","title":"Gradient of hyperplane wrt the data point coordinates","text":"Now that we've solved the SVM, we can compute the sensitivity of optimal values â€“ the separating hyperplane in our case â€“ with respect to perturbations of the problem data â€“ the data points â€“ using DiffOpt.\n\nHow does a change in coordinates of the data points, X, affects the position of the hyperplane? This is achieved by finding gradients of w and b with respect to X[i].\n\nBegin differentiating the model. analogous to varying Î¸ in the expression:\n\ny_i (w^T (X_i + theta) + b) ge 1 - xi_i\n\nâˆ‡ = zeros(N)\nfor i in 1:N\n    for j in 1:N\n        if i == j\n            # we consider identical perturbations on all x_i coordinates\n            MOI.set(\n                model,\n                DiffOpt.ForwardConstraintFunction(),\n                con[j],\n                y[j] * sum(w),\n            )\n        else\n            MOI.set(model, DiffOpt.ForwardConstraintFunction(), con[j], 0.0)\n        end\n    end\n    DiffOpt.forward_differentiate!(model)\n    dw = MOI.get.(model, DiffOpt.ForwardVariablePrimal(), w)\n    db = MOI.get(model, DiffOpt.ForwardVariablePrimal(), b)\n    âˆ‡[i] = LinearAlgebra.norm(dw) + LinearAlgebra.norm(db)\nend\n\nWe can visualize the separating hyperplane sensitivity with respect to the data points. Note that all the small numbers were converted into 1/10 of the largest value to show all the points of the set.\n\np3 = Plots.scatter(\n    X[:, 1],\n    X[:, 2];\n    color = [yi > 0 ? :red : :blue for yi in y],\n    label = \"\",\n    markersize = 2 * (max.(1.8âˆ‡, 0.2 * maximum(âˆ‡))),\n)\nPlots.yaxis!(p3, (-2, 4.5))\nPlots.plot!(p3, svm_x, svm_y; label = \"\", width = 3)\nPlots.title!(\"Sensitivity of the separator to data point variations\")\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/matrix-inversion-manual/#Differentiating-a-QP-wrt-a-single-variable","page":"Differentiating a QP wrt a single variable","title":"Differentiating a QP wrt a single variable","text":"(Image: )\n\nConsider the quadratic program\n\nbeginsplit\nbeginarray ll\nmboxminimize  frac12 x^T Q x + q^T x \nmboxsubject to  G x leq h x in mathcalR^2 \nendarray\nendsplit\n\nwhere Q, q, G are fixed and h is the single parameter.\n\nIn this example, we'll try to differentiate the QP wrt h, by finding its jacobian by hand (using Eqn (6) of QPTH article) and compare the results:\n\nManual compuation\nUsing JuMP and DiffOpt\n\nAssuming\n\nQ = [[4, 1], [1, 2]]\nq = [1, 1]\nG = [1, 1]\n\nand begining with a starting value of h=-1\n\nfew values just for reference\n\nvariable optimal value note\nx* [-0.25; -0.75] Primal optimal\nðœ†âˆ— -0.75 Dual optimal","category":"section"},{"location":"examples/matrix-inversion-manual/#Finding-Jacobian-using-matrix-inversion","page":"Differentiating a QP wrt a single variable","title":"Finding Jacobian using matrix inversion","text":"Lets formulate Eqn (6) of QPTH article for our QP. If we assume h as the only parameter and Q,q,G as fixed problem data - also note that our QP doesn't involves Ax=b constraint - then Eqn (6) reduces to\n\nbegingather\n beginbmatrix\n     Q  G^T \n     lambda^* G  G x^* - h\n endbmatrix\n beginbmatrix\n     dx \n     d lambda\n endbmatrix\n =\n  beginbmatrix\n   0 \n   lambda^* dh\n   endbmatrix\nendgather\n\nNow to find the jacobians $ \\frac{\\partial x}{\\partial h}, \\frac{\\partial \\lambda}{\\partial h}$ we substitute dh = I = [1] and plug in values of Q,q,G to get\n\nbegingather\n beginbmatrix\n     4  1  1 \n     1  2  1 \n     -075  -075  0\n endbmatrix\n beginbmatrix\n     fracpartial x_1partial h \n     fracpartial x_2partial h \n     fracpartial lambdapartial h\n endbmatrix\n =\n  beginbmatrix\n   0 \n   0 \n   -075\n   endbmatrix\nendgather\n\nUpon solving using matrix inversion, the jacobian is\n\nfracpartial x_1partial h = 025 fracpartial x_2partial h = 075 fracpartial lambdapartial h = -175","category":"section"},{"location":"examples/matrix-inversion-manual/#Finding-Jacobian-using-JuMP-and-DiffOpt","page":"Differentiating a QP wrt a single variable","title":"Finding Jacobian using JuMP and DiffOpt","text":"using JuMP\nimport DiffOpt\nimport Ipopt\n\nn = 2 # variable dimension\nm = 1; # no of inequality constraints\n\nQ = [4.0 1.0; 1.0 2.0]\nq = [1.0; 1.0]\nG = [1.0 1.0;]\nh = [-1.0;]   # initial values set\n\nInitialize empty model\n\nmodel = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer))\nset_silent(model)\n\nAdd the variables\n\n@variable(model, x[1:2])\n\nAdd the constraints.\n\n@constraint(model, cons[j in 1:1], sum(G[j, i] * x[i] for i in 1:2) <= h[j]);\n\n@objective(\n    model,\n    Min,\n    1 / 2 * sum(Q[j, i] * x[i] * x[j] for i in 1:2, j in 1:2) +\n    sum(q[i] * x[i] for i in 1:2)\n)\n\nSolve problem\n\noptimize!(model)\n\nprimal solution\n\nvalue.(x)\n\ndual solution\n\ndual.(cons)\n\nset sensitivitity\n\nMOI.set(\n    model,\n    DiffOpt.ForwardConstraintFunction(),\n    cons[1],\n    0.0 * index(x[1]) - 1.0,  # to indicate the direction vector to get directional derivatives\n)\n\nNote that 0.0 * index(x[1]) is used to make its type typeof(0.0 * index(x[1]) - 1.0) <: MOI.AbstractScalarFunction. To indicate different direction to get directional derivative, users should replace 0.0 * index(x[1]) - 1.0 as the form of dG*x - dh, where dG and dh correspond to the elements of direction vectors along G and h axes, respectively.\n\nCompute derivatives\n\nDiffOpt.forward_differentiate!(model)\n\nQuery derivative\n\ndx = MOI.get.(model, DiffOpt.ForwardVariablePrimal(), x)\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_sweep/#Thermal-Generation-Dispatch-Sweep-Example","page":"Thermal Generation Dispatch Sweep Example","title":"Thermal Generation Dispatch Sweep Example","text":"A classic application is to allocate power generation to meet a demand d at minimum cost, subject to capacity limits. We consider a simplified economic dispatch problem:\n\nbeginalign*\nmin_g_i ge 0phi ge 0  quad sum_i=1^n c_ig_i + sum_i=1^n c_2ig_i^2  + c_phi phi \ntextst  quad sum_i=1^n g_i + phi = d quad (lambda)\n quad 0 le g_i le G_i quad i=1dotsn\nendalign*\n\nwhere g_i is the power generated by plant i, each with linear unit cost c_i, quadratic cost component c_2i and capacity G_i, and phi is unmet demand with penalty c_phi. We treat d (the system demand) as a parameter. Differentiating through this QP quantifies how optimal generation shifts as demand changes.\n\nWhen d changes by a small amount, DiffOpt.forward\\_differentiate! solves a linear system capturing the KKT conditions, revealing how g_1^*, g_2^*, and phi^* shift with respect to d. These sensitivities are critical for power systems operators to understand how different plants ramp up or down as demand fluctuates.","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_sweep/#Define-and-solve-the-Thermal-Dispatch-Problem-for-a-range-of-demands","page":"Thermal Generation Dispatch Sweep Example","title":"Define and solve the Thermal Dispatch Problem for a range of demands","text":"First, import the libraries.\n\nusing Test\nusing JuMP\nimport DiffOpt\nimport HiGHS\nusing Plots\nusing Plots.Measures\n\nFixed data\n\nc = [20.0, 30.0]        # linear cost ($/MWh)\nc2 = [0.2, 0.1]        # quadratic cost ($/MWhÂ²)\nG = [150.0, 80.0]      # capacities (MW)\ncÏ† = 10_000.0            # penalty for unmet demand ($/MWh)\n\nd_range = 11.0:4.0:300.0 # demand sweep (MW) â€“ slightly coarser for clarity\nN = length(d_range)\n\nStorage for results\n\ng1, g2, _Ï† = zeros(N), zeros(N), zeros(N)\ndg1_dd, dg2_dd = zeros(N), zeros(N)\ndÏ†_dd, dJ_dd = zeros(N), zeros(N)\n\nSweep & Differentiation\n\nfor (k, d_val) in enumerate(d_range)\n    println(\"Demand: \", k, \" of \", N, \" (\", d_val, \")\")\n    model = DiffOpt.quadratic_diff_model(HiGHS.Optimizer)\n    set_silent(model)\n\n    @variable(model, d in Parameter(d_val))          # parameter\n    @variables(model, begin                          # decisions\n        0 <= g[i=1:2] <= G[i]\n        Ï† >= 0\n    end)\n\n    @objective(\n        model,\n        Min,                           # cost\n        sum(c[i] * g[i] + c2[i] * g[i]^2 for i in 1:2) + cÏ† * Ï†\n    )\n\n    @constraint(model, con, sum(g) + Ï† == d)              # balance\n\n    optimize!(model)\n\n    # ---------- store primal results ----------\n    g1[k] = value(g[1])\n    g2[k] = value(g[2])\n    _Ï†[k] = value(Ï†)\n\n    # ---------- forward sensitivities ----------\n    DiffOpt.empty_input_sensitivities!(model)\n    DiffOpt.set_forward_parameter(model, d, 1.0)\n    DiffOpt.forward_differentiate!(model)\n\n    dg1_dd[k] = DiffOpt.get_forward_variable(model, g[1])\n    dg2_dd[k] = DiffOpt.get_forward_variable(model, g[2])\n    dÏ†_dd[k] = DiffOpt.get_forward_variable(model, Ï†)\n\n    # marginal cost  Î»\n    dJ_dd[k] = dual.(con)\nend","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_sweep/#Results-with-Plot-graphs","page":"Thermal Generation Dispatch Sweep Example","title":"Results with Plot graphs","text":"default(;\n    size = (1150, 350),\n    legendfontsize = 8,\n    guidefontsize = 9,\n    tickfontsize = 7,\n)\n\nStacked-area dispatch plot\n\nplt_dispatch = plot(\n    d_range,\n    g1;                    # lower layer\n    fillrange = 0,                                  # fill down to zero\n    label = \"gâ‚\",\n    xlabel = \"Demand (MWh)\",\n    ylabel = \"g (MWh)\",\n    left_margin = 5Measures.mm,\n    bottom_margin = 5Measures.mm,\n    title = \"Optimal dispatch\",\n);\n\nplot!(\n    plt_dispatch,\n    d_range,\n    g1 .+ g2;              # upper layer\n    fillrange = g1,                                 # fill down to gâ‚\n    label = \"gâ‚‚\",\n);\n\nplot!(\n    plt_dispatch,\n    d_range,\n    _Ï†;                     # unmet demand as a line\n    lw = 2,\n    c = :red,\n    label = \"Ï† (unserved)\",\n);\n\ncapacity_limit = d_range[findfirst(g2 .== 80.0)]\n\nvline!(\n    plt_dispatch,\n    [capacity_limit, sum(G)];\n    l = :dash,\n    c = :black,\n    label = \"capacity limit\",\n);\nnothing #hide\n\n(b) marginal cost Î»(d)\n\nplt_mc = plot(\n    d_range,\n    dJ_dd;\n    lw = 2,\n    c = :black,\n    xlabel = \"Demand (MWh)\",\n    ylabel = \"Î» (\\$/MWh)\",\n    title = \"Electricity Price\",\n    yscale = :log10,\n    left_margin = 5Measures.mm,\n    bottom_margin = 5Measures.mm,\n    legend = false,\n);\n\nvline!(plt_mc, [capacity_limit, sum(G)]; l = :dash, c = :gray, label = \"\");\nnothing #hide\n\n(c) generation sensitivities\n\nplt_sens = plot(\n    d_range,\n    dg1_dd;\n    lw = 2,\n    xlabel = \"Demand (MWh)\",\n    ylabel = \"âˆ‚g/âˆ‚d  (MWh per MWh)\",\n    title = \"Generation Sensitivities\",\n    label = \"âˆ‚gâ‚/âˆ‚d\",\n);\n\nplot!(plt_sens, d_range, dg2_dd; lw = 2, label = \"âˆ‚gâ‚‚/âˆ‚d\");\nhline!(plt_sens, [0, 1]; l = :dot, c = :gray, label = \"\");\n\nvline!(plt_sens, [capacity_limit, sum(G)]; l = :dash, c = :gray, label = \"\");\nnothing #hide\n\ncombine all\n\nplot_all = plot(plt_dispatch, plt_mc, plt_sens; layout = (1, 3))\n\nOptimal dispatch (left), marginal electricity price lambda(d)=partial Jpartial d (center, logarithmic scale), and forward sensitivities partial g_ipartial d (right) for demands ranging from approx 0 to MWh.  The vertical dashed lines mark when the individual plant capacities are reachedâ€“-g_2 reaches it's capacity at MWh and g_1 at MWh.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/autotuning-ridge/#Auto-tuning-Hyperparameters","page":"Auto-tuning Hyperparameters","title":"Auto-tuning Hyperparameters","text":"(Image: )\n\nThis example shows how to learn a hyperparameter in Ridge Regression using a gradient descent routine. Let the regularized regression problem be formulated as:\n\nbeginequation\nmin_w quad frac12nd sum_i=1^n (w^T x_i - y_i)^2 + fracalpha2d  w _2^2\nendequation\n\nwhere\n\nx, y are the data points\nw are the learned weights\nÎ± is the hyperparameter acting on regularization.\n\nThe main optimization model will be formulated with JuMP. Using the gradient of the optimal weights with respect to the regularization parameters computed with DiffOpt, we can perform a gradient descent on top of the inner model to minimize the test loss.\n\nThis tutorial uses the following packages\n\nusing JuMP     # The mathematical programming modelling language\nimport DiffOpt # JuMP extension for differentiable optimization\nimport Ipopt    # Optimization solver that handles quadratic programs\nimport LinearAlgebra\nimport Plots\nimport Random","category":"section"},{"location":"examples/autotuning-ridge/#Generating-a-noisy-regression-dataset","page":"Auto-tuning Hyperparameters","title":"Generating a noisy regression dataset","text":"Random.seed!(42)\n\nN = 100\nD = 20\nnoise = 5\n\nw_real = 10 * randn(D)\nX = 10 * randn(N, D)\ny = X * w_real + noise * randn(N)\nl = N Ã· 2  # test train split\n\nX_train = X[1:l, :]\nX_test = X[(l+1):N, :]\ny_train = y[1:l]\ny_test = y[(l+1):N];\nnothing #hide","category":"section"},{"location":"examples/autotuning-ridge/#Defining-the-regression-problem","page":"Auto-tuning Hyperparameters","title":"Defining the regression problem","text":"We implement the regularized regression problem as a function taking the problem data, building a JuMP model and solving it.\n\nfunction fit_ridge(model, X, y, Î±)\n    JuMP.empty!(model)\n    set_silent(model)\n    N, D = size(X)\n    @variable(model, w[1:D])\n    @expression(model, err_term, X * w - y)\n    @objective(\n        model,\n        Min,\n        LinearAlgebra.dot(err_term, err_term) / (2 * N * D) +\n        Î± * LinearAlgebra.dot(w, w) / (2 * D),\n    )\n    optimize!(model)\n    @assert termination_status(model) in\n            [MOI.OPTIMAL, MOI.LOCALLY_SOLVED, MOI.ALMOST_LOCALLY_SOLVED]\n    return w\nend\n\nWe can solve the problem for several values of Î± to visualize the effect of regularization on the testing and training loss.\n\nÎ±s = 0.00:0.01:0.50\nmse_test = Float64[]\nmse_train = Float64[]\nmodel = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer))\n(Ntest, D) = size(X_test)\n(Ntrain, D) = size(X_train)\nfor Î± in Î±s\n    w = fit_ridge(model, X_train, y_train, Î±)\n    wÌ‚ = value.(w)\n    yÌ‚_test = X_test * wÌ‚\n    yÌ‚_train = X_train * wÌ‚\n    push!(mse_test, LinearAlgebra.norm(yÌ‚_test - y_test)^2 / (2 * Ntest * D))\n    push!(\n        mse_train,\n        LinearAlgebra.norm(yÌ‚_train - y_train)^2 / (2 * Ntrain * D),\n    )\nend\n\nVisualize the Mean Score Error metric\n\nPlots.plot(\n    Î±s,\n    mse_test ./ sum(mse_test);\n    label = \"MSE test\",\n    xaxis = \"Î±\",\n    yaxis = \"MSE\",\n    legend = (0.8, 0.2),\n    width = 3,\n)\nPlots.plot!(\n    Î±s,\n    mse_train ./ sum(mse_train);\n    label = \"MSE train\",\n    linestyle = :dash,\n    width = 3,\n)\nPlots.title!(\"Normalized MSE on training and testing sets\")","category":"section"},{"location":"examples/autotuning-ridge/#Leveraging-differentiable-optimization:-computing-the-derivative-of-the-solution","page":"Auto-tuning Hyperparameters","title":"Leveraging differentiable optimization: computing the derivative of the solution","text":"Using DiffOpt, we can compute âˆ‚w_i/âˆ‚Î±, the derivative of the learned solution Ì‚w w.r.t. the regularization parameter.\n\nfunction compute_dw_dÎ±(model, w)\n    D = length(w)\n    dw_dÎ± = zeros(D)\n    MOI.set(\n        model,\n        DiffOpt.ForwardObjectiveFunction(),\n        LinearAlgebra.dot(w, w) / (2 * D),\n    )\n    DiffOpt.forward_differentiate!(model)\n    for i in 1:D\n        dw_dÎ±[i] = MOI.get(model, DiffOpt.ForwardVariablePrimal(), w[i])\n    end\n    return dw_dÎ±\nend\n\nUsing âˆ‚w_i/âˆ‚Î± computed with compute_dw_dÎ±, we can compute the derivative of the test loss w.r.t. the parameter Î± by composing derivatives.\n\nfunction d_testloss_dÎ±(model, X_test, y_test, w, wÌ‚)\n    N, D = size(X_test)\n    dw_dÎ± = compute_dw_dÎ±(model, w)\n    err_term = X_test * wÌ‚ - y_test\n    return sum(eachindex(err_term)) do i\n        return LinearAlgebra.dot(X_test[i, :], dw_dÎ±) * err_term[i]\n    end / (N * D)\nend\n\nWe can define a meta-optimizer function performing gradient descent on the test loss w.r.t. the regularization parameter.\n\nfunction descent(Î±0, max_iters = 100; fixed_step = 0.01, grad_tol = 1e-3)\n    Î±_s = Float64[]\n    âˆ‚Î±_s = Float64[]\n    test_loss = Float64[]\n    Î± = Î±0\n    N, D = size(X_test)\n    model = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer))\n    for iter in 1:max_iters\n        w = fit_ridge(model, X_train, y_train, Î±)\n        wÌ‚ = value.(w)\n        err_term = X_test * wÌ‚ - y_test\n        âˆ‚Î± = d_testloss_dÎ±(model, X_test, y_test, w, wÌ‚)\n        push!(Î±_s, Î±)\n        push!(âˆ‚Î±_s, âˆ‚Î±)\n        push!(test_loss, LinearAlgebra.norm(err_term)^2 / (2 * N * D))\n        Î± -= fixed_step * âˆ‚Î±\n        if abs(âˆ‚Î±) â‰¤ grad_tol\n            break\n        end\n    end\n    return Î±_s, âˆ‚Î±_s, test_loss\nend\n\nÎ±Ì„, âˆ‚Î±Ì„, mseÌ„ = descent(0.10, 500)\niters = 1:length(Î±Ì„);\nnothing #hide\n\nVisualize gradient descent and convergence\n\nPlots.plot(\n    Î±s,\n    mse_test;\n    label = \"MSE test\",\n    xaxis = (\"Î±\"),\n    legend = :topleft,\n    width = 2,\n)\nPlots.plot!(Î±Ì„, mseÌ„; label = \"learned Î±\", width = 5, style = :dot)\nPlots.title!(\"Regularizer learning\")\n\nVisualize the convergence of Î± to its optimal value\n\nPlots.plot(\n    iters,\n    Î±Ì„;\n    label = nothing,\n    color = :blue,\n    xaxis = (\"Iterations\"),\n    legend = :bottom,\n    title = \"Convergence of Î±\",\n)\n\nVisualize the convergence of the objective function\n\nPlots.plot(\n    iters,\n    mseÌ„;\n    label = nothing,\n    color = :red,\n    xaxis = (\"Iterations\"),\n    legend = :bottom,\n    title = \"Convergence of MSE\",\n)\n\nVisualize the convergence of the derivative to zero\n\nPlots.plot(\n    iters,\n    âˆ‚Î±Ì„;\n    label = nothing,\n    color = :green,\n    xaxis = (\"Iterations\"),\n    legend = :bottom,\n    title = \"Convergence of âˆ‚Î±\",\n)\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/polyhedral_project/#Polyhedral-QP-layer","page":"Polyhedral QP layer","title":"Polyhedral QP layer","text":"(Image: )\n\nWe use DiffOpt to define a custom network layer which, given an input matrix y, computes its projection onto a polytope defined by a fixed number of inequalities: a_i^T x â‰¥ b_i. A neural network is created using Flux.jl and trained on the MNIST dataset, integrating this quadratic optimization layer.\n\nThe QP is solved in the forward pass, and its DiffOpt derivative is used in the backward pass expressed with ChainRulesCore.rrule.\n\nThis example is similar to the custom ReLU layer, except that the layer is parameterized by the hyperplanes (w,b) and not a simple stateless function. This also means that ChainRulesCore.rrule must return the derivatives of the output with respect to the layer parameters to allow for backpropagation.\n\nusing JuMP\nimport DiffOpt\nimport Ipopt\nimport ChainRulesCore\nimport Flux\nimport MLDatasets\nimport Statistics\nusing Base.Iterators: repeated\nusing LinearAlgebra\nusing Random\n\nRandom.seed!(42)","category":"section"},{"location":"examples/polyhedral_project/#The-Polytope-representation-and-its-derivative","page":"Polyhedral QP layer","title":"The Polytope representation and its derivative","text":"struct Polytope{N}\n    w::NTuple{N,Vector{Float64}}\n    b::Vector{Float64}\nend\n\nPolytope(w::NTuple{N}) where {N} = Polytope{N}(w, randn(N))\n\nWe define a \"call\" operation on the polytope, making it a so-called functor. Calling the polytope with a matrix y operates an Euclidean projection of this matrix onto the polytope.\n\nfunction (polytope::Polytope{N})(\n    y::AbstractMatrix;\n    model = direct_model(DiffOpt.diff_optimizer(Ipopt.Optimizer)),\n) where {N}\n    layer_size, batch_size = size(y)\n    empty!(model)\n    set_silent(model)\n    @variable(model, x[1:layer_size, 1:batch_size])\n    @constraint(\n        model,\n        greater_than_cons[idx in 1:N, sample in 1:batch_size],\n        dot(polytope.w[idx], x[:, sample]) â‰¥ polytope.b[idx]\n    )\n    @objective(model, Min, dot(x - y, x - y))\n    optimize!(model)\n    return Float32.(JuMP.value.(x))\nend\n\nThe @functor macro from Flux implements auxiliary functions for collecting the parameters of our custom layer and operating backpropagation.\n\nFlux.@functor Polytope\n\nDefine the reverse differentiation rule, for the function we defined above. Flux uses ChainRules primitives to implement reverse-mode differentiation of the whole network. To learn the current layer (the polytope the layer contains), the gradient is computed with respect to the Polytope fields in a ChainRulesCore.Tangent type which is used to represent derivatives with respect to structs. For more details about backpropagation, visit Introduction, ChainRulesCore.jl.\n\nfunction ChainRulesCore.rrule(\n    polytope::Polytope{N},\n    y::AbstractMatrix,\n) where {N}\n    model = direct_model(DiffOpt.diff_optimizer(Ipopt.Optimizer))\n    xv = polytope(y; model = model)\n    function pullback_matrix_projection(dl_dx)\n        dl_dx = ChainRulesCore.unthunk(dl_dx)\n        #  `dl_dy` is the derivative of `l` wrt `y`\n        x = model[:x]::Matrix{JuMP.VariableRef}\n        layer_size, batch_size = size(x)\n        # grad wrt input parameters\n        dl_dy = zeros(size(x))\n        # grad wrt layer parameters\n        dl_dw = zero.(polytope.w)\n        dl_db = zero(polytope.b)\n        # set sensitivities\n        MOI.set.(model, DiffOpt.ReverseVariablePrimal(), x, dl_dx)\n        # compute grad\n        DiffOpt.reverse_differentiate!(model)\n        # compute gradient wrt objective function parameter y\n        obj_expr = MOI.get(model, DiffOpt.ReverseObjectiveFunction())\n        dl_dy .= -2 * JuMP.coefficient.(obj_expr, x)\n        greater_than_cons = model[:greater_than_cons]\n        for idx in 1:N, sample in 1:batch_size\n            cons_expr = MOI.get(\n                model,\n                DiffOpt.ReverseConstraintFunction(),\n                greater_than_cons[idx, sample],\n            )\n            dl_db[idx] -= JuMP.constant(cons_expr) / batch_size\n            dl_dw[idx] .+=\n                JuMP.coefficient.(cons_expr, x[:, sample]) / batch_size\n        end\n        dself = ChainRulesCore.Tangent{Polytope{N}}(; w = dl_dw, b = dl_db)\n        return (dself, dl_dy)\n    end\n    return xv, pullback_matrix_projection\nend","category":"section"},{"location":"examples/polyhedral_project/#Define-the-Network","page":"Polyhedral QP layer","title":"Define the Network","text":"layer_size = 20\nm = Flux.Chain(\n    Flux.Dense(784, layer_size), # 784 being image linear dimension (28 x 28)\n    Polytope((randn(layer_size), randn(layer_size), randn(layer_size))),\n    Flux.Dense(layer_size, 10), # 10 being the number of outcomes (0 to 9)\n    Flux.softmax,\n)","category":"section"},{"location":"examples/polyhedral_project/#Prepare-data","page":"Polyhedral QP layer","title":"Prepare data","text":"M = 500 # batch size\n# Preprocessing train data\nimgs = MLDatasets.MNIST(; split = :train).features[:, :, 1:M]\nlabels = MLDatasets.MNIST(; split = :train).targets[1:M]\ntrain_X = float.(reshape(imgs, size(imgs, 1) * size(imgs, 2), M)) # stack images\ntrain_Y = Flux.onehotbatch(labels, 0:9);\n# Preprocessing test data\ntest_imgs = MLDatasets.MNIST(; split = :test).features[:, :, 1:M]\ntest_labels = MLDatasets.MNIST(; split = :test).targets[1:M]\ntest_X = float.(reshape(test_imgs, size(test_imgs, 1) * size(test_imgs, 2), M))\ntest_Y = Flux.onehotbatch(test_labels, 0:9);\nnothing #hide\n\nDefine input data The original data is repeated epochs times because Flux.train! only loops through the data set once\n\nepochs = 50\ndataset = repeated((train_X, train_Y), epochs);\nnothing #hide","category":"section"},{"location":"examples/polyhedral_project/#Network-training","page":"Polyhedral QP layer","title":"Network training","text":"training loss function, Flux optimizer\n\ncustom_loss(m, x, y) = Flux.crossentropy(m(x), y)\nopt = Flux.setup(Flux.Adam(), m)\n\nTrain to optimize network parameters\n\n@time Flux.train!(custom_loss, m, dataset, opt);\nnothing #hide\n\nAlthough our custom implementation takes time, it is able to reach similar accuracy as the usual ReLU function implementation.","category":"section"},{"location":"examples/polyhedral_project/#Accuracy-results","page":"Polyhedral QP layer","title":"Accuracy results","text":"Average of correct guesses\n\naccuracy(x, y) = Statistics.mean(Flux.onecold(m(x)) .== Flux.onecold(y));\nnothing #hide\n\nTraining accuracy\n\naccuracy(train_X, train_Y)\n\nTest accuracy\n\naccuracy(test_X, test_Y)\n\nNote that the accuracy is low due to simplified training. It is possible to increase the number of samples N, the number of epochs epoch and the connectivity inner.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/sensitivity-analysis-svm_new/#Sensitivity-Analysis-of-SVM","page":"Sensitivity Analysis of SVM","title":"Sensitivity Analysis of SVM","text":"(Image: )\n\nThis notebook illustrates sensitivity analysis of data points in a Support Vector Machine (inspired from @matbesancon's SimpleSVMs.)\n\nFor reference, Section 10.1 of https://online.stat.psu.edu/stat508/book/export/html/792 gives an intuitive explanation of what it means to have a sensitive hyperplane or data point. The general form of the SVM training problem is given below (with ell_2 regularization):\n\nbeginsplit\nbeginarray ll\nmboxminimize  lambdaw^2 + sum_i=1^N xi_i \nmboxst  xi_i ge 0 quad quad i=1N  \n             y_i (w^T X_i + b) ge 1 - xi_i quad i=1N  \nendarray\nendsplit\n\nwhere\n\nX, y are the N data points\nw is the support vector\nb determines the offset b/||w|| of the hyperplane with normal w\nÎ¾ is the soft-margin loss\nÎ» is the ell_2 regularization.\n\nThis tutorial uses the following packages\n\nusing JuMP     # The mathematical programming modelling language\nimport DiffOpt # JuMP extension for differentiable optimization\nimport Ipopt   # Optimization solver that handles quadratic programs\nimport LinearAlgebra\nimport Plots\nimport Random","category":"section"},{"location":"examples/sensitivity-analysis-svm_new/#Define-and-solve-the-SVM","page":"Sensitivity Analysis of SVM","title":"Define and solve the SVM","text":"Construct two clusters of data points.\n\nN = 100\nD = 2\n\nRandom.seed!(62)\nX_data = vcat(randn(N Ã· 2, D), randn(N Ã· 2, D) .+ [2.0, 2.0]')\ny = append!(ones(N Ã· 2), -ones(N Ã· 2))\nÎ» = 0.05;\nnothing #hide\n\nLet's initialize a special model that can understand sensitivities\n\nmodel = DiffOpt.quadratic_diff_model(Ipopt.Optimizer)\nset_silent(model)\n\nAdd the variables\n\n@variable(model, Î¾[1:N] >= 0)\n@variable(model, w[1:D])\n@variable(model, b);\nnothing #hide\n\nAdd the parameters to be differentiated\n\n@variable(model, X[1:N, 1:D] in Parameter.(X_data))\n\nAdd the constraints\n\n@constraint(\n    model,\n    con[i in 1:N],\n    y[i] * (LinearAlgebra.dot(X[i, :], w) + b) >= 1 - Î¾[i]\n);\nnothing #hide\n\nDefine the objective and solve\n\n@objective(model, Min, Î» * LinearAlgebra.dot(w, w) + sum(Î¾))\n\noptimize!(model)\n\nWe can visualize the separating hyperplane.\n\nloss = objective_value(model)\n\nwv = value.(w)\n\nbv = value(b)\n\nsvm_x = [-2.0, 4.0] # arbitrary points\nsvm_y = (-bv .- wv[1] * svm_x) / wv[2]\n\np = Plots.scatter(\n    X_data[:, 1],\n    X_data[:, 2];\n    color = [yi > 0 ? :red : :blue for yi in y],\n    label = \"\",\n)\nPlots.plot!(\n    p,\n    svm_x,\n    svm_y;\n    label = \"loss = $(round(loss, digits=2))\",\n    width = 3,\n)","category":"section"},{"location":"examples/sensitivity-analysis-svm_new/#Gradient-of-hyperplane-wrt-the-data-point-coordinates","page":"Sensitivity Analysis of SVM","title":"Gradient of hyperplane wrt the data point coordinates","text":"Now that we've solved the SVM, we can compute the sensitivity of optimal values â€“ the separating hyperplane in our case â€“ with respect to perturbations of the problem data â€“ the data points â€“ using DiffOpt.\n\nHow does a change in coordinates of the data points, X, affects the position of the hyperplane? This is achieved by finding gradients of w and b with respect to X[i].\n\nBegin differentiating the model. analogous to varying Î¸ in the expression:\n\ny_i (w^T (X_i + theta) + b) ge 1 - xi_i\n\nâˆ‡ = zeros(N)\nfor i in 1:N\n    for j in 1:N\n        if i == j\n            # we consider identical perturbations on all x_i coordinates\n            DiffOpt.set_forward_parameter.(model, X[i, :], 1.0)\n        else\n            DiffOpt.set_forward_parameter.(model, X[i, :], 0.0)\n        end\n    end\n    DiffOpt.forward_differentiate!(model)\n    dw = DiffOpt.get_forward_variable.(model, w)\n    db = DiffOpt.get_forward_variable.(model, b)\n    âˆ‡[i] = LinearAlgebra.norm(dw) + LinearAlgebra.norm(db)\nend\n\nWe can visualize the separating hyperplane sensitivity with respect to the data points. Note that all the small numbers were converted into 1/10 of the largest value to show all the points of the set.\n\np3 = Plots.scatter(\n    X_data[:, 1],\n    X_data[:, 2];\n    color = [yi > 0 ? :red : :blue for yi in y],\n    label = \"\",\n    markersize = 2 * (max.(1.8âˆ‡, 0.2 * maximum(âˆ‡))),\n)\nPlots.yaxis!(p3, (-2, 4.5))\nPlots.plot!(p3, svm_x, svm_y; label = \"\", width = 3)\nPlots.title!(\"Sensitivity of the separator to data point variations\")\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"reference/#Reference","page":"Reference","title":"Reference","text":"","category":"section"},{"location":"reference/#DiffOpt.AbstractLazyScalarFunction","page":"Reference","title":"DiffOpt.AbstractLazyScalarFunction","text":"abstract type AbstractLazyScalarFunction <: MOI.AbstractScalarFunction end\n\nSubtype of MOI.AbstractScalarFunction that is not a standard MOI scalar function but can be converted to one using standard_form.\n\nThe function can also be inspected lazily using JuMP.coefficient or quad_sym_half.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.AbstractModel","page":"Reference","title":"DiffOpt.AbstractModel","text":"abstract type AbstractModel <: MOI.ModelLike end\n\nModel supporting forward_differentiate! and reverse_differentiate!.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.DifferentiateTimeSec","page":"Reference","title":"DiffOpt.DifferentiateTimeSec","text":"DifferentiateTimeSec()\n\nA model attribute for the total elapsed time (in seconds) for computing the differentiation information.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ForwardConstraintDual","page":"Reference","title":"DiffOpt.ForwardConstraintDual","text":"ForwardConstraintDual <: MOI.AbstractConstraintAttribute\n\nA MOI.AbstractConstraintAttribute to get output data from forward differentiation for the dual variable.\n\nFor instance, to get the sensitivity of the dual of constraint of index ci with respect to the parameter perturbation, do the following:\n\nMOI.get(model, DiffOpt.ForwardConstraintDual(), ci)\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ForwardConstraintFunction","page":"Reference","title":"DiffOpt.ForwardConstraintFunction","text":"ForwardConstraintFunction <: MOI.AbstractConstraintAttribute\n\nA MOI.AbstractConstraintAttribute to set input data to forward differentiation, that is, problem input data.\n\nFor instance, if the scalar constraint of index ci contains Î¸ * (x + 2y) <= 5Î¸, for the purpose of computing the derivative with respect to Î¸, the following should be set:\n\nMOI.set(model, DiffOpt.ForwardConstraintFunction(), ci, 1.0 * x + 2.0 * y - 5.0)\n\nNote that we use -5 as the ForwardConstraintFunction sets the tangent of the ConstraintFunction so we consider the expression Î¸ * (x + 2y - 5).\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ForwardConstraintSet","page":"Reference","title":"DiffOpt.ForwardConstraintSet","text":"ForwardConstraintSet <: MOI.AbstractConstraintAttribute\n\nA MOI.AbstractConstraintAttribute to set input data to forward differentiation, that is, problem input data.\n\nCurrently, this only works for the set MOI.Parameter.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ForwardObjectiveFunction","page":"Reference","title":"DiffOpt.ForwardObjectiveFunction","text":"ForwardObjectiveFunction <: MOI.AbstractModelAttribute\n\nA MOI.AbstractModelAttribute to set input data to forward differentiation, that is, problem input data. The possible values are any MOI.AbstractScalarFunction. A MOI.ScalarQuadraticFunction can only be used in linearly constrained quadratic models.\n\nFor instance, if the objective contains Î¸ * (x + 2y), for the purpose of computing the derivative with respect to Î¸, the following should be set:\n\nMOI.set(model, DiffOpt.ForwardObjectiveFunction(), 1.0 * x + 2.0 * y)\n\nwhere x and y are the relevant MOI.VariableIndex.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ForwardObjectiveSensitivity","page":"Reference","title":"DiffOpt.ForwardObjectiveSensitivity","text":"ForwardObjectiveSensitivity <: MOI.AbstractModelAttribute\n\nA MOI.AbstractModelAttribute to get output objective sensitivity data from forward differentiation.\n\nFor instance, to get the sensitivity of the objective function with respect to the parameter perturbation, do the following:\n\nMOI.get(model, DiffOpt.ForwardObjectiveSensitivity())\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ForwardVariablePrimal","page":"Reference","title":"DiffOpt.ForwardVariablePrimal","text":"ForwardVariablePrimal <: MOI.AbstractVariableAttribute\n\nA MOI.AbstractVariableAttribute to get output data from forward differentiation, that is, problem solution.\n\nFor instance, to get the tangent of the variable of index vi corresponding to the tangents given to ForwardObjectiveFunction and ForwardConstraintFunction, do the following:\n\nMOI.get(model, DiffOpt.ForwardVariablePrimal(), vi)\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.IndexMappedFunction","page":"Reference","title":"DiffOpt.IndexMappedFunction","text":"IndexMappedFunction{F<:MOI.AbstractFunction} <: AbstractLazyScalarFunction\n\nLazily represents the function MOI.Utilities.map_indices(index_map, DiffOpt.standard_form(func)).\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.MOItoJuMP","page":"Reference","title":"DiffOpt.MOItoJuMP","text":"MOItoJuMP{F<:MOI.AbstractScalarFunction} <: JuMP.AbstractJuMPScalar\n\nLazily represents the function JuMP.jump_function(model, DiffOpt.standard_form(func)).\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.MatrixScalarQuadraticFunction","page":"Reference","title":"DiffOpt.MatrixScalarQuadraticFunction","text":"struct MatrixScalarQuadraticFunction{T, VT, MT} <: MOI.AbstractScalarFunction\n    affine::VectorScalarAffineFunction{T,VT}\n    terms::MT\nend\n\nRepresents the function x' * terms * x / 2 + affine as an MOI.AbstractScalarFunction where x[i] = MOI.VariableIndex(i). Use standard_form to convert it to a MOI.ScalarQuadraticFunction{T}.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.MatrixVectorAffineFunction","page":"Reference","title":"DiffOpt.MatrixVectorAffineFunction","text":"MatrixVectorAffineFunction{T, VT} <: MOI.AbstractVectorFunction\n\nRepresents the function terms * x + constant as an MOI.AbstractVectorFunction where x[i] = MOI.VariableIndex(i). Use standard_form to convert it to a MOI.VectorAffineFunction{T}.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ModelConstructor","page":"Reference","title":"DiffOpt.ModelConstructor","text":"ModelConstructor <: MOI.AbstractOptimizerAttribute\n\nDetermines which subtype of DiffOpt.AbstractModel to use for differentiation. When set to nothing, the first one out of model.model_constructors that support the problem is used.\n\nExamples:\n\njulia> MOI.set(model, DiffOpt.ModelConstructor(), DiffOpt.QuadraticProgram.Model)\n\njulia> MOI.set(model, DiffOpt.ModelConstructor(), DiffOpt.ConicProgram.Model)\n\njulia> MOI.set(model, DiffOpt.ModelConstructor(), DiffOpt.NonlinearProgram.Model)\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.NonLinearKKTJacobianFactorization","page":"Reference","title":"DiffOpt.NonLinearKKTJacobianFactorization","text":"NonLinearKKTJacobianFactorization <: MOI.AbstractModelAttribute\n\nA MOI.AbstractModelAttribute to set which factorization method to use for the nonlinear KKT Jacobian matrix, necessary for the implict function diferentiation for NonLinearProgram models.\n\nThe function will be called with the following signature:\n\nfunction factorization(M::SparseMatrixCSC{T<Real}, # The matrix to factorize\n    model::NonLinearProgram.Model (can be ignored - useful for inertia correction)\n)\n\nM is the matrix to factorize.\nmodel is the nonlinear model data that generated M. This can be used for\n\nsome factorization techniques such as LU with inertia correction.\n\nCan be set by the user to use a custom factorization function:\n\nMOI.set(model, DiffOpt.NonLinearKKTJacobianFactorization(), factorization)\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ObjectiveFunctionAttribute","page":"Reference","title":"DiffOpt.ObjectiveFunctionAttribute","text":"struct ObjectiveFunctionAttribute{A,F} <: MOI.AbstractModelAttribute\n    attr::A\nend\n\nObjective function attribute attr for the function type F. The type F is used by a MOI.Bridges.AbstractBridgeOptimizer to keep track of its position in a chain of objective bridges.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ProductOfSets","page":"Reference","title":"DiffOpt.ProductOfSets","text":"ProductOfSets{T} <: MOI.Utilities.OrderedProductOfSets{T}\n\nThe MOI.Utilities.@product_of_sets macro requires to know the list of sets at compile time. In DiffOpt however, the list depends on what the user is going to use as set as DiffOpt supports any set as long as it implements the required function of MathOptSetDistances. For this type, the list of sets can be given a run-time.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ReverseConstraintDual","page":"Reference","title":"DiffOpt.ReverseConstraintDual","text":"ReverseConstraintDual <: MOI.AbstractConstraintAttribute\n\nA MOI.AbstractConstraintAttribute to set input data from reverse differentiation.\n\nFor instance, to set the sensitivity value with respect to the dual variable of constraint with index ci do the following:\n\nMOI.set(model, DiffOpt.ReverseConstraintDual(), ci, value)\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ReverseConstraintFunction","page":"Reference","title":"DiffOpt.ReverseConstraintFunction","text":"ReverseConstraintFunction\n\nAn MOI.AbstractConstraintAttribute to get output data to reverse differentiation, that is, problem input data.\n\nFor instance, if the following returns x + 2y + 5, it means that the tangent has coordinate 1 for the coefficient of x, coordinate 2 for the coefficient of y and 5 for the function constant. If the constraint is of the form func == constant or func <= constant, the tangent for the constant on the right-hand side is -5.\n\nMOI.get(model, DiffOpt.ReverseConstraintFunction(), ci)\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ReverseConstraintSet","page":"Reference","title":"DiffOpt.ReverseConstraintSet","text":"ReverseConstraintSet\n\nAn MOI.AbstractConstraintAttribute to get output data to reverse differentiation, that is, problem input data.\n\nCurrently, this only works for the set MOI.Parameter.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ReverseObjectiveFunction","page":"Reference","title":"DiffOpt.ReverseObjectiveFunction","text":"ReverseObjectiveFunction <: MOI.AbstractModelAttribute\n\nA MOI.AbstractModelAttribute to get output data to reverse differentiation, that is, problem input data.\n\nFor instance, to get the tangent of the objective function corresponding to the tangent given to ReverseVariablePrimal, do the following:\n\nfunc = MOI.get(model, DiffOpt.ReverseObjectiveFunction())\n\nThen, to get the sensitivity of the linear term with variable x, do\n\nJuMP.coefficient(func, x)\n\nTo get the sensitivity with respect to the quadratic term with variables x and y, do either\n\nJuMP.coefficient(func, x, y)\n\nor\n\nDiffOpt.quad_sym_half(func, x, y)\n\nwarning: Warning\nThese two lines are not equivalent in case x == y, see quad_sym_half for the details on the difference between these two functions.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ReverseObjectiveSensitivity","page":"Reference","title":"DiffOpt.ReverseObjectiveSensitivity","text":"ReverseObjectiveSensitivity <: MOI.AbstractModelAttribute\n\nA MOI.AbstractModelAttribute to set input data for reverse differentiation.\n\nFor instance, to set the sensitivity of the parameter perturbation with respect to the objective function perturbation, do the following:\n\nMOI.set(model, DiffOpt.ReverseObjectiveSensitivity(), value)\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.ReverseVariablePrimal","page":"Reference","title":"DiffOpt.ReverseVariablePrimal","text":"ReverseVariablePrimal <: MOI.AbstractVariableAttribute\n\nA MOI.AbstractVariableAttribute to set input data to reverse differentiation, that is, problem solution.\n\nFor instance, to set the tangent of the variable of index vi, do the following:\n\nMOI.set(model, DiffOpt.ReverseVariablePrimal(), x)\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.SparseVectorAffineFunction","page":"Reference","title":"DiffOpt.SparseVectorAffineFunction","text":"struct SparseVectorAffineFunction{T} <: MOI.AbstractVectorFunction\n    terms::SparseArrays.SparseMatrixCSC{T,Int}\n    constants::Vector{T}\nend\n\nThe vector-valued affine function A x + b, where:\n\nA is the sparse matrix given by terms\nb is the vector constants\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.VectorScalarAffineFunction","page":"Reference","title":"DiffOpt.VectorScalarAffineFunction","text":"VectorScalarAffineFunction{T, VT} <: MOI.AbstractScalarFunction\n\nRepresents the function x â‹… terms + constant as an MOI.AbstractScalarFunction where x[i] = MOI.VariableIndex(i). Use standard_form to convert it to a MOI.ScalarAffineFunction{T}.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.DÏ€-Union{Tuple{T}, Tuple{Vector{T}, MathOptInterface.ModelLike, DiffOpt.ProductOfSets}} where T","page":"Reference","title":"DiffOpt.DÏ€","text":"DÏ€(v::Vector{Float64}, model, cones::ProductOfSets)\n\nGiven a model, its cones, find the gradient of the projection of the vectors v of length equal to the number of rows in the conic form onto the cartesian product of the cones corresponding to these rows. For more info, refer to https://github.com/matbesancon/MathOptSetDistances.jl\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.add_all_model_constructors-Tuple{Any}","page":"Reference","title":"DiffOpt.add_all_model_constructors","text":"add_all_model_constructors(model)\n\nAdd all constructors of AbstractModel defined in this package to model with add_model_constructor.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.add_model_constructor-Tuple{DiffOpt.Optimizer, Any}","page":"Reference","title":"DiffOpt.add_model_constructor","text":"addmodelconstructor(optimizer::Optimizer, model_constructor)\n\nAdd the constructor of AbstractModel for optimizer to choose from when trying to differentiate.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.conic_diff_model-Tuple{Any}","page":"Reference","title":"DiffOpt.conic_diff_model","text":"conic_diff_model(optimizer_constructor; with_bridge_type = Float64, with_cache_type = Float64, with_outer_cache = true)\n\nCreate a JuMP model with a differentiable optimizer for conic programs. The optimizer is created using optimizer_constructor.\n\nSee also: nonlinear_diff_model, quadratic_diff_model, diff_model.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.dU_from_dQ!-Tuple{Any, Any}","page":"Reference","title":"DiffOpt.dU_from_dQ!","text":"dU_from_dQ!(dQ, U)\n\nReturn the solution dU of the matrix equation dQ = dU' * U + U' * dU where dQ and U are the two argument of the function.\n\nThis function overwrites the first argument dQ to store the solution. The matrix U is not however modified.\n\nThe matrix dQ is assumed to be symmetric and the matrix U is assumed to be upper triangular.\n\nWe can exploit the structure of U here:\n\nIf the factorization was obtained from SVD, U would be orthogonal\nIf the factorization was obtained from Cholesky, U would be upper triangular.\n\nThe MOI bridge uses Cholesky in order to exploit sparsity so we are in the second case.\n\nWe look for an upper triangular dU as well.\n\nWe can find each column of dU by solving a triangular linear system once the previous column have been found. Indeed, let dj be the jth column of dU dU' * U = vcat(dj'U for j in axes(U, 2)) Therefore, dQ[j, 1:j] = dj'U[:, 1:j] + U[:, j]'dU[:, 1:j]SodQ[j, 1:(j-1)] - U[:, j]' * dU[:, 1:(j-1)] = dj'U[:, 1:(j-1)]anddQ[j, j] / 2 = dj'U[:, j]`\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.diff_model-Tuple{Any}","page":"Reference","title":"DiffOpt.diff_model","text":"diff_model(optimizer_constructor; with_bridge_type = Float64, with_cache_type = Float64, with_outer_cache = true)\n\nCreate a JuMP model with a differentiable optimizer. The optimizer is created using optimizer_constructor. This model will try to select the proper differentiable optimization method based on the problem structure.\n\nSee also: nonlinear_diff_model, conic_diff_model, quadratic_diff_model.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.diff_optimizer-Tuple{Any}","page":"Reference","title":"DiffOpt.diff_optimizer","text":"function diff_optimizer(\n    optimizer_constructor;\n    with_bridge_type = Float64,\n    with_cache_type = Float64,\n    with_outer_cache = !isnothing(with_bridge_type),\n    allow_parametric_opt_interface = true,\n)\n\nCreates a DiffOpt.Optimizer, which is an MOI layer with an internal optimizer and other utility methods. Results (primal, dual and slack values) are obtained by querying the internal optimizer instantiated using the optimizer_constructor. These values are required for find jacobians with respect to problem data.\n\nThe inner optimizer is instantiated with MOI.instantiate(optimizer_constructor; with_bridge_type, with_cache_type); see the docs of MOI.instantiate.\n\nIf allow_parametric_opt_interface is true and the inner optimizer does not natively (in the sense, without the bridge layer) supports ParameterSet, then a ParametricOptInterface.Optimizer layer is added.\n\nIf with_outer_cache is true, an additional layer of cache is added.\n\nOne define a differentiable model by using any solver of choice. Example:\n\njulia> import DiffOpt, HiGHS\n\njulia> model = DiffOpt.diff_optimizer(HiGHS.Optimizer)\njulia> set_attribute(model, DiffOpt.ModelConstructor, DiffOpt.QuadraticProgram.Model) # optional selection of diff method\njulia> x = model.add_variable(model)\njulia> model.add_constraint(model, ...)\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.empty_input_sensitivities!","page":"Reference","title":"DiffOpt.empty_input_sensitivities!","text":"empty_input_sensitivities!(model::MOI.ModelLike)\n\nEmpty the input sensitivities of the model. Sets to zero all the sensitivities set by the user with method such as:\n\nMOI.set(model, DiffOpt.ReverseVariablePrimal(), variable_index, value)\nMOI.set(model, DiffOpt.ForwardObjectiveFunction(), expression)\nMOI.set(model, DiffOpt.ForwardConstraintFunction(), index, expression)\n\n\n\n\n\n","category":"function"},{"location":"reference/#DiffOpt.forward_differentiate!","page":"Reference","title":"DiffOpt.forward_differentiate!","text":"forward_differentiate!(model::Optimizer)\n\nWrapper method for the forward pass. This method will consider as input a currently solved problem and differentials with respect to problem data set with the ForwardObjectiveFunction and  ForwardConstraintFunction attributes. The output solution differentials can be queried with the attribute ForwardVariablePrimal.\n\n\n\n\n\n","category":"function"},{"location":"reference/#DiffOpt.get_forward_objective-Tuple{JuMP.Model}","page":"Reference","title":"DiffOpt.get_forward_objective","text":"get_forward_objective(model::JuMP.Model)\n\nGet the value of the objective output sensitivity for forward mode.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.get_forward_variable-Tuple{JuMP.Model, JuMP.VariableRef}","page":"Reference","title":"DiffOpt.get_forward_variable","text":"get_forward_variable(model::JuMP.Model, variable::JuMP.VariableRef)\n\nGet the value of a variable output sensitivity for forward mode.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.get_reverse_parameter-Tuple{JuMP.Model, JuMP.VariableRef}","page":"Reference","title":"DiffOpt.get_reverse_parameter","text":"get_reverse_parameter(model::JuMP.Model, variable::JuMP.VariableRef)\n\nGet the value of a parameter output sensitivity for reverse mode.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.map_rows-Tuple{Function, Any, DiffOpt.ProductOfSets, Union{DiffOpt.Flattened, DiffOpt.Nested}}","page":"Reference","title":"DiffOpt.map_rows","text":"map_rows(f::Function, model, cones::ProductOfSets, map_mode::Union{Nested{T}, Flattened{T}})\n\nGiven a model, its cones and map_mode of type Nested (resp. Flattened), return a Vector{T} of length equal to the number of cones (resp. rows) in the conic form where the value for the index (resp. rows) corresponding to each cone is equal to f(ci, r) where ci is the corresponding constraint index in model and r is a UnitRange of the corresponding rows in the conic form.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.nonlinear_diff_model-Tuple{Any}","page":"Reference","title":"DiffOpt.nonlinear_diff_model","text":"nonlinear_diff_model(optimizer_constructor; with_bridge_type = Float64, with_cache_type = Float64, with_outer_cache = true)\n\nCreate a JuMP model with a differentiable optimizer for nonlinear programs. The optimizer is created using optimizer_constructor.\n\nSee also: conic_diff_model, quadratic_diff_model, diff_model.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.quad_sym_half","page":"Reference","title":"DiffOpt.quad_sym_half","text":"quad_sym_half(func, vi1::MOI.VariableIndex, vi2::MOI.VariableIndex)\n\nReturn Q[i,j] = Q[j,i] where the quadratic terms of func is represented by x' Q x / 2 for a symmetric matrix Q where x[i] = vi1 and x[j] = vi2. Note that while this is equal to JuMP.coefficient(func, vi1, vi2) if vi1 != vi2, in the case vi1 == vi2, it is rather equal to 2JuMP.coefficient(func, vi1, vi2).\n\n\n\n\n\n","category":"function"},{"location":"reference/#DiffOpt.quadratic_diff_model-Tuple{Any}","page":"Reference","title":"DiffOpt.quadratic_diff_model","text":"quadratic_diff_model(optimizer_constructor; with_bridge_type = Float64, with_cache_type = Float64, with_outer_cache = true)\n\nCreate a JuMP model with a differentiable optimizer for quadratic programs. The optimizer is created using optimizer_constructor.\n\nSee also: nonlinear_diff_model, conic_diff_model, diff_model.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.reverse_differentiate!","page":"Reference","title":"DiffOpt.reverse_differentiate!","text":"reverse_differentiate!(model::MOI.ModelLike)\n\nWrapper method for the backward pass / reverse differentiation. This method will consider as input a currently solved problem and differentials with respect to the solution set with the ReverseVariablePrimal attribute. The output problem data differentials can be queried with the attributes ReverseObjectiveFunction and ReverseConstraintFunction.\n\n\n\n\n\n","category":"function"},{"location":"reference/#DiffOpt.set_forward_parameter-Tuple{JuMP.Model, JuMP.VariableRef, Number}","page":"Reference","title":"DiffOpt.set_forward_parameter","text":"set_forward_parameter(model::JuMP.Model, variable::JuMP.VariableRef, value::Number)\n\nSet the value of a parameter input sensitivity for forward mode.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.set_reverse_objective-Tuple{JuMP.Model, Number}","page":"Reference","title":"DiffOpt.set_reverse_objective","text":"set_reverse_objective(model::JuMP.Model, value::Number)\n\nSet the value of the objective input sensitivity for reverse mode.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.set_reverse_variable-Tuple{JuMP.Model, JuMP.VariableRef, Number}","page":"Reference","title":"DiffOpt.set_reverse_variable","text":"set_reverse_variable(model::JuMP.Model, variable::JuMP.VariableRef, value::Number)\n\nSet the value of a variable input sensitivity for reverse mode.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.standard_form","page":"Reference","title":"DiffOpt.standard_form","text":"standard_form(func::AbstractLazyScalarFunction)\n\nConverts func to a standard MOI scalar function.\n\nstandard_form(func::MOItoJuMP)\n\nConverts func to a standard JuMP scalar function.\n\n\n\n\n\n","category":"function"},{"location":"reference/#DiffOpt.Î”Q_from_Î”U!-Tuple{Any, Any}","page":"Reference","title":"DiffOpt.Î”Q_from_Î”U!","text":"Î”Q_from_Î”U!(Î”U, U)\n\nReturn the symmetric solution Î”Q of the matrix equation triu(Î”U) = 2triu(U * Î”Q) where Î”U and U are the two argument of the function.\n\nThis function overwrites the first argument Î”U to store the solution. The matrix U is not however modified.\n\nThe matrix U is assumed to be upper triangular.\n\nWe can exploit the structure of U here:\n\nIf the factorization was obtained from SVD, U would be orthogonal\nIf the factorization was obtained from Cholesky, U would be upper triangular.\n\nThe MOI bridge uses Cholesky in order to exploit sparsity so we are in the second case.\n\nWe can find each column of Î”Q by solving a triangular linear system.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.Ï€-Union{Tuple{T}, Tuple{Vector{T}, MathOptInterface.ModelLike, DiffOpt.ProductOfSets}} where T","page":"Reference","title":"DiffOpt.Ï€","text":"Ï€(v::Vector{Float64}, model::MOI.ModelLike, cones::ProductOfSets)\n\nGiven a model, its cones, find the projection of the vectors v of length equal to the number of rows in the conic form onto the cartesian product of the cones corresponding to these rows. For more info, refer to https://github.com/matbesancon/MathOptSetDistances.jl\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.QuadraticProgram.LinearAlgebraSolver","page":"Reference","title":"DiffOpt.QuadraticProgram.LinearAlgebraSolver","text":"LinearAlgebraSolver\n\nOptimizer attribute for the solver to use for the linear algebra operations. Each solver must implement: solve_system(solver, LHS, RHS, iterative::Bool).\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.QuadraticProgram.Model","page":"Reference","title":"DiffOpt.QuadraticProgram.Model","text":"DiffOpt.QuadraticProgram.Model <: DiffOpt.AbstractModel\n\nModel to differentiate quadratic programs.\n\nFor the reverse differentiation, it differentiates the optimal solution z and return product of jacobian matrices (dz / dQ, dz / dq, etc) with the backward pass vector dl / dz\n\nThe method computes the product of\n\njacobian of problem solution z* with respect to  problem parameters set with the DiffOpt.ReverseVariablePrimal\na backward pass vector dl / dz, where l can be a loss function\n\nNote that this method does not returns the actual jacobians.\n\nFor more info refer eqn(7) and eqn(8) of https://arxiv.org/pdf/1703.00443.pdf\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.QuadraticProgram.create_LHS_matrix","page":"Reference","title":"DiffOpt.QuadraticProgram.create_LHS_matrix","text":"create_LHS_matrix(z, Î», Q, G, h, A=nothing)\n\nInverse matrix specified on RHS of eqn(7) in https://arxiv.org/pdf/1703.00443.pdf\n\nHelper method while calling reverse_differentiate!\n\n\n\n\n\n","category":"function"},{"location":"reference/#DiffOpt.QuadraticProgram.solve_system-NTuple{4, Any}","page":"Reference","title":"DiffOpt.QuadraticProgram.solve_system","text":"Default solve_system call uses IterativeSolvers or the default linear solve\n\n\n\n\n\n","category":"method"},{"location":"reference/#MathOptInterface.get-Tuple{DiffOpt.QuadraticProgram.Model, DiffOpt.ForwardObjectiveSensitivity}","page":"Reference","title":"MathOptInterface.get","text":"Method not supported for DiffOpt.QuadraticProgram.Model directly. However, a fallback is provided in DiffOpt.\n\n\n\n\n\n","category":"method"},{"location":"reference/#MathOptInterface.set-Tuple{DiffOpt.QuadraticProgram.Model, DiffOpt.ReverseObjectiveSensitivity, Any}","page":"Reference","title":"MathOptInterface.set","text":"Method not supported for DiffOpt.QuadraticProgram.Model directly. However, a fallback is provided in DiffOpt.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.ConicProgram.Model","page":"Reference","title":"DiffOpt.ConicProgram.Model","text":"Diffopt.ConicProgram.Model <: DiffOpt.AbstractModel\n\nModel to differentiate conic programs.\n\nThe forward differentiation computes the product of the derivative (Jacobian) at the conic program parameters A, b, c to the perturbations dA, db, dc.\n\nThe reverse differentiation computes the product of the transpose of the derivative (Jacobian) at the conic program parameters A, b, c to the perturbations dx, dy, ds.\n\nFor theoretical background, refer Section 3 of Differentiating Through a Cone Program, https://arxiv.org/abs/1904.09043\n\n\n\n\n\n","category":"type"},{"location":"reference/#MathOptInterface.get-Tuple{DiffOpt.ConicProgram.Model, DiffOpt.ForwardObjectiveSensitivity}","page":"Reference","title":"MathOptInterface.get","text":"Method not supported for DiffOpt.ConicProgram.Model directly. However, a fallback is provided in DiffOpt.\n\n\n\n\n\n","category":"method"},{"location":"reference/#MathOptInterface.set-Tuple{DiffOpt.ConicProgram.Model, DiffOpt.ReverseObjectiveSensitivity, Any}","page":"Reference","title":"MathOptInterface.set","text":"Method not supported for DiffOpt.ConicProgram.Model directly. However, a fallback is provided in DiffOpt.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram.Model","page":"Reference","title":"DiffOpt.NonLinearProgram.Model","text":"DiffOpt.NonLinearProgram.Model <: DiffOpt.AbstractModel\n\nModel to differentiate nonlinear programs.\n\nSupports forward and reverse differentiation, caching sensitivity data for primal variables, constraints, and bounds, excluding slack variables.\n\n\n\n\n\n","category":"type"},{"location":"reference/#DiffOpt.NonLinearProgram._build_sensitivity_matrices-Union{Tuple{Z}, Tuple{DiffOpt.NonLinearProgram.Model, Vector{MathOptInterface.Nonlinear.ConstraintIndex}, AbstractVector, AbstractVector, AbstractVector, AbstractVector, AbstractVector, Vararg{Vector{Z}, 5}}} where Z<:Integer","page":"Reference","title":"DiffOpt.NonLinearProgram._build_sensitivity_matrices","text":"_build_sensitivity_matrices(model::Model, cons::Vector{MOI.Nonlinear.ConstraintIndex}, _X::AbstractVector, _V_L::AbstractVector, _X_L::AbstractVector, _V_U::AbstractVector, _X_U::AbstractVector, leq_locations::Vector{Z}, geq_locations::Vector{Z}, ineq_locations::Vector{Z}, has_up::Vector{Z}, has_low::Vector{Z})\n\nBuild the M (KKT Jacobian w.r.t. solution) and N (KKT Jacobian w.r.t. parameters) matrices for the sensitivity analysis.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._compute_derivatives_no_relax-Union{Tuple{Z}, Tuple{DiffOpt.NonLinearProgram.Model, Vector{MathOptInterface.Nonlinear.ConstraintIndex}, AbstractVector, AbstractVector, AbstractVector, AbstractVector, AbstractVector, Vararg{Vector{Z}, 5}}} where Z<:Integer","page":"Reference","title":"DiffOpt.NonLinearProgram._compute_derivatives_no_relax","text":"_compute_derivatives_no_relax(model::Model, cons::Vector{MOI.Nonlinear.ConstraintIndex},\n    _X::AbstractVector, _V_L::AbstractVector, _X_L::AbstractVector, _V_U::AbstractVector, _X_U::AbstractVector, leq_locations::Vector{Z}, geq_locations::Vector{Z}, ineq_locations::Vector{Z},\n    has_up::Vector{Z}, has_low::Vector{Z}\n)\n\nCompute the derivatives of the solution w.r.t. the parameters without accounting for active set changes.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._compute_optimal_hess_jac-Tuple{DiffOpt.NonLinearProgram.Model, Vector{MathOptInterface.Nonlinear.ConstraintIndex}}","page":"Reference","title":"DiffOpt.NonLinearProgram._compute_optimal_hess_jac","text":"_compute_optimal_hess_jac(evaluator::MOI.Nonlinear.Evaluator, rows::Vector{JuMP.ConstraintRef}, x::Vector{JuMP.VariableRef})\n\nCompute the Hessian of the Lagrangian and Jacobian of the constraints calculated at the optimal solution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._compute_optimal_hessian-Tuple{DiffOpt.NonLinearProgram.Model, Vector{MathOptInterface.Nonlinear.ConstraintIndex}}","page":"Reference","title":"DiffOpt.NonLinearProgram._compute_optimal_hessian","text":"_compute_optimal_hessian(evaluator::MOI.Nonlinear.Evaluator, rows::Vector{JuMP.ConstraintRef}, x::Vector{JuMP.VariableRef})\n\nCompute the Hessian of the Lagrangian calculated at the optimal solution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._compute_optimal_jacobian-Tuple{DiffOpt.NonLinearProgram.Model, Vector{MathOptInterface.Nonlinear.ConstraintIndex}}","page":"Reference","title":"DiffOpt.NonLinearProgram._compute_optimal_jacobian","text":"_compute_optimal_jacobian(evaluator::MOI.Nonlinear.Evaluator, rows::Vector{JuMP.ConstraintRef}, x::Vector{JuMP.VariableRef})\n\nCompute the Jacobian of the constraints calculated at the optimal solution.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._compute_sensitivity-Tuple{DiffOpt.NonLinearProgram.Model}","page":"Reference","title":"DiffOpt.NonLinearProgram._compute_sensitivity","text":"_compute_sensitivity(model::Model; tol=1e-6)\n\nCompute the sensitivity of the solution given sensitivity of the parameters (Î”p).\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._compute_solution_and_bounds-Tuple{DiffOpt.NonLinearProgram.Model}","page":"Reference","title":"DiffOpt.NonLinearProgram._compute_solution_and_bounds","text":"_compute_solution_and_bounds(model::Model; tol=1e-6)\n\nCompute the solution and bounds of the primal variables.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._create_evaluator-Tuple{DiffOpt.NonLinearProgram.Form}","page":"Reference","title":"DiffOpt.NonLinearProgram._create_evaluator","text":"_create_evaluator(form::Form)\n\nCreate the evaluator for the NLP.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._fill_off_diagonal-Tuple{SparseArrays.SparseMatrixCSC}","page":"Reference","title":"DiffOpt.NonLinearProgram._fill_off_diagonal","text":"_fill_off_diagonal(H)\n\nFilling the off-diagonal elements of a sparse matrix to make it symmetric.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._find_inequalities-Tuple{DiffOpt.NonLinearProgram.Form}","page":"Reference","title":"DiffOpt.NonLinearProgram._find_inequalities","text":"_find_inequalities(cons::Vector{JuMP.ConstraintRef})\n\nFind the indices of the inequality constraints.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._inertia_correction-Union{Tuple{T}, Tuple{SparseArrays.SparseMatrixCSC, Int64, Int64}} where T<:Real","page":"Reference","title":"DiffOpt.NonLinearProgram._inertia_correction","text":"_inertia_correction(\n    M::SparseArrays.SparseMatrixCSC,\n    num_cons::Int,\n    num_w::Int;\n    st::T = 1e-6,\n    max_corrections::Int = 50\n) where T<:Real\n\nInertia correction for the Jacobian of the KKT system. Similar to the inertia correction in Ipopt.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._is_greater_inequality-Union{Tuple{MathOptInterface.ConstraintIndex{F, S}}, Tuple{S}, Tuple{F}} where {F<:Union{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.ScalarNonlinearFunction, MathOptInterface.ScalarQuadraticFunction{Float64}}, S<:MathOptInterface.GreaterThan}","page":"Reference","title":"DiffOpt.NonLinearProgram._is_greater_inequality","text":"_is_greater_inequality(con::MOI.ConstraintIndex{F, S}) where {F, S}\n\nCheck if the constraint is a greater than inequality.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._is_less_inequality-Union{Tuple{MathOptInterface.ConstraintIndex{F, S}}, Tuple{S}, Tuple{F}} where {F<:Union{MathOptInterface.ScalarAffineFunction{Float64}, MathOptInterface.ScalarNonlinearFunction, MathOptInterface.ScalarQuadraticFunction{Float64}}, S<:MathOptInterface.LessThan}","page":"Reference","title":"DiffOpt.NonLinearProgram._is_less_inequality","text":"_is_less_inequality(con::MOI.ConstraintIndex{F, S}) where {F, S}\n\nCheck if the constraint is a less than inequality.\n\n\n\n\n\n","category":"method"},{"location":"reference/#DiffOpt.NonLinearProgram._lu_with_inertia_correction-Union{Tuple{T}, Tuple{SparseArrays.SparseMatrixCSC, DiffOpt.NonLinearProgram.Model}, Tuple{SparseArrays.SparseMatrixCSC, DiffOpt.NonLinearProgram.Model, T}, Tuple{SparseArrays.SparseMatrixCSC, DiffOpt.NonLinearProgram.Model, T, Int64}} where T<:Real","page":"Reference","title":"DiffOpt.NonLinearProgram._lu_with_inertia_correction","text":"function _lu_with_inertia_correction(\n    M::SparseArrays.SparseMatrixCSC, # Jacobian of KKT system\n    model::Model, # Model to extract number of variables and constraints\n    st::T = 1e-6, # Step size for inertia correction\n    max_corrections::Int = 50, # Maximum number of corrections\n) where T<:Real\n\nLu-factorization with inertia correction. If no inertia correction is needed, it only performs the LU factorization.\n\n\n\n\n\n","category":"method"},{"location":"examples/nearest_correlation/#Nearest-correlation","page":"Nearest correlation","title":"Nearest correlation","text":"(Image: )\n\nThis example illustrates the sensitivity analysis of the nearest correlation problem studied in [H02].\n\nHigham, Nicholas J. Computing the nearest correlation matrixâ€”a problem from finance. IMA journal of Numerical Analysis 22.3 (2002): 329-343.\n\nusing DiffOpt, JuMP, SCS, LinearAlgebra\nsolver = SCS.Optimizer\n\nfunction proj(A, dH = Diagonal(ones(size(A, 1))), H = ones(size(A)))\n    n = LinearAlgebra.checksquare(A)\n    model = Model(() -> DiffOpt.diff_optimizer(solver))\n    @variable(model, X[1:n, 1:n] in PSDCone())\n    @constraint(model, [i in 1:n], X[i, i] == 1)\n    @objective(model, Min, sum((H .* (X - A)) .^ 2))\n    MOI.set(\n        model,\n        DiffOpt.ForwardObjectiveFunction(),\n        sum((dH .* (X - A)) .^ 2),\n    )\n    optimize!(model)\n    DiffOpt.forward_differentiate!(model)\n    dX = MOI.get.(model, DiffOpt.ForwardVariablePrimal(), X)\n    return value.(X), dX\nend\n\nExample from [H02, p. 334-335]:\n\nA = LinearAlgebra.Tridiagonal(ones(2), ones(3), ones(2))\n\nThe projection is computed as follows:\n\nX, dX = proj(A)\nnothing # hide\n\nThe projection of A is:\n\nX\n\nThe derivative of the projection with respect to a uniform increase of the weights of the diagonal entries is:\n\ndX\n\nExample from [H02, Section 4, p. 340]:\n\nA = LinearAlgebra.Tridiagonal(-ones(3), 2ones(4), -ones(3))\n\nThe projection is computed as follows:\n\nX, dX = proj(A)\nnothing # hide\n\nThe projection of A is:\n\nX\n\nThe derivative of the projection with respect to a uniform increase of the weights of the diagonal entries is:\n\ndX\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"usage/#Usage","page":"Usage","title":"Usage","text":"Create a differentiable model from existing optimizers\n\nusing JuMP\nimport DiffOpt\nimport SCS\n\nmodel = DiffOpt.diff_optimizer(SCS.Optimizer)\n\nUpdate and solve the model \n\nx = MOI.add_variables(model, 2)\nc = MOI.add_constraint(model, ...)\n\nMOI.optimize!(model)\n\nFinally differentiate the model (primal and dual variables specifically) to obtain product of jacobians with respect to problem parameters and a backward pass vector. Currently DiffOpt supports two backends for differentiating a model:\n\nTo differentiate Convex Quadratic Program\n\nbeginalign*\n min_x in mathbbR^n  frac12 x^T Q x + q^T x   \n textst                A x = b        qquad         b in mathbbR^m \n                            G x leq h     qquad         h in mathbbR^p\nendalign*\n\nwe can use the reverse_differentiate! method\n\nMOI.set.(model,\n    DiffOpt.ReverseVariablePrimal(), x, ones(2))\nDiffOpt.reverse_differentiate!(model)\ngrad_obj = MOI.get(model, DiffOpt.ReverseObjectiveFunction())\ngrad_con = MOI.get.(model, DiffOpt.ReverseConstraintFunction(), c)\n\nTo differentiate convex conic program\n\nbeginalign*\n min_x in mathbbR^n  c^T x \n textst                A x + s = b  \n                            b in mathbbR^m  \n                            s in mathcalK\nendalign*\n\nwe can use the forward_differentiate! method with perturbations in matrices A, b, c:\n\nimport LinearAlgebra: â‹…\nMOI.set(model, DiffOpt.ForwardObjectiveFunction(), ones(2) â‹… x)\nDiffOpt.forward_differentiate!(model)\ngrad_x = MOI.get.(model, DiffOpt.ForwardVariablePrimal(), x)\n\nTo differentiate a general nonlinear program, have to use the API for Parameterized JuMP models. For example, consider the following nonlinear program:\n\nusing JuMP, DiffOpt, HiGHS\n\nmodel = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer))\nset_silent(model)\n\np_val = 4.0\npc_val = 2.0\n@variable(model, x)\n@variable(model, p in Parameter(p_val))\n@variable(model, pc in Parameter(pc_val))\n@constraint(model, cons, pc * x >= 3 * p)\n@objective(model, Min, x^4)\noptimize!(model)\n@show value(x) == 3 * p_val / pc_val\n\n# the function is\n# x(p, pc) = 3p / pc\n# hence,\n# dx/dp = 3 / pc\n# dx/dpc = -3p / pc^2\n\n# First, try forward mode AD\n\n# differentiate w.r.t. p\ndirection_p = 3.0\nMOI.set(model, DiffOpt.ForwardConstraintSet(), ParameterRef(p), Parameter(direction_p))\nDiffOpt.forward_differentiate!(model)\n@show MOI.get(model, DiffOpt.ForwardVariablePrimal(), x) == direction_p * 3 / pc_val\n\n# update p and pc\np_val = 2.0\npc_val = 6.0\nset_parameter_value(p, p_val)\nset_parameter_value(pc, pc_val)\n# re-optimize\noptimize!(model)\n# check solution\n@show value(x) â‰ˆ 3 * p_val / pc_val\n\n# stop differentiating with respect to p\nDiffOpt.empty_input_sensitivities!(model)\n# differentiate w.r.t. pc\ndirection_pc = 10.0\nMOI.set(model, DiffOpt.ForwardConstraintSet(), ParameterRef(pc), Parameter(direction_pc))\nDiffOpt.forward_differentiate!(model)\n@show abs(MOI.get(model, DiffOpt.ForwardVariablePrimal(), x) -\n    -direction_pc * 3 * p_val / pc_val^2) < 1e-5\n\n# always a good practice to clear previously set sensitivities\nDiffOpt.empty_input_sensitivities!(model)\n# Now, reverse model AD\ndirection_x = 10.0\nMOI.set(model, DiffOpt.ReverseVariablePrimal(), x, direction_x)\nDiffOpt.reverse_differentiate!(model)\n@show MOI.get(model, DiffOpt.ReverseConstraintSet(), ParameterRef(p)) == MOI.Parameter(direction_x * 3 / pc_val)\n@show abs(MOI.get(model, DiffOpt.ReverseConstraintSet(), ParameterRef(pc)).value -\n    -direction_x * 3 * p_val / pc_val^2) < 1e-5","category":"section"},{"location":"usage/#Calculating-objective-sensitivity-with-respect-to-parameters-(currently-only-supported-for-Nonlinear-Programs)","page":"Usage","title":"Calculating objective sensitivity with respect to parameters (currently only supported for Nonlinear Programs)","text":"Consider a differentiable model with parameters p and pc as in the previous example:\n\nusing JuMP, DiffOpt, HiGHS\n\nmodel = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer))\nset_silent(model)\n\np_val = 4.0\npc_val = 2.0\n@variable(model, x)\n@variable(model, p in Parameter(p_val))\n@variable(model, pc in Parameter(pc_val))\n@constraint(model, cons, pc * x >= 3 * p)\n@objective(model, Min, x^4)\noptimize!(model)\n\ndirection_p = 3.0\nMOI.set(model, DiffOpt.ForwardConstraintSet(), ParameterRef(p), Parameter(direction_p))\nDiffOpt.forward_differentiate!(model)\n\nUsing Lagrangian duality we can easily calculate the objective sensitivity with respect to parameters that appear as constants of the constraints (e.g, cons in this case for parameter p) - i.e. The objective sensitivity w.r.t. a constant parameter change is given by the optimal dual multiplier, under strong duality.\n\nOn the other hand, if the parameter appears as a coefficient of the constraints, one can calculate the objective sensitivity with respect to the parameter using the sensitivities of the variables with respect to the parameter, ( \\frac{\\partial x}{\\partial p} ), and the gradient of the objective with respect to the variables ( \\frac{\\partial f}{\\partial x} ):\n\nfracpartial fpartial p = fracpartial fpartial x fracpartial xpartial p\n\nA consequence of the chain-rule.\n\nIn order to calculate the objective perturbation with respect to the parameter perturbation vector, we can use the following code:\n\n# Always a good practice to clear previously set sensitivities\nDiffOpt.empty_input_sensitivities!(model)\n\nMOI.set(model, DiffOpt.ForwardConstraintSet(), ParameterRef(p), Parameter(3.0))\nMOI.set(model, DiffOpt.ForwardConstraintSet(), ParameterRef(p_c), Parameter(3.0))\nDiffOpt.forward_differentiate!(model)\n\nMOI.get(model, DiffOpt.ForwardObjectiveSensitivity())\n\nIn reverse mode, we can calculate the parameter perturbation with respect to the objective perturbation:\n\n# Always a good practice to clear previously set sensitivities\nDiffOpt.empty_input_sensitivities!(model)\n\nMOI.set(\n    model,\n    DiffOpt.ReverseObjectiveSensitivity(),\n    0.1,\n)\n\nDiffOpt.reverse_differentiate!(model)\n\nMOI.get(model, DiffOpt.ReverseConstraintSet(), ParameterRef(p))\n\nIt is important to note that the (reverse) parameter perturbation given an objective perturbation is somewhat equivalent to the perturbation with respect to solution (since one can be calculated from the other). Therefore, one cannot set both the objective sensitivity (DiffOpt.ReverseObjectiveSensitivity) and the solution sensitivity (e.g. DiffOpt.ReverseVariablePrimal) at the same time - the code will throw an error if you try to do so.","category":"section"},{"location":"examples/Mean_Variance_Portfolio_Example/#Mean-Variance-Portfolio-Example","page":"Mean Variance Portfolio Example","title":"Mean Variance Portfolio Example","text":"Consider the Markowitz portfolio selection problem, which allocates weights x in mathbbR^n to n assets so as to maximize returns subject to a variance limit v_max:\n\nmax_x quad mu^top x\nquadtextstquad\nx^top Sigma x le v_max quad\nmathbf1^top x = 1quad\nx succeq 0\n\nwhere mu is the vector of expected returns, Sigma is the covariance matrix, and x must sum to 1 (fully invest the budget). An efficient conic version of this problem casts the variance limit as a second order cone constraint:\n\n Sigma^12 x _2 le sigma_max\n\nwhere Sigma^12 is the Cholesky factorization of the covariance matrix and sigma_max is the standard deviation limit.\n\nPractitioners often care about an \\emph{out-of-sample performance metric} L(x) evaluated on test data or scenarios that differ from those used to form mu and Sigma. To assess the impact of the risk profile in the performance evaluation, one can compute:\n\nfracdLdsigma_max =\nunderbracefracpartial Lpartial x_text(1) decision impact\ncdot\nunderbracefracpartial x^*partial sigma_max_text(2) from DiffOptjl\n\nwhere x^*(sigma_max) is the portfolio that solves the conic Markowitz problem under a given risk limit.","category":"section"},{"location":"examples/Mean_Variance_Portfolio_Example/#Define-and-solve-the-Mean-Variance-Portfolio-Problem-for-a-range-of-risk-limits","page":"Mean Variance Portfolio Example","title":"Define and solve the Mean-Variance Portfolio Problem for a range of risk limits","text":"First, import the libraries.\n\nusing Test\nusing JuMP\nimport DiffOpt\nusing LinearAlgebra\nimport SCS\nusing Plots\nusing Plots.Measures\n\nFixed data\n\nTraining data (in-sample)\n\nÎ£ = [\n    0.002 0.0005 0.001\n    0.0005 0.003 0.0002\n    0.001 0.0002 0.0025\n]\nÎ¼_train = [0.05, 0.08, 0.12]\n\nTest data (out-of-sample)\n\nÎ¼_test = [0.02, -0.3, 0.1]             # simple forecast error example\n\nSweep over Ïƒ_max\n\nÏƒ_grid = 0.002:0.002:0.06\nN = length(Ïƒ_grid)\n\npredicted_ret = zeros(N)                 # Î¼_train' * x*\nrealised_ret = zeros(N)                 # Î¼_test'  * x*\nloss = zeros(N)                 # L(x*)\ndL_dÏƒ = zeros(N)                 # âˆ‚L/âˆ‚Ïƒ_max  from DiffOpt\n\nfor (k, Ïƒ_val) in enumerate(Ïƒ_grid)\n\n    # 1) differentiable conic model\n    model = DiffOpt.conic_diff_model(SCS.Optimizer)\n    set_silent(model)\n\n    # 2) parameter Ïƒ_max\n    @variable(model, Ïƒ_max in Parameter(Ïƒ_val))\n\n    # 3) portfolio weights\n    @variable(model, x[1:3] >= 0)\n    @constraint(model, sum(x) <= 1)\n\n    # 4) objective: maximise expected return (training data)\n    @objective(model, Max, dot(Î¼_train, x))\n\n    # 5) conic variance constraint  ||L*x|| <= Ïƒ_max\n    L_chol = cholesky(Symmetric(Î£)).L\n    @variable(model, t >= 0)\n    @constraint(model, [t; L_chol * x] in SecondOrderCone())\n    @constraint(model, t <= Ïƒ_max)\n\n    optimize!(model)\n\n    x_opt = value.(x)\n    println(\"Optimal portfolio weights: \", x_opt)\n\n    # store performance numbers\n    predicted_ret[k] = dot(Î¼_train, x_opt)\n    realised_ret[k] = dot(Î¼_test, x_opt)\n\n    # -------- reverse differentiation wrt Ïƒ_max --------\n    DiffOpt.empty_input_sensitivities!(model)\n    # âˆ‚L/âˆ‚x   (adjoint)  =  -Î¼_test\n    DiffOpt.set_reverse_variable.(model, x, Î¼_test)\n    DiffOpt.reverse_differentiate!(model)\n    dL_dÏƒ[k] = DiffOpt.get_reverse_parameter(model, Ïƒ_max)\nend","category":"section"},{"location":"examples/Mean_Variance_Portfolio_Example/#Results-with-Plot-graphs","page":"Mean Variance Portfolio Example","title":"Results with Plot graphs","text":"default(;\n    size = (1150, 350),\n    legendfontsize = 8,\n    guidefontsize = 9,\n    tickfontsize = 7,\n)\n\n(a) predicted vs realised return\n\nplt_ret = plot(\n    Ïƒ_grid,\n    realised_ret;\n    lw = 2,\n    label = \"Realised (test)\",\n    xlabel = \"Ïƒ_max (risk limit)\",\n    ylabel = \"Return\",\n    title = \"Return vs risk limit\",\n    legend = :bottomright,\n);\nplot!(\n    plt_ret,\n    Ïƒ_grid,\n    predicted_ret;\n    lw = 2,\n    ls = :dash,\n    label = \"Predicted (train)\",\n);\nnothing #hide\n\n(b) out-of-sample loss and its gradient\n\nplt_loss = plot(\n    Ïƒ_grid,\n    dL_dÏƒ;\n    xlabel = \"Ïƒ_max (risk limit)\",\n    ylabel = \"âˆ‚L/âˆ‚Ïƒ_max\",\n    title = \"Return Gradient\",\n    legend = false,\n);\n\nplot_all = plot(\n    plt_ret,\n    plt_loss;\n    layout = (1, 2),\n    left_margin = 5Plots.Measures.mm,\n    bottom_margin = 5Plots.Measures.mm,\n)\n\nImpact of the risk limit sigma_max on Markowitz portfolios.  Left: predicted in-sample return versus realized out-of-sample return.  Right: the out-of-sample loss L(x) together with the absolute gradient partial Lpartialsigma_max obtained from DiffOpt.jl.  The gradient tells the practitioner which wayâ€”and how aggressivelyâ€”to adjust sigma_max to reduce forecast error; its value is computed in one reverse-mode call without re-solving the optimization for perturbed risk limits.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_Example/#Thermal-Generation-Dispatch-Example","page":"Thermal Generation Dispatch Example","title":"Thermal Generation Dispatch Example","text":"(Image: )\n\nThis example illustrates the sensitivity analysis of thermal generation dispatch problem.\n\nThis problem can be described as the choice of thermal generation g given a demand d, a price for thermal generation c and a penalty price c_{Ï•} for any demand not attended Ï•.\n\nbeginsplit\nbeginarray ll\nmboxminimize  sum_i=1^N c_i g_i + c_phi phi \nmboxst  g_i ge 0 quad i=1N  \n             g_i le G_i quad i=1N  \n             sum_i=1^N g_i + phi = d\nendarray\nendsplit\n\nwhere\n\nG_{i} is the maximum possible generation for a thermal generator i","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_Example/#Define-and-solve-the-Thermal-Dispatch-Problem","page":"Thermal Generation Dispatch Example","title":"Define and solve the Thermal Dispatch Problem","text":"First, import the libraries.\n\nusing Test\nusing JuMP\nimport DiffOpt\nimport LinearAlgebra: dot\nimport HiGHS\nimport MathOptInterface as MOI\nimport Plots\n\nDefine the model that will be construct given a set of parameters.\n\nfunction generate_model(\n    d::Float64;\n    g_sup::Vector{Float64},\n    c_g::Vector{Float64},\n    c_Ï•::Float64,\n)\n    # Creation of the Model and Parameters\n    model = Model(() -> DiffOpt.diff_optimizer(HiGHS.Optimizer))\n    set_silent(model)\n    I = length(g_sup)\n\n    # Variables\n    @variable(model, g[i in 1:I] >= 0.0)\n    @variable(model, Ï• >= 0.0)\n\n    # Constraints\n    @constraint(model, limit_constraints_sup[i in 1:I], g[i] <= g_sup[i])\n    @constraint(model, demand_constraint, sum(g) + Ï• == d)\n\n    # Objectives\n    @objective(model, Min, dot(c_g, g) + c_Ï• * Ï•)\n\n    # Solve the model\n    optimize!(model)\n\n    # Return the solved model\n    return model\nend\n\nDefine the functions that will get the primal values g and \\phi and sensitivity analysis of the demand dg/dd and d\\phi/dd from a optimized model.\n\nfunction diff_forward(model::Model, Ïµ::Float64 = 1.0)\n    # Initialization of parameters and references to simplify the notation\n    vect_ref = [model[:g]; model[:Ï•]]\n    I = length(model[:g])\n\n    # Get the primal solution of the model\n    vect = MOI.get.(model, MOI.VariablePrimal(), vect_ref)\n\n    # Pass the perturbation to the DiffOpt Framework and set the context to Forward\n    constraint_equation = convert(MOI.ScalarAffineFunction{Float64}, Ïµ)\n    MOI.set(\n        model,\n        DiffOpt.ForwardConstraintFunction(),\n        model[:demand_constraint],\n        constraint_equation,\n    )\n    DiffOpt.forward_differentiate!(model)\n\n    # Get the derivative of the model\n    dvect = MOI.get.(model, DiffOpt.ForwardVariablePrimal(), vect_ref)\n\n    # Return the values as a vector\n    return [vect; dvect]\nend\n\nfunction diff_reverse(model::Model, Ïµ::Float64 = 1.0)\n    # Initialization of parameters and references to simplify the notation\n    vect_ref = [model[:g]; model[:Ï•]]\n    I = length(model[:g])\n\n    # Get the primal solution of the model\n    vect = MOI.get.(model, MOI.VariablePrimal(), vect_ref)\n\n    # Set variables needed for the DiffOpt Backward Framework\n    dvect = Array{Float64,1}(undef, I + 1)\n    perturbation = zeros(I + 1)\n\n    # Loop for each primal variable\n    for i in 1:(I+1)\n        # Set the perturbation in the Primal Variables and set the context to Backward\n        perturbation[i] = Ïµ\n        MOI.set.(model, DiffOpt.ReverseVariablePrimal(), vect_ref, perturbation)\n        DiffOpt.reverse_differentiate!(model)\n\n        # Get the value of the derivative of the model\n        dvect[i] = JuMP.constant(\n            MOI.get(\n                model,\n                DiffOpt.ReverseConstraintFunction(),\n                model[:demand_constraint],\n            ),\n        )\n        perturbation[i] = 0.0\n    end\n\n    # Return the values as a vector\n    return [vect; dvect]\nend\n\nInitialize of Parameters\n\ng_sup = [10.0, 20.0, 30.0]\nI = length(g_sup)\nd = 0.0:0.1:80\nd_size = length(d)\nc_g = [1.0, 3.0, 5.0]\nc_Ï• = 10.0;\nnothing #hide\n\nGenerate models for each demand d\n\nmodels = generate_model.(d; g_sup = g_sup, c_g = c_g, c_Ï• = c_Ï•);\nnothing #hide\n\nGet the results of models with the DiffOpt Forward and Backward context\n\nresult_forward = diff_forward.(models)\noptimize!.(models)\nresult_reverse = diff_reverse.(models);\nnothing #hide\n\nOrganization of results to plot Initialize data_results that will contain every result\n\ndata_results = Array{Float64,3}(undef, 2, d_size, 2 * (I + 1));\nnothing #hide\n\nPopulate the data_results array\n\nfor k in 1:d_size\n    data_results[1, k, :] = result_forward[k]\n    data_results[2, k, :] = result_reverse[k]\nend","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_Example/#Results-with-Plot-graphs","page":"Thermal Generation Dispatch Example","title":"Results with Plot graphs","text":"","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_Example/#Results-for-the-forward-context","page":"Thermal Generation Dispatch Example","title":"Results for the forward context","text":"Result Primal Values:\n\nPlots.plot(\n    d,\n    data_results[1, :, 1:(I+1)];\n    title = \"Generation by Demand\",\n    label = [\"Thermal Generation 1\" \"Thermal Generation 2\" \"Thermal Generation 3\" \"Generation Deficit\"],\n    xlabel = \"Demand [unit]\",\n    ylabel = \"Generation [unit]\",\n)\n\nResult Sensitivity Analysis:\n\nPlots.plot(\n    d,\n    data_results[1, :, (I+2):(2*(I+1))];\n    title = \"Sensitivity of Generation by Demand\",\n    label = [\"T. Gen. 1 Sensitivity\" \"T. Gen. 2 Sensitivity\" \"T. Gen. 3 Sensitivity\" \"Gen. Deficit Sensitivity\"],\n    xlabel = \"Demand [unit]\",\n    ylabel = \"Sensitivity [-]\",\n)","category":"section"},{"location":"examples/Thermal_Generation_Dispatch_Example/#Results-for-the-reverse-context","page":"Thermal Generation Dispatch Example","title":"Results for the reverse context","text":"Result Primal Values:\n\nPlots.plot(\n    d,\n    data_results[2, :, 1:(I+1)];\n    title = \"Generation by Demand\",\n    label = [\"Thermal Generation 1\" \"Thermal Generation 2\" \"Thermal Generation 3\" \"Generation Deficit\"],\n    xlabel = \"Demand [unit]\",\n    ylabel = \"Generation [unit]\",\n)\n\nResult Sensitivity Analysis:\n\nPlots.plot(\n    d,\n    data_results[2, :, (I+2):(2*(I+1))];\n    title = \"Sensitivity of Generation by Demand\",\n    label = [\"T. Gen. 1 Sensitivity\" \"T. Gen. 2 Sensitivity\" \"T. Gen. 3 Sensitivity\" \"Gen. Deficit Sensitivity\"],\n    xlabel = \"Demand [unit]\",\n    ylabel = \"Sensitivity [-]\",\n)\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/autotuning-ridge_new/#Auto-tuning-Hyperparameters-(JuMP-API)","page":"Auto-tuning Hyperparameters (JuMP API)","title":"Auto-tuning Hyperparameters (JuMP API)","text":"(Image: )\n\nThis example shows how to learn a hyperparameter in Ridge Regression using a gradient descent routine. Let the regularized regression problem be formulated as:\n\nbeginequation\nmin_w quad frac12nd sum_i=1^n (w^T x_i - y_i)^2 + fracalpha2d  w _2^2\nendequation\n\nwhere\n\nx, y are the data points\nw are the learned weights\nÎ± is the hyperparameter acting on regularization.\n\nThe main optimization model will be formulated with JuMP. Using the gradient of the optimal weights with respect to the regularization parameters computed with DiffOpt, we can perform a gradient descent on top of the inner model to minimize the test loss.\n\nThis tutorial uses the following packages\n\nusing JuMP     # The mathematical programming modelling language\nimport DiffOpt # JuMP extension for differentiable optimization\nimport Ipopt   # Optimization solver that handles quadratic programs\nimport LinearAlgebra\nimport Plots\nimport Random","category":"section"},{"location":"examples/autotuning-ridge_new/#Generating-a-noisy-regression-dataset","page":"Auto-tuning Hyperparameters (JuMP API)","title":"Generating a noisy regression dataset","text":"Random.seed!(42)\n\nN = 100\nD = 20\nnoise = 5\n\nw_real = 10 * randn(D)\nX = 10 * randn(N, D)\ny = X * w_real + noise * randn(N)\nl = N Ã· 2  # test train split\n\nX_train = X[1:l, :]\nX_test = X[(l+1):N, :]\ny_train = y[1:l]\ny_test = y[(l+1):N];\nnothing #hide","category":"section"},{"location":"examples/autotuning-ridge_new/#Defining-the-regression-problem","page":"Auto-tuning Hyperparameters (JuMP API)","title":"Defining the regression problem","text":"We implement the regularized regression problem as a function taking the problem data, building a JuMP model and solving it. Note the cubic term in the objective function (Î± * dot(w, w)), currently this is not handled by ParametricOptInterface smoothly, so we use Ipopt as the solver that support parameters as part of nonlinear (here only cubic) objective functions.\n\nfunction build_fit_ridge(X, y, Î±_val = 1.0)\n    model = DiffOpt.nonlinear_diff_model(Ipopt.Optimizer)\n    set_silent(model)\n    N, D = size(X)\n    @variable(model, w[1:D])\n    @variable(model, Î± in Parameter(Î±_val))\n    @expression(model, err_term, X * w - y)\n    @objective(\n        model,\n        Min,\n        LinearAlgebra.dot(err_term, err_term) / (2 * N * D) +\n        Î± * LinearAlgebra.dot(w, w) / (2 * D),\n    )\n    return model\nend\n\nfunction optimize_fit_ridge!(model, Î±_val)\n    set_parameter_value(model[:Î±], Î±_val)\n    optimize!(model)\n    return value.(model[:w])\nend\n\nWe can solve the problem for several values of Î± to visualize the effect of regularization on the testing and training loss.\n\nÎ±s = 0.00:0.01:0.50\nmse_test = Float64[]\nmse_train = Float64[]\nmodel = build_fit_ridge(X, y)\n(Ntest, D) = size(X_test)\n(Ntrain, D) = size(X_train)\nfor Î± in Î±s\n    wÌ‚ = optimize_fit_ridge!(model, Î±)\n    yÌ‚_test = X_test * wÌ‚\n    yÌ‚_train = X_train * wÌ‚\n    push!(mse_test, LinearAlgebra.norm(yÌ‚_test - y_test)^2 / (2 * Ntest * D))\n    push!(\n        mse_train,\n        LinearAlgebra.norm(yÌ‚_train - y_train)^2 / (2 * Ntrain * D),\n    )\nend\n\nVisualize the Mean Score Error metric\n\nPlots.plot(\n    Î±s,\n    mse_test ./ sum(mse_test);\n    label = \"MSE test\",\n    xaxis = \"Î±\",\n    yaxis = \"MSE\",\n    legend = (0.8, 0.2),\n    width = 3,\n)\nPlots.plot!(\n    Î±s,\n    mse_train ./ sum(mse_train);\n    label = \"MSE train\",\n    linestyle = :dash,\n    width = 3,\n)\nPlots.title!(\"Normalized MSE on training and testing sets\")","category":"section"},{"location":"examples/autotuning-ridge_new/#Leveraging-differentiable-optimization:-computing-the-derivative-of-the-solution","page":"Auto-tuning Hyperparameters (JuMP API)","title":"Leveraging differentiable optimization: computing the derivative of the solution","text":"Using DiffOpt, we can compute âˆ‚w_i/âˆ‚Î±, the derivative of the learned solution Ì‚w w.r.t. the regularization parameter.\n\nfunction compute_dw_dÎ±(model, w)\n    D = length(w)\n    dw_dÎ± = zeros(D)\n    DiffOpt.set_forward_parameter(model, model[:Î±], 1.0)\n    DiffOpt.forward_differentiate!(model)\n    for i in 1:D\n        dw_dÎ±[i] = DiffOpt.get_forward_variable(model, w[i])\n    end\n    return dw_dÎ±\nend\n\nUsing âˆ‚w_i/âˆ‚Î± computed with compute_dw_dÎ±, we can compute the derivative of the test loss w.r.t. the parameter Î± by composing derivatives.\n\nfunction d_testloss_dÎ±(model, X_test, y_test, wÌ‚)\n    N, D = size(X_test)\n    dw_dÎ± = compute_dw_dÎ±(model, model[:w])\n    err_term = X_test * wÌ‚ - y_test\n    return sum(eachindex(err_term)) do i\n        return LinearAlgebra.dot(X_test[i, :], dw_dÎ±) * err_term[i]\n    end / (N * D)\nend\n\nWe can define a meta-optimizer function performing gradient descent on the test loss w.r.t. the regularization parameter.\n\nfunction descent(Î±0, max_iters = 100; fixed_step = 0.01, grad_tol = 1e-3)\n    Î±_s = Float64[]\n    âˆ‚Î±_s = Float64[]\n    test_loss = Float64[]\n    Î± = Î±0\n    N, D = size(X_test)\n    model = build_fit_ridge(X_train, y_train)\n    for iter in 1:max_iters\n        wÌ‚ = optimize_fit_ridge!(model, Î±)\n        err_term = X_test * wÌ‚ - y_test\n        âˆ‚Î± = d_testloss_dÎ±(model, X_test, y_test, wÌ‚)\n        push!(Î±_s, Î±)\n        push!(âˆ‚Î±_s, âˆ‚Î±)\n        push!(test_loss, LinearAlgebra.norm(err_term)^2 / (2 * N * D))\n        Î± -= fixed_step * âˆ‚Î±\n        if abs(âˆ‚Î±) â‰¤ grad_tol\n            break\n        end\n    end\n    return Î±_s, âˆ‚Î±_s, test_loss\nend\n\nÎ±Ì„, âˆ‚Î±Ì„, mseÌ„ = descent(0.10, 500)\niters = 1:length(Î±Ì„);\nnothing #hide\n\nVisualize gradient descent and convergence\n\nPlots.plot(\n    Î±s,\n    mse_test;\n    label = \"MSE test\",\n    xaxis = (\"Î±\"),\n    legend = :topleft,\n    width = 2,\n)\nPlots.plot!(Î±Ì„, mseÌ„; label = \"learned Î±\", width = 5, style = :dot)\nPlots.title!(\"Regularizer learning\")\n\nVisualize the convergence of Î± to its optimal value\n\nPlots.plot(\n    iters,\n    Î±Ì„;\n    label = nothing,\n    color = :blue,\n    xaxis = (\"Iterations\"),\n    legend = :bottom,\n    title = \"Convergence of Î±\",\n)\n\nVisualize the convergence of the objective function\n\nPlots.plot(\n    iters,\n    mseÌ„;\n    label = nothing,\n    color = :red,\n    xaxis = (\"Iterations\"),\n    legend = :bottom,\n    title = \"Convergence of MSE\",\n)\n\nVisualize the convergence of the derivative to zero\n\nPlots.plot(\n    iters,\n    âˆ‚Î±Ì„;\n    label = nothing,\n    color = :green,\n    xaxis = (\"Iterations\"),\n    legend = :bottom,\n    title = \"Convergence of âˆ‚Î±\",\n)\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/chainrules_unit_new/#ChainRules-integration-demo:-Relaxed-Unit-Commitment","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"(Image: )\n\nIn this example, we will demonstrate the integration of DiffOpt with ChainRulesCore.jl, the library allowing the definition of derivatives for functions that can then be used by automatic differentiation systems.\n\nusing JuMP\nimport DiffOpt\nimport Plots\nimport LinearAlgebra: â‹…\nimport HiGHS\nimport ChainRulesCore","category":"section"},{"location":"examples/chainrules_unit_new/#Unit-commitment-problem","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Unit commitment problem","text":"We will consider a unit commitment problem, finding the cost-minimizing activation of generation units in a power network over multiple time periods. The considered constraints include:\n\nDemand satisfaction of several loads\nRamping constraints\nGeneration limits.\n\nThe decisions are:\n\nu_it in 01: activation of the i-th unit at time t\np_it: power output of the i-th unit at time t.\n\nDiffOpt handles convex optimization problems only, we therefore relax the domain of the u_it variables to left01right.","category":"section"},{"location":"examples/chainrules_unit_new/#Primal-UC-problem","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Primal UC problem","text":"ChainRules defines the differentiation of functions. The actual function that is differentiated in the context of DiffOpt is the solution map taking in input the problem parameters and returning the solution.\n\nfunction unit_commitment(\n    _load1_demand,\n    _load2_demand,\n    gen_costs,\n    noload_costs;\n    model = Model(HiGHS.Optimizer),\n    silent = false,\n)\n    MOI.set(model, MOI.Silent(), silent)\n\n    # Problem data\n    units = [1, 2] # Generator identifiers\n    load_names = [\"Load1\", \"Load2\"] # Load identifiers\n    n_periods = 4 # Number of time periods\n    Pmin = Dict(1 => fill(0.5, n_periods), 2 => fill(0.5, n_periods)) # Minimum power output (pu)\n    Pmax = Dict(1 => fill(3.0, n_periods), 2 => fill(3.0, n_periods)) # Maximum power output (pu)\n    RR = Dict(1 => 0.25, 2 => 0.25) # Ramp rates (pu/min)\n    P0 = Dict(1 => 0.0, 2 => 0.0) # Initial power output (pu)\n\n    # Parameters\n    @variable(model, load1_demand[1:n_periods] in Parameter.(_load1_demand)) # Load 1 demand (pu)\n    @variable(model, load2_demand[1:n_periods] in Parameter.(_load2_demand)) # Load 2 demand (pu)\n    D = Dict(\"Load1\" => load1_demand, \"Load2\" => load2_demand)\n    @variable(model, Cp[1:2] in Parameter.(gen_costs)) # Generation costs ($/pu)\n    @variable(model, Cnl[1:2] in Parameter.(noload_costs)) # No-load costs ($)\n\n    # Variables\n    # Note: u represents the activation of generation units.\n    # Would be binary in the typical UC problem, relaxed here to u âˆˆ [0,1]\n    # for a linear relaxation.\n    @variable(model, 0 <= u[g in units, t in 1:n_periods] <= 1) # Commitment\n    @variable(model, p[g in units, t in 1:n_periods] >= 0) # Power output (pu)\n\n    # Constraints\n\n    # Energy balance\n    @constraint(\n        model,\n        energy_balance_cons[t in 1:n_periods],\n        sum(p[g, t] for g in units) == sum(D[l][t] for l in load_names),\n    )\n\n    # Generation limits\n    @constraint(\n        model,\n        [g in units, t in 1:n_periods],\n        Pmin[g][t] * u[g, t] <= p[g, t]\n    )\n    @constraint(\n        model,\n        [g in units, t in 1:n_periods],\n        p[g, t] <= Pmax[g][t] * u[g, t]\n    )\n\n    # Ramp rates\n    @constraint(\n        model,\n        [g in units, t in 2:n_periods],\n        p[g, t] - p[g, t-1] <= 60 * RR[g]\n    )\n    @constraint(model, [g in units], p[g, 1] - P0[g] <= 60 * RR[g])\n    @constraint(\n        model,\n        [g in units, t in 2:n_periods],\n        p[g, t-1] - p[g, t] <= 60 * RR[g]\n    )\n    @constraint(model, [g in units], P0[g] - p[g, 1] <= 60 * RR[g])\n\n    # Objective\n    @objective(\n        model,\n        Min,\n        sum(\n            (Cp[g] * p[g, t]) + (Cnl[g] * u[g, t]) for\n            g in units, t in 1:n_periods\n        ),\n    )\n\n    optimize!(model)\n    # asserting finite optimal value\n    @assert termination_status(model) == MOI.OPTIMAL\n    # converting to dense matrix\n    return JuMP.value.(p.data)\nend\n\nm = Model(HiGHS.Optimizer)\n@show unit_commitment(\n    [1.0, 1.2, 1.4, 1.6],\n    [1.0, 1.2, 1.4, 1.6],\n    [1000.0, 1500.0],\n    [500.0, 1000.0],\n    model = m,\n    silent = true,\n)","category":"section"},{"location":"examples/chainrules_unit_new/#Perturbation-of-a-single-input-parameter","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Perturbation of a single input parameter","text":"Let us vary the demand at the second time frame on both loads:\n\ndemand_values = 0.05:0.05:3.0\npvalues = map(demand_values) do di\n    return unit_commitment(\n        [1.0, di, 1.4, 1.6],\n        [1.0, di, 1.4, 1.6],\n        [1000.0, 1500.0],\n        [500.0, 1000.0];\n        silent = true,\n    )\nend\npflat = [getindex.(pvalues, i) for i in eachindex(pvalues[1])];\nnothing #hide\n\nThe influence of this variation of the demand is piecewise linear on the generation at different time frames:\n\nPlots.scatter(demand_values, pflat; xaxis = (\"Demand\"), yaxis = (\"Generation\"))\nPlots.title!(\"Different time frames and generators\")\nPlots.xlims!(0.0, 3.5)","category":"section"},{"location":"examples/chainrules_unit_new/#Forward-Differentiation","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Forward Differentiation","text":"Forward differentiation rule for the solution map of the unit commitment problem. It takes as arguments:\n\nthe perturbations on the input parameters\nthe differentiated function\nthe primal values of the input parameters,\n\nand returns a tuple (primal_output, perturbations), the main primal result and the perturbation propagated to this result:\n\nfunction ChainRulesCore.frule(\n    (_, Î”load1_demand, Î”load2_demand, Î”gen_costs, Î”noload_costs),\n    ::typeof(unit_commitment),\n    load1_demand,\n    load2_demand,\n    gen_costs,\n    noload_costs;\n    optimizer = HiGHS.Optimizer,\n)\n    # creating the UC model with a DiffOpt optimizer wrapper around HiGHS\n    model = DiffOpt.diff_model(optimizer)\n    # building and solving the main model\n    pv = unit_commitment(\n        load1_demand,\n        load2_demand,\n        gen_costs,\n        noload_costs;\n        model = model,\n    )\n    # Setting perturbations in the parameters\n    DiffOpt.set_forward_parameter.(model, model[:load1_demand], Î”load1_demand)\n    DiffOpt.set_forward_parameter.(model, model[:load2_demand], Î”load2_demand)\n    DiffOpt.set_forward_parameter.(model, model[:Cp], Î”gen_costs)\n    DiffOpt.set_forward_parameter.(model, model[:Cnl], Î”noload_costs)\n    # computing the forward differentiation\n    DiffOpt.forward_differentiate!(model)\n    # querying the corresponding perturbation of the decision\n    Î”p = DiffOpt.get_forward_variable.(model, model[:p])\n    return (pv, Î”p.data)\nend\n\nWe can now compute the perturbation of the output powers Î”pv for a perturbation of the first load demand at time 2:\n\nload1_demand = [1.0, 1.0, 1.4, 1.6]\nload2_demand = [1.0, 1.0, 1.4, 1.6]\ngen_costs = [1000.0, 1500.0]\nnoload_costs = [500.0, 1000.0];\nnothing #hide\n\nall input perturbations are 0 except first load at time 2\n\nÎ”load1_demand = 0 * load1_demand\nÎ”load1_demand[2] = 1.0\nÎ”load2_demand = 0 * load2_demand\nÎ”gen_costs = 0 * gen_costs\nÎ”noload_costs = 0 * noload_costs\n(pv, Î”pv) = ChainRulesCore.frule(\n    (nothing, Î”load1_demand, Î”load2_demand, Î”gen_costs, Î”noload_costs),\n    unit_commitment,\n    load1_demand,\n    load2_demand,\n    gen_costs,\n    noload_costs,\n)\n\nÎ”pv\n\nThe result matches what we observe in the previous figure: the generation of the first generator at the second time frame (third element on the plot).","category":"section"},{"location":"examples/chainrules_unit_new/#Reverse-mode-differentiation-of-the-solution-map","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Reverse-mode differentiation of the solution map","text":"The rrule returns the primal and a pullback. The pullback takes a seed for the optimal solution Ì„p and returns derivatives with respect to each input parameter of the function.\n\nfunction ChainRulesCore.rrule(\n    ::typeof(unit_commitment),\n    load1_demand,\n    load2_demand,\n    gen_costs,\n    noload_costs;\n    optimizer = HiGHS.Optimizer,\n    silent = false,\n)\n    model = DiffOpt.diff_model(optimizer)\n    # solve the forward UC problem\n    pv = unit_commitment(\n        load1_demand,\n        load2_demand,\n        gen_costs,\n        noload_costs;\n        model = model,\n        silent = silent,\n    )\n    function pullback_unit_commitment(pb)\n        # set sensitivities\n        DiffOpt.set_reverse_variable.(model, model[:p], pb)\n        # compute the gradients\n        DiffOpt.reverse_differentiate!(model)\n        # retrieve the gradients with respect to the parameters\n        dload1_demand =\n            DiffOpt.get_reverse_parameter.(model, model[:load1_demand])\n        dload2_demand =\n            DiffOpt.get_reverse_parameter.(model, model[:load2_demand])\n        dgen_costs = DiffOpt.get_reverse_parameter.(model, model[:Cp])\n        dnoload_costs = DiffOpt.get_reverse_parameter.(model, model[:Cnl])\n        return (dload1_demand, dload2_demand, dgen_costs, dnoload_costs)\n    end\n    return (pv, pullback_unit_commitment)\nend\n\nWe can set a seed of one on the power of the first generator at the second time frame and zero for all other parts of the solution:\n\n(pv, pullback_unit_commitment) = ChainRulesCore.rrule(\n    unit_commitment,\n    load1_demand,\n    load2_demand,\n    gen_costs,\n    noload_costs;\n    optimizer = HiGHS.Optimizer,\n    silent = true,\n)\ndpv = 0 * pv\ndpv[1, 2] = 1\ndargs = pullback_unit_commitment(dpv)\n(dload1_demand, dload2_demand, dgen_costs, dnoload_costs) = dargs;\nnothing #hide\n\nThe sensitivities with respect to the load demands are:\n\ndload1_demand\n\nand:\n\ndload2_demand\n\nThe sensitivity of the generation is propagated to the sensitivity of both loads at the second time frame.\n\nThis example integrating ChainRules was designed with support from Invenia Technical Computing.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/sensitivity-analysis-ridge_new/#Sensitivity-Analysis-of-Ridge-Regression","page":"Sensitivity Analysis of Ridge Regression","title":"Sensitivity Analysis of Ridge Regression","text":"(Image: )\n\nThis example illustrates the sensitivity analysis of data points in a Ridge Regression problem. The general form of the problem is given below:\n\nbeginsplit\nbeginarray ll\nmboxminimize  sum_i=1^N (y_i - w x_i - b)^2 + alpha (w^2 + b^2) \nendarray\nendsplit\n\nwhere\n\nw, b are slope and intercept of the regressing line\nx, y are the N data points\nÎ± is the regularization constant\n\nwhich is equivalent to:\n\nbeginsplit\nbeginarray ll\nmboxminimize  e^tope + alpha (w^2) \nmboxst  e_i = y_i - w x_i - b quad quad i=1N  \nendarray\nendsplit\n\nThis tutorial uses the following packages\n\nusing JuMP\nimport DiffOpt\nimport Random\nimport Ipopt\nimport Plots\nusing LinearAlgebra: dot","category":"section"},{"location":"examples/sensitivity-analysis-ridge_new/#Define-and-solve-the-problem","page":"Sensitivity Analysis of Ridge Regression","title":"Define and solve the problem","text":"Construct a set of noisy (guassian) data points around a line.\n\nRandom.seed!(42)\n\nN = 150\n\nw_orig = 2 * abs(randn())\nb = rand()\nX = randn(N)\nY = w_orig * X .+ b + 0.8 * randn(N);\nnothing #hide\n\nThe helper method fit_ridge defines and solves the corresponding model. The ridge regression is modeled with quadratic programming (quadratic objective and linear constraints) and solved in generic methods of Ipopt. This is not the standard way of solving the ridge regression problem this is done here for didactic purposes.\n\nfunction build_fit_ridge(X_data, Y_data, alpha = 0.1)\n    N = length(Y_data)\n    # Initialize a JuMP Model with Ipopt solver\n    # model = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer)) # TODO: this is not auto detecting scalar nonlinear function (alpha * w * w)\n    model = DiffOpt.nonlinear_diff_model(Ipopt.Optimizer)\n    set_silent(model)\n    @variable(model, w) # angular coefficient\n    @variable(model, b) # linear coefficient\n    @variable(model, Î± in Parameter(alpha)) # regularization parameter\n    @variable(model, X[1:N] in Parameter.(X_data))\n    @variable(model, Y[1:N] in Parameter.(Y_data))\n    # expression defining approximation error\n    @expression(model, e[i=1:N], Y[i] - w * X[i] - b)\n    # objective minimizing squared error and ridge penalty\n    @objective(model, Min, 1 / N * dot(e, e) + Î± * (w^2))\n    optimize!(model)\n    return model\nend\n\nfunction optimize_fit_ridge!(model, alpha)\n    set_parameter_value(model[:Î±], alpha)\n    optimize!(model)\n    return model[:w], model[:b]\nend\n\nPlot the data points and the fitted line for different alpha values\n\np = Plots.scatter(X, Y; label = nothing, legend = :topleft)\nmi, ma = minimum(X), maximum(X)\nPlots.title!(\"Fitted lines and points\")\n\nmodel = build_fit_ridge(X, Y)\nfor alpha in 0.5:0.5:1.5\n    local w, b = optimize_fit_ridge!(model, alpha)\n    wÌ‚ = value(w)\n    bÌ‚ = value(b)\n    Plots.plot!(\n        p,\n        [mi, ma],\n        [mi * wÌ‚ + bÌ‚, ma * wÌ‚ + bÌ‚];\n        label = \"alpha=$alpha\",\n        width = 2,\n    )\nend\np","category":"section"},{"location":"examples/sensitivity-analysis-ridge_new/#Differentiate","page":"Sensitivity Analysis of Ridge Regression","title":"Differentiate","text":"Now that we've solved the problem, we can compute the sensitivity of optimal values of the slope w with respect to perturbations in the data points (x,y).\n\nalpha = 0.4\nw, b = optimize_fit_ridge!(model, alpha)\nwÌ‚ = value(w)\nbÌ‚ = value(b)\n\nSensitivity with respect to x and y\n\nâˆ‡y = zero(X)\nâˆ‡x = zero(X)\nfor i in 1:N\n    # X[i] sensitivity\n    DiffOpt.empty_input_sensitivities!(model)\n    DiffOpt.set_forward_parameter(model, model[:X][i], 1.0)\n    DiffOpt.forward_differentiate!(model)\n    âˆ‡x[i] = DiffOpt.get_forward_variable(model, w)\n    # Y[i] sensitivity\n    DiffOpt.empty_input_sensitivities!(model)\n    DiffOpt.set_forward_parameter(model, model[:Y][i], 1.0)\n    DiffOpt.forward_differentiate!(model)\n    âˆ‡y[i] = DiffOpt.get_forward_variable(model, w)\nend\n\nVisualize point sensitivities with respect to regression points.\n\np = Plots.scatter(\n    X,\n    Y;\n    color = [dw < 0 ? :blue : :red for dw in âˆ‡x],\n    markersize = [5 * abs(dw) + 1.2 for dw in âˆ‡x],\n    label = \"\",\n)\nmi, ma = minimum(X), maximum(X)\nPlots.plot!(\n    p,\n    [mi, ma],\n    [mi * wÌ‚ + bÌ‚, ma * wÌ‚ + bÌ‚];\n    color = :blue,\n    label = \"\",\n)\nPlots.title!(\"Regression slope sensitivity with respect to x\")\n\np = Plots.scatter(\n    X,\n    Y;\n    color = [dw < 0 ? :blue : :red for dw in âˆ‡y],\n    markersize = [5 * abs(dw) + 1.2 for dw in âˆ‡y],\n    label = \"\",\n)\nmi, ma = minimum(X), maximum(X)\nPlots.plot!(\n    p,\n    [mi, ma],\n    [mi * wÌ‚ + bÌ‚, ma * wÌ‚ + bÌ‚];\n    color = :blue,\n    label = \"\",\n)\nPlots.title!(\"Regression slope sensitivity with respect to y\")\n\nNote the points with less central x values induce a greater y sensitivity of the slope.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/nearest_correlation_new/#Nearest-correlation","page":"Nearest correlation","title":"Nearest correlation","text":"(Image: )\n\nThis example illustrates the sensitivity analysis of the nearest correlation problem studied in [H02].\n\nHigham, Nicholas J. Computing the nearest correlation matrixâ€”a problem from finance. IMA journal of Numerical Analysis 22.3 (2002): 329-343.\n\nusing DiffOpt, JuMP, SCS, LinearAlgebra\nsolver = SCS.Optimizer\n\nfunction proj(A, dH = Diagonal(ones(size(A, 1))), H_data = ones(size(A)))\n    n = LinearAlgebra.checksquare(A)\n    model = Model(() -> DiffOpt.diff_optimizer(solver))\n    @variable(model, X[1:n, 1:n] in PSDCone())\n    @variable(model, H[1:n, 1:n] in Parameter.(H_data))\n    @variable(model, E[1:n, 1:n])\n    @constraint(model, [i in 1:n], X[i, i] == 1)\n    @constraint(model, E .== (H .* (X .- A)))\n    @objective(model, Min, sum(E .^ 2))\n    for i in 1:n\n        DiffOpt.set_forward_parameter(model, H[i, i], dH[i, i])\n    end\n    optimize!(model)\n    DiffOpt.forward_differentiate!(model)\n    dX = DiffOpt.get_forward_variable.(model, X)\n    return value.(X), dX\nend\n\nExample from [H02, p. 334-335]:\n\nA = LinearAlgebra.Tridiagonal(ones(2), ones(3), ones(2))\n\nThe projection is computed as follows:\n\nX, dX = proj(A)\nnothing # hide\n\nThe projection of A is:\n\nX\n\nThe derivative of the projection with respect to a uniform increase of the weights of the diagonal entries is:\n\ndX\n\nExample from [H02, Section 4, p. 340]:\n\nA = LinearAlgebra.Tridiagonal(-ones(3), 2ones(4), -ones(3))\n\nThe projection is computed as follows:\n\nX, dX = proj(A)\nnothing # hide\n\nThe projection of A is:\n\nX\n\nThe derivative of the projection with respect to a uniform increase of the weights of the diagonal entries is:\n\ndX\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"#DiffOpt.jl","page":"Home","title":"DiffOpt.jl","text":"DiffOpt.jl is a package for differentiating convex and non-convex optimization program (JuMP.jl or MathOptInterface.jl models) with respect to program parameters. Note that this package does not contain any solver. This package has two major backends, available via the reverse_differentiate! and forward_differentiate! methods, to differentiate models (quadratic or conic) with optimal solutions.\n\nnote: Note\nCurrently supports linear programs (LP), convex quadratic programs (QP), convex conic programs (SDP, SOCP, exponential cone constraints only), and general nonlinear programs (NLP).","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"DiffOpt can be installed through the Julia package manager:\n\n(v1.3) pkg> add https://github.com/jump-dev/DiffOpt.jl","category":"section"},{"location":"#Why-are-Differentiable-optimization-problems-important?","page":"Home","title":"Why are Differentiable optimization problems important?","text":"Differentiable optimization is a promising field of constrained optimization and has many potential applications in game theory, control theory and machine learning (specifically deep learning - refer this video for more). Recent work has shown how to differentiate specific subclasses of constrained optimization problems. But several applications remain unexplored (refer section 8 of this really good thesis). With the help of automatic differentiation, differentiable optimization can have a significant impact on creating end-to-end differentiable systems to model neural networks, stochastic processes, or a game.","category":"section"},{"location":"#Contributing","page":"Home","title":"Contributing","text":"Contributions to this package are more than welcome, if you find a bug or have any suggestions for the documentation please post it on the github issue tracker.\n\nWhen contributing please note that the package follows the JuMP style guide","category":"section"},{"location":"examples/chainrules_unit/#ChainRules-integration-demo:-Relaxed-Unit-Commitment","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"ChainRules integration demo: Relaxed Unit Commitment","text":"(Image: )\n\nIn this example, we will demonstrate the integration of DiffOpt with ChainRulesCore.jl, the library allowing the definition of derivatives for functions that can then be used by automatic differentiation systems.\n\nusing JuMP\nimport DiffOpt\nimport Plots\nimport LinearAlgebra: â‹…\nimport HiGHS\nimport ChainRulesCore","category":"section"},{"location":"examples/chainrules_unit/#Unit-commitment-problem","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Unit commitment problem","text":"We will consider a unit commitment problem, finding the cost-minimizing activation of generation units in a power network over multiple time periods. The considered constraints include:\n\nDemand satisfaction of several loads\nRamping constraints\nGeneration limits.\n\nThe decisions are:\n\nu_it in 01: activation of the i-th unit at time t\np_it: power output of the i-th unit at time t.\n\nDiffOpt handles convex optimization problems only, we therefore relax the domain of the u_it variables to left01right.","category":"section"},{"location":"examples/chainrules_unit/#Primal-UC-problem","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Primal UC problem","text":"ChainRules defines the differentiation of functions. The actual function that is differentiated in the context of DiffOpt is the solution map taking in input the problem parameters and returning the solution.\n\nfunction unit_commitment(\n    load1_demand,\n    load2_demand,\n    gen_costs,\n    noload_costs;\n    model = Model(HiGHS.Optimizer),\n    silent = false,\n)\n    MOI.set(model, MOI.Silent(), silent)\n\n    # Problem data\n    units = [1, 2] # Generator identifiers\n    load_names = [\"Load1\", \"Load2\"] # Load identifiers\n    n_periods = 4 # Number of time periods\n    Pmin = Dict(1 => fill(0.5, n_periods), 2 => fill(0.5, n_periods)) # Minimum power output (pu)\n    Pmax = Dict(1 => fill(3.0, n_periods), 2 => fill(3.0, n_periods)) # Maximum power output (pu)\n    RR = Dict(1 => 0.25, 2 => 0.25) # Ramp rates (pu/min)\n    P0 = Dict(1 => 0.0, 2 => 0.0) # Initial power output (pu)\n    D = Dict(\"Load1\" => load1_demand, \"Load2\" => load2_demand) # Demand (pu)\n    Cp = Dict(1 => gen_costs[1], 2 => gen_costs[2]) # Generation cost coefficient ($/pu)\n    Cnl = Dict(1 => noload_costs[1], 2 => noload_costs[2]) # No-load cost ($)\n\n    # Variables\n    # Note: u represents the activation of generation units.\n    # Would be binary in the typical UC problem, relaxed here to u âˆˆ [0,1]\n    # for a linear relaxation.\n    @variable(model, 0 <= u[g in units, t in 1:n_periods] <= 1) # Commitment\n    @variable(model, p[g in units, t in 1:n_periods] >= 0) # Power output (pu)\n\n    # Constraints\n\n    # Energy balance\n    @constraint(\n        model,\n        energy_balance_cons[t in 1:n_periods],\n        sum(p[g, t] for g in units) == sum(D[l][t] for l in load_names),\n    )\n\n    # Generation limits\n    @constraint(\n        model,\n        [g in units, t in 1:n_periods],\n        Pmin[g][t] * u[g, t] <= p[g, t]\n    )\n    @constraint(\n        model,\n        [g in units, t in 1:n_periods],\n        p[g, t] <= Pmax[g][t] * u[g, t]\n    )\n\n    # Ramp rates\n    @constraint(\n        model,\n        [g in units, t in 2:n_periods],\n        p[g, t] - p[g, t-1] <= 60 * RR[g]\n    )\n    @constraint(model, [g in units], p[g, 1] - P0[g] <= 60 * RR[g])\n    @constraint(\n        model,\n        [g in units, t in 2:n_periods],\n        p[g, t-1] - p[g, t] <= 60 * RR[g]\n    )\n    @constraint(model, [g in units], P0[g] - p[g, 1] <= 60 * RR[g])\n\n    # Objective\n    @objective(\n        model,\n        Min,\n        sum(\n            (Cp[g] * p[g, t]) + (Cnl[g] * u[g, t]) for\n            g in units, t in 1:n_periods\n        ),\n    )\n\n    optimize!(model)\n    # asserting finite optimal value\n    @assert termination_status(model) == MOI.OPTIMAL\n    # converting to dense matrix\n    return JuMP.value.(p.data)\nend\n\nm = Model(HiGHS.Optimizer)\n@show unit_commitment(\n    [1.0, 1.2, 1.4, 1.6],\n    [1.0, 1.2, 1.4, 1.6],\n    [1000.0, 1500.0],\n    [500.0, 1000.0],\n    model = m,\n    silent = true,\n)","category":"section"},{"location":"examples/chainrules_unit/#Perturbation-of-a-single-input-parameter","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Perturbation of a single input parameter","text":"Let us vary the demand at the second time frame on both loads:\n\ndemand_values = 0.05:0.05:3.0\npvalues = map(demand_values) do di\n    return unit_commitment(\n        [1.0, di, 1.4, 1.6],\n        [1.0, di, 1.4, 1.6],\n        [1000.0, 1500.0],\n        [500.0, 1000.0];\n        silent = true,\n    )\nend\npflat = [getindex.(pvalues, i) for i in eachindex(pvalues[1])];\nnothing #hide\n\nThe influence of this variation of the demand is piecewise linear on the generation at different time frames:\n\nPlots.scatter(demand_values, pflat; xaxis = (\"Demand\"), yaxis = (\"Generation\"))\nPlots.title!(\"Different time frames and generators\")\nPlots.xlims!(0.0, 3.5)","category":"section"},{"location":"examples/chainrules_unit/#Forward-Differentiation","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Forward Differentiation","text":"Forward differentiation rule for the solution map of the unit commitment problem. It takes as arguments:\n\nthe perturbations on the input parameters\nthe differentiated function\nthe primal values of the input parameters,\n\nand returns a tuple (primal_output, perturbations), the main primal result and the perturbation propagated to this result:\n\nfunction ChainRulesCore.frule(\n    (_, Î”load1_demand, Î”load2_demand, Î”gen_costs, Î”noload_costs),\n    ::typeof(unit_commitment),\n    load1_demand,\n    load2_demand,\n    gen_costs,\n    noload_costs;\n    optimizer = HiGHS.Optimizer,\n)\n    # creating the UC model with a DiffOpt optimizer wrapper around HiGHS\n    model = Model(() -> DiffOpt.diff_optimizer(optimizer))\n    # building and solving the main model\n    pv = unit_commitment(\n        load1_demand,\n        load2_demand,\n        gen_costs,\n        noload_costs;\n        model = model,\n    )\n    energy_balance_cons = model[:energy_balance_cons]\n\n    # Setting some perturbation of the energy balance constraints\n    # Perturbations are set as MOI functions\n    Î”energy_balance = [\n        convert(MOI.ScalarAffineFunction{Float64}, d1 + d2) for\n        (d1, d2) in zip(Î”load1_demand, Î”load2_demand)\n    ]\n    MOI.set.(\n        model,\n        DiffOpt.ForwardConstraintFunction(),\n        energy_balance_cons,\n        Î”energy_balance,\n    )\n\n    p = model[:p]\n    u = model[:u]\n\n    # setting the perturbation of the linear objective\n    Î”obj =\n        sum(Î”gen_costs â‹… p[:, t] + Î”noload_costs â‹… u[:, t] for t in size(p, 2))\n    MOI.set(model, DiffOpt.ForwardObjectiveFunction(), Î”obj)\n    DiffOpt.forward_differentiate!(JuMP.backend(model))\n    # querying the corresponding perturbation of the decision\n    Î”p = MOI.get.(model, DiffOpt.ForwardVariablePrimal(), p)\n    return (pv, Î”p.data)\nend\n\nWe can now compute the perturbation of the output powers Î”pv for a perturbation of the first load demand at time 2:\n\nload1_demand = [1.0, 1.0, 1.4, 1.6]\nload2_demand = [1.0, 1.0, 1.4, 1.6]\ngen_costs = [1000.0, 1500.0]\nnoload_costs = [500.0, 1000.0];\nnothing #hide\n\nall input perturbations are 0 except first load at time 2\n\nÎ”load1_demand = 0 * load1_demand\nÎ”load1_demand[2] = 1.0\nÎ”load2_demand = 0 * load2_demand\nÎ”gen_costs = 0 * gen_costs\nÎ”noload_costs = 0 * noload_costs\n(pv, Î”pv) = ChainRulesCore.frule(\n    (nothing, Î”load1_demand, Î”load2_demand, Î”gen_costs, Î”noload_costs),\n    unit_commitment,\n    load1_demand,\n    load2_demand,\n    gen_costs,\n    noload_costs,\n)\n\nÎ”pv\n\nThe result matches what we observe in the previous figure: the generation of the first generator at the second time frame (third element on the plot).","category":"section"},{"location":"examples/chainrules_unit/#Reverse-mode-differentiation-of-the-solution-map","page":"ChainRules integration demo: Relaxed Unit Commitment","title":"Reverse-mode differentiation of the solution map","text":"The rrule returns the primal and a pullback. The pullback takes a seed for the optimal solution Ì„p and returns derivatives with respect to each input parameter of the function.\n\nfunction ChainRulesCore.rrule(\n    ::typeof(unit_commitment),\n    load1_demand,\n    load2_demand,\n    gen_costs,\n    noload_costs;\n    optimizer = HiGHS.Optimizer,\n    silent = false,\n)\n    model = Model(() -> DiffOpt.diff_optimizer(optimizer))\n    # solve the forward UC problem\n    pv = unit_commitment(\n        load1_demand,\n        load2_demand,\n        gen_costs,\n        noload_costs;\n        model = model,\n        silent = silent,\n    )\n    function pullback_unit_commitment(pb)\n        p = model[:p]\n        u = model[:u]\n        energy_balance_cons = model[:energy_balance_cons]\n\n        MOI.set.(model, DiffOpt.ReverseVariablePrimal(), p, pb)\n        DiffOpt.reverse_differentiate!(JuMP.backend(model))\n\n        obj = MOI.get(model, DiffOpt.ReverseObjectiveFunction())\n\n        # computing derivative wrt linear objective costs\n        dgen_costs = similar(gen_costs)\n        dgen_costs[1] = sum(JuMP.coefficient.(obj, p[1, :]))\n        dgen_costs[2] = sum(JuMP.coefficient.(obj, p[2, :]))\n\n        dnoload_costs = similar(noload_costs)\n        dnoload_costs[1] = sum(JuMP.coefficient.(obj, u[1, :]))\n        dnoload_costs[2] = sum(JuMP.coefficient.(obj, u[2, :]))\n\n        # computing derivative wrt constraint constant\n        dload1_demand = JuMP.constant.(\n            MOI.get.(\n                model,\n                DiffOpt.ReverseConstraintFunction(),\n                energy_balance_cons,\n            ),\n        )\n        dload2_demand = copy(dload1_demand)\n        return (dload1_demand, dload2_demand, dgen_costs, dnoload_costs)\n    end\n    return (pv, pullback_unit_commitment)\nend\n\nWe can set a seed of one on the power of the first generator at the second time frame and zero for all other parts of the solution:\n\n(pv, pullback_unit_commitment) = ChainRulesCore.rrule(\n    unit_commitment,\n    load1_demand,\n    load2_demand,\n    gen_costs,\n    noload_costs;\n    optimizer = HiGHS.Optimizer,\n    silent = true,\n)\ndpv = 0 * pv\ndpv[1, 2] = 1\ndargs = pullback_unit_commitment(dpv)\n(dload1_demand, dload2_demand, dgen_costs, dnoload_costs) = dargs;\nnothing #hide\n\nThe sensitivities with respect to the load demands are:\n\ndload1_demand\n\nand:\n\ndload2_demand\n\nThe sensitivity of the generation is propagated to the sensitivity of both loads at the second time frame.\n\nThis example integrating ChainRules was designed with support from Invenia Technical Computing.\n\n\n\nThis page was generated using Literate.jl.","category":"section"},{"location":"examples/custom-relu/#Custom-ReLU-layer","page":"Custom ReLU layer","title":"Custom ReLU layer","text":"(Image: )\n\nWe demonstrate how DiffOpt can be used to generate a simple neural network unit - the ReLU layer. A neural network is created using Flux.jl and trained on the MNIST dataset.\n\nThis tutorial uses the following packages\n\nusing JuMP\nimport DiffOpt\nimport Ipopt\nimport ChainRulesCore\nimport Flux\nimport MLDatasets\nimport Statistics\nimport Base.Iterators: repeated\nusing LinearAlgebra","category":"section"},{"location":"examples/custom-relu/#The-ReLU-and-its-derivative","page":"Custom ReLU layer","title":"The ReLU and its derivative","text":"Define a relu through an optimization problem solved by a quadratic solver. Return the solution of the problem.\n\nfunction matrix_relu(\n    y::Matrix;\n    model = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer)),\n)\n    layer_size, batch_size = size(y)\n    empty!(model)\n    set_silent(model)\n    @variable(model, x[1:layer_size, 1:batch_size] >= 0)\n    @objective(model, Min, x[:]'x[:] - 2y[:]'x[:])\n    optimize!(model)\n    return Float32.(value.(x))\nend\n\nDefine the reverse differentiation rule, for the function we defined above.\n\nfunction ChainRulesCore.rrule(::typeof(matrix_relu), y::Matrix{T}) where {T}\n    model = Model(() -> DiffOpt.diff_optimizer(Ipopt.Optimizer))\n    pv = matrix_relu(y; model = model)\n    function pullback_matrix_relu(dl_dx)\n        # some value from the backpropagation (e.g., loss) is denoted by `l`\n        # so `dl_dy` is the derivative of `l` wrt `y`\n        x = model[:x]::Matrix{JuMP.VariableRef} # load decision variable `x` into scope\n        dl_dy = zeros(T, size(x))\n        dl_dq = zeros(T, size(x))\n        # set sensitivities\n        MOI.set.(model, DiffOpt.ReverseVariablePrimal(), x[:], dl_dx[:])\n        # compute grad\n        DiffOpt.reverse_differentiate!(model)\n        # return gradient wrt objective function parameters\n        obj_exp = MOI.get(model, DiffOpt.ReverseObjectiveFunction())\n        # coeff of `x` in q'x = -2y'x\n        dl_dq[:] .= JuMP.coefficient.(obj_exp, x[:])\n        dq_dy = -2 # dq/dy = -2\n        dl_dy[:] .= dl_dq[:] * dq_dy\n        return (ChainRulesCore.NoTangent(), dl_dy)\n    end\n    return pv, pullback_matrix_relu\nend\n\nFor more details about backpropagation, visit Introduction, ChainRulesCore.jl.","category":"section"},{"location":"examples/custom-relu/#Define-the-network","page":"Custom ReLU layer","title":"Define the network","text":"layer_size = 10\nm = Flux.Chain(\n    Flux.Dense(784, layer_size), # 784 being image linear dimension (28 x 28)\n    matrix_relu,\n    Flux.Dense(layer_size, 10), # 10 being the number of outcomes (0 to 9)\n    Flux.softmax,\n)","category":"section"},{"location":"examples/custom-relu/#Prepare-data","page":"Custom ReLU layer","title":"Prepare data","text":"N = 1000 # batch size\n# Preprocessing train data\nimgs = MLDatasets.MNIST(; split = :train).features[:, :, 1:N]\nlabels = MLDatasets.MNIST(; split = :train).targets[1:N]\ntrain_X = float.(reshape(imgs, size(imgs, 1) * size(imgs, 2), N)) # stack images\ntrain_Y = Flux.onehotbatch(labels, 0:9);\n# Preprocessing test data\ntest_imgs = MLDatasets.MNIST(; split = :test).features[:, :, 1:N]\ntest_labels = MLDatasets.MNIST(; split = :test).targets[1:N];\ntest_X = float.(reshape(test_imgs, size(test_imgs, 1) * size(test_imgs, 2), N))\ntest_Y = Flux.onehotbatch(test_labels, 0:9);\nnothing #hide\n\nDefine input data The original data is repeated epochs times because Flux.train! only loops through the data set once\n\nepochs = 50 # ~1 minute (i7 8th gen with 16gb RAM)\n# epochs = 100 # leads to 77.8% in about 2 minutes\ndataset = repeated((train_X, train_Y), epochs);\nnothing #hide","category":"section"},{"location":"examples/custom-relu/#Network-training","page":"Custom ReLU layer","title":"Network training","text":"training loss function, Flux optimizer\n\ncustom_loss(m, x, y) = Flux.crossentropy(m(x), y)\nopt = Flux.setup(Flux.Adam(), m)\n\nTrain to optimize network parameters\n\n@time Flux.train!(custom_loss, m, dataset, opt);\nnothing #hide\n\nAlthough our custom implementation takes time, it is able to reach similar accuracy as the usual ReLU function implementation.","category":"section"},{"location":"examples/custom-relu/#Accuracy-results","page":"Custom ReLU layer","title":"Accuracy results","text":"Average of correct guesses\n\naccuracy(x, y) = Statistics.mean(Flux.onecold(m(x)) .== Flux.onecold(y));\nnothing #hide\n\nTraining accuracy\n\naccuracy(train_X, train_Y)\n\nTest accuracy\n\naccuracy(test_X, test_Y)\n\nNote that the accuracy is low due to simplified training. It is possible to increase the number of samples N, the number of epochs epoch and the connectivity inner.\n\n\n\nThis page was generated using Literate.jl.","category":"section"}]
}
